
        
        define(["require", "exports"], function (require, exports) { 
        
          const bestPracticeIssuesJson = {"version": "1.2", "available": true, "sectionId": "bestPractice", "sectionTitle": "Best Practice Issues", "sectionMessage": "Best practice results collected at : ", "sectionTimeContext": "2024-08-29 16:54:05.611763", "context": {"count": 17, "status": "danger", "tag": "CRIT:3 / FAIL:9 / WARN:5", "alertMessages": [], "clusterSummary": {"dataAvailable": true, "summaryTable": {"columns": [{"headerText": "Heading", "field": "heading"}, {"headerText": "Description", "field": "description", "className": "table-world-wrap"}], "records": [{"id": "958c1204-0c9a-40d7-99d4-79d6b65f13d6", "heading": "Exachk Version", "description": "24.8.0_20240828"}, {"id": "8e1f65c6-cd23-45d9-8a7c-1f0826d48705", "heading": "Executed By", "description": "root"}, {"id": "6bb4cacb-139b-47f8-90af-29b5cf53b14d", "heading": "Collection Date", "description": "2024-08-29 16:54:05.611763"}, {"id": "1a1764a3-a0bf-42db-b718-34a8ed3765db", "heading": "Duration", "description": "7 mins, 44 seconds"}, {"id": "b0e6276b-7465-439b-a545-17d518df1c12", "heading": "Arguments", "description": "-silentforce  "}, {"id": "0618395c-f9bb-4038-8545-79569b7e9828", "heading": "Valid For", "description": "179 days"}]}}, "programName": "Exachk", "snapshotTimestamp": "2024-08-29 16:54:05.611763", "healthScore": 92, "sections": [{"sectionId": "0e03c055-1a8a-4eef-bc18-773e85bd722c", "sectionName": "Exadata Critical Issues", "subsection": [{"subSectionName": "Database Server", "checksList": [{"id": "52eb5de4-a5f2-431d-9954-b3db5140dbd1", "checkCategory": "HOST", "checkID": "08F94F10048267B1E0639912F50A42AD", "checkType": "OS", "checkName": "Exadata Critical Issue EX82", "checkStatus": "CRITICAL", "status": "danger", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "danger", "statusLabel": "CRITICAL", "output": "AHF-10582: System is exposed to Exadata Critical Issue EX82"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - EXADATA CRITICAL ISSUE EX82\n\n\n\nExadata version:22.1.6.0.0.221207\nInstalled computenode RPM:exadata-sun-kvm-computenode-22.1.6.0.0.221207-1.noarch\nNumber of storage servers:3\nQuorum disk devices\nlrwxrwxrwx 1 root root 8 Aug 29 16:47 /dev/exadata_quorum/QD_DATAC1_SCAQAL03ADM05VM01 -> ../dm-16\nlrwxrwxrwx 1 root root 8 Aug 29 16:47 /dev/exadata_quorum/QD_DATAC1_SCAQAL03ADM06VM01 -> ../dm-19\nlrwxrwxrwx 1 root root 8 Aug 29 16:47 /dev/exadata_quorum/QD_RECOC1_SCAQAL03ADM05VM01 -> ../dm-17\nlrwxrwxrwx 1 root root 8 Aug 29 16:47 /dev/exadata_quorum/QD_RECOC1_SCAQAL03ADM06VM01 -> ../dm-18\nIs fix 35885988 present in filter_quorum.sh:No"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "danger", "statusLabel": "CRITICAL", "output": "AHF-10582: System is exposed to Exadata Critical Issue EX82"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - EXADATA CRITICAL ISSUE EX82\n\n\n\nExadata version:22.1.6.0.0.221207\nInstalled computenode RPM:exadata-sun-kvm-computenode-22.1.6.0.0.221207-1.noarch\nNumber of storage servers:3\nQuorum disk devices\nlrwxrwxrwx 1 root root 8 Aug 29 16:47 /dev/exadata_quorum/QD_DATAC1_SCAQAL03ADM05VM01 -> ../dm-16\nlrwxrwxrwx 1 root root 8 Aug 29 16:47 /dev/exadata_quorum/QD_DATAC1_SCAQAL03ADM06VM01 -> ../dm-18\nlrwxrwxrwx 1 root root 8 Aug 29 16:47 /dev/exadata_quorum/QD_RECOC1_SCAQAL03ADM05VM01 -> ../dm-17\nlrwxrwxrwx 1 root root 8 Aug 29 16:47 /dev/exadata_quorum/QD_RECOC1_SCAQAL03ADM06VM01 -> ../dm-19\nIs fix 35885988 present in filter_quorum.sh:No"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nA system exposed to a critical issue may experience system-wide impact to\nperformance or availability.\n\nRisk:\n\nDue to bug 35909280 and bug 35909317, high CPU utilization in a VM guest after the number of CPUs has been reduced online causes slowness in systemd-udevd service, which can lead to missing quorum disk device symbolic links on Exadata systems with fewer than five storage servers.  Missing quorum disk device symbolic links prevent ASM disks from coming back online, which can cause the following:\n\"\tFailed rolling storage server update because grid disks fail to activate.  Exadata Database Service would experience this issue as failed monthly or quarterly Exadata Infrastructure Maintenance.\n\"\tFailed Clusterware restart or ASM diskgroup unmount/mount operations due to an insufficient number of Partnership Status Table (PST) blocks.\n\"\tDatabase node reboot due to the number of available voting disks falling below the minimum required.\n\nAction / Repair:\n\nSee Exadata Critical Issue EX82 in MOS note 1270094.1."}]}, {"id": "444b4606-8368-48c7-aa3f-d9cffe830ab1", "checkCategory": "HOST", "checkID": "EC5E26BA64E8DA45E053D398EB0A285B", "checkType": "OS", "checkName": "Exadata Critical Issue DB50", "checkStatus": "CRITICAL", "status": "danger", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "danger", "statusLabel": "CRITICAL", "output": "AHF-10240: System is exposed to Exadata Critical Issue DB50"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - EXADATA CRITICAL ISSUE DB50\n\n\n\nGRID fixes for home - /u01/app/21.0.0.0/grid\n33610957:installed\n34534868:not installed\n\nRDBMS fixes for home - /u01/app/oracle/product/21.0.0.0/dbhome_1\n34286265:not installed\n34318125:not installed\n34672698:not installed\n\nSystemd service configuration files containing Delegate=yes:\n/etc/systemd/system/oracle-ohasd.service\n/etc/systemd/system/oracle-tfa.service\n\n\nDatabase process VKTM scheduling policy:\nPID POL CMD\n58762 TS  ora_vktm_CDB11\n76973 RR  asm_vktm_+ASM1"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "danger", "statusLabel": "CRITICAL", "output": "AHF-10240: System is exposed to Exadata Critical Issue DB50"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - EXADATA CRITICAL ISSUE DB50\n\n\n\nGRID fixes for home - /u01/app/21.0.0.0/grid\n33610957:installed\n34534868:not installed\n\nRDBMS fixes for home - /u01/app/oracle/product/21.0.0.0/dbhome_1\n34286265:not installed\n34318125:not installed\n34672698:not installed\n\nSystemd service configuration files containing Delegate=yes:\n/etc/systemd/system/oracle-ohasd.service\n/etc/systemd/system/oracle-tfa.service\n\n\nDatabase process VKTM scheduling policy:\nPID POL CMD\n100414 RR  asm_vktm_+ASM2\n208582 TS  ora_vktm_CDB12"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nA system exposed to a critical issue may experience system-wide impact to performance or availability.\n\nRisk:\n\nIssue #1 - Bug 33610957, Bug 34534868 - During operating system startup\nOracle Clusterware may not start because the CSS daemon (OCSSD process\nocssd.bin) cannot be set to run with real-time scheduler priority.\n\nIssue #2 - Bug 34286265, Bug 34318125 - Set process priority fails on\ncritical database background processes, such as VMTK and LMS, which can\nresult in performance degradation.\n\nAction / Repair:\n\nSee Exadata Critical Issue DB50 in MOS note 1270094.1(below link)"}, {"id": "8995652d-2472-4d6e-be67-73287c846377", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= &id=1270094.1", "text": "Note: 1270094.1 - Exadata Critical Issues"}]}]}, {"id": "72aaab40-7a8b-4737-824c-79acbdb1b282", "checkCategory": "HOST", "checkID": "E375B6913A7B3615E04313C0E50A6432", "checkType": "OS", "checkName": "Exadata Critical Issue list checked", "checkStatus": "INFO", "status": "info", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "info", "statusLabel": "INFO", "output": "AHF-2943: Exadata Critical Issues (Doc ID 1270094.1):- DB1-DB4,DB6,DB9-DB50,DB52-DB54 EX1-EX65,EX67,EX69-EX78,EX80-EX85,EX87-EX88 and IB1-IB3,IB5-IB9"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - EXADATA CRITICAL ISSUE LIST CHECKED\n\n\n\nintentional left blank"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "This environment has been checked for exposure to the following Exadata Critical Issues from MOS Note 1270094.1\n\nExadata Database Server and Storage Server      : EX1-EX65,EX67,EX69-EX78,EX80-EX85,EX87-EX88\nOracle Database and Grid Infrastructure         : DB1-DB4, DB6, DB9-DB50,DB52-DB54\nExadata Fabric Switch                           : IB1-IB3,IB5-IB9\n\nReview following MOS Note 1270094.1 to identify newly added issues, or issues that have not been evaluated by Exachk."}, {"id": "650d3c0a-6266-4068-a16c-46b598351c33", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1270094.1", "text": "Note: 1270094.1 - Exadata Critical Issues"}]}]}, {"id": "46917499-3508-41c9-a92c-0f0ccb0a8496", "checkCategory": "HOST", "checkID": "070E9D5131A30E3FE0639712F50AD832", "checkType": "OS", "checkName": "Exadata Critical Issue EX81", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX81"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - EXADATA CRITICAL ISSUE EX81\n\n\n\nsystemctl is-active irqbalance:unknown\nsystemctl is-enabled irqbalance:disabled"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX81"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - EXADATA CRITICAL ISSUE EX81\n\n\n\nsystemctl is-active irqbalance:unknown\nsystemctl is-enabled irqbalance:disabled"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nA system exposed to a critical issue may experience system-wide impact to\nperformance or availability.\n\nRisk:\n\nDue to bug 35719844 and bug 35703260, KVM guests incorrectly have the irqbalance service enabled and running, which causes excessive interrupt remapping, and conflicts with proper interrupt remapping performed by the cellirqbalance service.  Excessive interrupt remapping in the KVM guest can introduce a race condition in qemu in the KVM host that can result in RDS connection hang across the entire cluster.\n\nAction / Repair:\n\nSee Exadata Critical Issue EX81 in MOS note 1270094.1."}]}, {"id": "eee1a88c-8330-4b4c-a1de-accef6e3d15f", "checkCategory": "HOST", "checkID": "811C6F7E69AB3871E053D498EB0A8EE0", "checkType": "OS_OUT_CHECK", "checkName": "Exadata Critical Issue EX50", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX50"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR EXADATA CRITICAL ISSUE EX50\n\n\n\nExadata Software version = 22.1.6.0.0.221207\nContents of /usr/lib/tmpfiles.d/tmp.conf:-\n\n\nv /tmp 1777 root root 10d\nv /var/tmp 1777 root root 30d\n\nx /tmp/systemd-private-%b-*\nX /tmp/systemd-private-%b-*/tmp\nx /var/tmp/systemd-private-%b-*\nX /var/tmp/systemd-private-%b-*/tmp\n\nR! /tmp/systemd-private-*\nR! /var/tmp/systemd-private-*"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX50"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR EXADATA CRITICAL ISSUE EX50\n\n\n\nExadata Software version = 22.1.6.0.0.221207\nContents of /usr/lib/tmpfiles.d/tmp.conf:-\n\n\nv /tmp 1777 root root 10d\nv /var/tmp 1777 root root 30d\n\nx /tmp/systemd-private-%b-*\nX /tmp/systemd-private-%b-*/tmp\nx /var/tmp/systemd-private-%b-*\nX /var/tmp/systemd-private-%b-*/tmp\n\nR! /tmp/systemd-private-*\nR! /var/tmp/systemd-private-*"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nA system exposed to a critical issue may experience system-wide impact to performance or availability\n\nRisk:\n\nKernel service systemd-tmpfiles-clean.service may remove required socket \nfiles in /var/tmp/.oracle, which may cause database startup or connections to \nfail, or clusterware connection to fail on Exadata database servers running \nOracle Linux 7 (i.e. Exadata 19.1). \n\nAction / Repair:\n\nSee Exadata Critical Issue EX50 in below document 1270094.1 for additional details\n\nOr you can use Exachk's repair functionality to repair this check on all nodes in cluster  using ./exachk -repair all -check 811C6F7E69AB3871E053D498EB0A8EE0 -dbnone -showpass\n\nAlso this misconfiguration can be repaired with repair functionality in AHF using \"ahfctl compliance -repair -check 811C6F7E69AB3871E053D498EB0A8EE0\".\nTo see the repair command, run \"ahfctl compliance -showrepair 811C6F7E69AB3871E053D498EB0A8EE0\"."}, {"id": "c68f335c-2753-4cb7-9152-6fdf3df9e907", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1270094.1", "text": "Note: 1270094.1 - Exadata Critical Issues"}]}]}, {"id": "76cfbcf3-b207-4493-adc7-1d14d8504eb0", "checkCategory": "HOST", "checkID": "8DC65FF147E791FEE053D198EB0AE642", "checkType": "OS_OUT_CHECK", "checkName": "Exadata Critical Issue EX55", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX55"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR EXADATA CRITICAL ISSUE EX55\n\n\n\nImage Version:22.1.6.0.0.221207"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX55"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR EXADATA CRITICAL ISSUE EX55\n\n\n\nImage Version:22.1.6.0.0.221207"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nA system exposed to a critical issue may experience system-wide impact to \nperformance or availability. \n\nRisk:\n\nDue to bug 29871722, a daily cron job scheduled for approximately 3am on \ndatabase servers that runs the /opt/oracle.cellos/genCellRoute.sh script \ncauses RDS connection reset to storage servers. RDS connection reset can \ncause diskmon split-brain with regard to storage server connectivity, which \ncan lead to database server eviction and reboot to resolve the diskmon \nsplit-brain condition. \n\nAction / Repair:\n\nRun the following Exachk command to repair this issue on this system:\nNote: This Exachk repair command must be run as the root user.\n\n./exachk -repaircheck all -check 8DC65FF147E791FEE053D198EB0AE642\n\nActions taken by this Exachk repair:\n\n1. On each database server\n# touch /etc/exadata/DISABLE_RDS_RESET_FOR_DUP_HWADDR \n\nAlso this misconfiguration can be repaired with repair functionality in AHF using \"ahfctl compliance -repair -check 8DC65FF147E791FEE053D198EB0AE642\".\nTo see the repair command, run \"ahfctl compliance -showrepair 8DC65FF147E791FEE053D198EB0AE642\"."}, {"id": "ab74e5c0-1e8b-4889-a1ba-dc19204c9251", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=DOCUMENT&sourceId=1270094.1&id=2560543.1", "text": "Doc ID 2560543.1 - (EX55) RDS connection reset by genCellRoute.sh to one or more storage servers may cause database server node eviction"}]}]}, {"id": "952faf29-0a2e-4696-9f87-9e0453ea1dde", "checkCategory": "HOST", "checkID": "915F7374A6872129E053D298EB0AD83D", "checkType": "OS_OUT_CHECK", "checkName": "Exadata Critical Issue EX56", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX56"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR EXADATA CRITICAL ISSUE EX56\n\n\n\nExadata Software version = 22.1.6.0.0.221207\n\nKernel Version = 4.14.35-2047.516.2.4.el7uek.x86_64"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX56"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR EXADATA CRITICAL ISSUE EX56\n\n\n\nExadata Software version = 22.1.6.0.0.221207\n\nKernel Version = 4.14.35-2047.516.2.4.el7uek.x86_64"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nA system exposed to a critical issue may experience system-wide impact to performance or availability. \n\nRisk:\n\nDue to unpublished bug 29797007, database servers (non-OVM, domU, or dom0) running an Exadata release with kernel version 4.1.12-124.26.12 (i.e. Exadata 18.1.16, 18.1.17, 18.1.18, 19.2.2, 19.2.3, and 19.2.4) will incorrectly detect corruption and fail to mount an ext4 file system that has the meta_bg feature set. \n\nAction / Repair:\n\nSee  Exadata Critical Issue EX56in below Exadata Critical Issue MOS Note"}, {"id": "718b527c-0490-494f-ab74-3fac60e3494c", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= &id=1270094.1", "text": "Note: 1270094.1 - Exadata Critical Issues"}]}]}, {"id": "66fe81b8-7d7e-4388-b316-5d9ee60deb35", "checkCategory": "HOST", "checkID": "9CC87B4EC33DAE8AE053D598EB0A65EF", "checkType": "OS_OUT_CHECK", "checkName": "Exadata Critical Issue EX57", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX57"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR EXADATA CRITICAL ISSUE EX57\n\n\n\nExadata Software version = 22.1.6.0.0.221207\n\nKernel Version = 4.14.35-2047.516.2.4.el7uek.x86_64"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX57"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR EXADATA CRITICAL ISSUE EX57\n\n\n\nExadata Software version = 22.1.6.0.0.221207\n\nKernel Version = 4.14.35-2047.516.2.4.el7uek.x86_64"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nA system exposed to a critical issue may experience system-wide impact to performance or availability.\n\nRisk:\n\nDue to unpublished bug 30388717, heavy RDMA traffic on the interconnect network (on either RoCE-based or InfiniBand-based systems) may cause a database server or storage server kernel to crash.\n\nAction / Repair:\n\nSee Exadata Critical Issue EX57 in MOS note 1270094.1."}, {"id": "c9a40f02-3bb4-4b7e-bb32-91511019dcf7", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= &id=1270094.1", "text": "Note: 1270094.1 - Exadata Critical Issues"}]}]}, {"id": "ef8408e5-bb21-4999-92e6-b950a82ef36f", "checkCategory": "HOST", "checkID": "9CC97C028C5E05AAE053D298EB0A1A6E", "checkType": "OS_OUT_CHECK", "checkName": "Exadata Critical Issue EX58", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX58"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR EXADATA CRITICAL ISSUE EX58\n\n\n\nExadata Software version = 22.1.6.0.0.221207\n\nKernel Version = 4.14.35-2047.516.2.4.el7uek.x86_64\n\nuptrack-updates RPM Version = uptrack-updates-4.14.35-2047.516.2.4.el7uek.x86_64-20221118-0.noarch"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX58"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR EXADATA CRITICAL ISSUE EX58\n\n\n\nExadata Software version = 22.1.6.0.0.221207\n\nKernel Version = 4.14.35-2047.516.2.4.el7uek.x86_64\n\nuptrack-updates RPM Version = uptrack-updates-4.14.35-2047.516.2.4.el7uek.x86_64-20221118-0.noarch"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nA system exposed to a critical issue may experience system-wide impact to performance or availability.\n\nRisk:\n\nDue to bug 30391350, after database server reboot, databases open slowly due to excessive LGWR waits caused by slow RDS connection formation.  Excessive LGWR waits may cause slowness on instances in other nodes in the cluster.  \nSlowness lasting up to 20 minutes has been observed on Exadata quarter rack systems experiencing this issue.\n\nAction / Repair:\n\nSee Exadata Critical Issue EX58 in MOS note 1270094.1."}, {"id": "4b203662-6374-4943-af57-e9c1a96f2cd5", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= &id=1270094.1", "text": "Note: 1270094.1 - Exadata Critical Issues"}]}]}, {"id": "cea05c22-39cb-4cf2-87b9-c5517e26ff9b", "checkCategory": "CRS HOME", "checkID": "A62E37CA2B79AB13E053D198EB0A764C", "checkType": "OS", "checkName": "Exadata Critical Issue EX62", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX62"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - EXADATA CRITICAL ISSUE EX62\n\n\n\nTFA Version = 2408000"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX62"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - EXADATA CRITICAL ISSUE EX62\n\n\n\nTFA Version = 2408000"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nA system exposed to a critical issue may experience system-wide impact to performance or availability.\n\nRisk:\n\nDue to bug 30767693, Trace File Analyzer (TFA), part of Autonomous Health Framework (AHF), uses excessive kernel memory on database servers, which leads to severe performance degradation, or database server instability.  As the number of databases and cluster resources increase the issue is more pronounced.\n\nAction / Repair:\n\nSee Exadata Critical Issue EX62 in below MOS note 1270094.1."}, {"id": "c2ebbf6a-5fba-48ee-b989-932ac3b5bebf", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1270094.1", "text": "Note: 1270094.1 - Exadata Critical Issues"}]}]}, {"id": "4d708a8e-dff1-4eb9-9162-f669d757d73d", "checkCategory": "HOST", "checkID": "B407B045E9413B83E053D598EB0A8904", "checkType": "OS_OUT_CHECK", "checkName": "Exadata Critical Issue EX64", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX64"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR EXADATA CRITICAL ISSUE EX64\n\n\n\nkernel version = 4.14.35.2047.516.2.4.el7uek.x86_64\nExadata image version = 22.1.6.0.0.221207\nuptrack-updates RPM version = uptrack-updates-4.14.35-2047.516.2.4.el7uek.x86_64-20221118-0.noarch"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX64"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR EXADATA CRITICAL ISSUE EX64\n\n\n\nkernel version = 4.14.35.2047.516.2.4.el7uek.x86_64\nExadata image version = 22.1.6.0.0.221207\nuptrack-updates RPM version = uptrack-updates-4.14.35-2047.516.2.4.el7uek.x86_64-20221118-0.noarch"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nA system exposed to a critical issue may experience system-wide impact to performance or availability.\n\nRisk:\n\nDue to bug 31784659 and bug 31648140, RDS connection establishment may be slow or hang resulting in node eviction, slow or hung clusterware/ASM startup, offline ASM disks, and slow or hung database(s). RDS connection establishment occurs during normal activity in many circumstances, including after restart of a fabric switch, database server, or storage server.\n\nAction / Repair:\n\nSee Exadata Critical Issue EX64 in MOS note 1270094.1."}, {"id": "b97f445e-8894-477f-972d-b94982bc707a", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= &id=1270094.1", "text": "Note: 1270094.1 - Exadata Critical Issues"}]}]}, {"id": "52e295ea-5f1d-4ca4-a9d7-8ff1304794b9", "checkCategory": "HOST", "checkID": "BF6DC15BD65390ECE053D398EB0AD720", "checkType": "OS_OUT_CHECK", "checkName": "Exadata Critical Issue EX67", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX67"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR EXADATA CRITICAL ISSUE EX67\n\n\n\nExadata software version = 22.1.6.0.0"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX67"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR EXADATA CRITICAL ISSUE EX67\n\n\n\nExadata software version = 22.1.6.0.0"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nA system exposed to a critical issue may experience system-wide impact to \nperformance or availability\n\nRisk:\n\nDue to bug 32404239, database instances may crash or database processes may\nfail due to an I/O buffer memory corruption.\n\nAction / Repair:\n\nSee Exadata Critical Issue EX67 in below document 1270094.1 for additional details"}, {"id": "487307b2-c614-46b3-8968-3fb66bc501fd", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1270094.1", "text": "Note: 1270094.1 - Exadata Critical Issues"}]}]}, {"id": "af7a8ce4-c33d-4caa-92f6-8769e9c5b3b7", "checkCategory": "HOST", "checkID": "C5A39BC21C9C79DFE053D198EB0A5537", "checkType": "OS_OUT_CHECK", "checkName": "Exadata Critical Issue EX33", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX33"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR EXADATA CRITICAL ISSUE EX33\n\n\n\nExadata Software version = 22.1.6.0.0.221207"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX33"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR EXADATA CRITICAL ISSUE EX33\n\n\n\nExadata Software version = 22.1.6.0.0.221207"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nA system exposed to a critical issue may experience system-wide impact to performance or availability.\n\nRisk:\n\nDue to bug 22118109, when under heavy InfiniBand network load, performance may be severely reduced, instance eviction may occur, or the database may hang due to RDS congestion.\n\nAction / Repair:\n\nSee Exadata Critical Issue EX33 in MOS note 1270094.1."}, {"id": "e7435e24-918b-46fc-a909-4777b8a7c969", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= &id=1270094.1", "text": "Note: 1270094.1 - Exadata Critical Issues"}]}]}, {"id": "739fda94-c799-48ed-87bd-a8e7a1c4e7d8", "checkCategory": "HOST", "checkID": "D6EA161793AEEFB9E053D198EB0AD5AA", "checkType": "OS", "checkName": "Exadata Critical Issue EX72", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX72"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - EXADATA CRITICAL ISSUE EX72\n\n\n\nimageinfo -ver:22.1.6.0.0\n\nGrid version:21.7.0.0.0\n\nrpm -q uptrack-updates-4.14.35-2047.516.2.4.el7uek.x86_64:uptrack-updates-4.14.35-2047.516.2.4.el7uek.x86_64-20221118-0.noarch\n\n/etc/exadata/config/bug33703438fixed.txt does not exist\n\n<GI_HOME>/bin/crsctl stat res ora.cssd -p -init | grep REBOOT_OPTS:\"REBOOT_OPTS=\"\n\nopatch lsinventory -disablelog -bugs_fixed -oh <GIHOME> | egrep '31411277|33563477|33731331':(no value returned)"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX72"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - EXADATA CRITICAL ISSUE EX72\n\n\n\nimageinfo -ver:22.1.6.0.0\n\nGrid version:21.7.0.0.0\n\nrpm -q uptrack-updates-4.14.35-2047.516.2.4.el7uek.x86_64:uptrack-updates-4.14.35-2047.516.2.4.el7uek.x86_64-20221118-0.noarch\n\n/etc/exadata/config/bug33703438fixed.txt does not exist\n\n<GI_HOME>/bin/crsctl stat res ora.cssd -p -init | grep REBOOT_OPTS:\"REBOOT_OPTS=\"\n\nopatch lsinventory -disablelog -bugs_fixed -oh <GIHOME> | egrep '31411277|33563477|33731331':(no value returned)"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nA system exposed to a critical issue may experience system-wide impact to\nperformance or availability.\n\nRisk:\n\nDue to bug 33703438, a database node (a physical server or a virtual KVM\nguest) on a RoCE-based  (i.e. X8M or X9M) Exadata system does not\nautomatically restart if it is evicted by Oracle Clusterware Cluster\nSynchronization Services (CSS). The evicted node will remain unavailable\nuntil manual action is taken to reset the node.\n\nAction / Repair:\n\n See Exadata Critical Issue EX72 in MOS note 1270094.1. "}]}, {"id": "ef3e242e-7244-4a5a-ab82-014b05d79e86", "checkCategory": "HOST", "checkID": "E1808F6279604436E053D198EB0ABAEA", "checkType": "OS", "checkName": "Exadata Critical Issue EX75", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX75"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Exadata Critical Issue EX75\n\n\n\nExadata Software version:22.1.6.0.0\n\nfindmnt /dev/shm:TARGET   SOURCE FSTYPE OPTIONS\n/dev/shm tmpfs  tmpfs  rw,size=608377856k\n\nPLSQL_CODE_TYPE:INTERPRETED           4233"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX75"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Exadata Critical Issue EX75\n\n\n\nExadata Software version:22.1.6.0.0\n\nfindmnt /dev/shm:TARGET   SOURCE FSTYPE OPTIONS\n/dev/shm tmpfs  tmpfs  rw,size=608377856k\n\nPLSQL_CODE_TYPE:INTERPRETED           4233"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nA system exposed to a critical issue may experience system-wide impact to\nperformance or availability.\n\nRisk:\n\nDue to bug 34034299, on Exadata Database Service and on-premises Exadata\nsystems, database instances may fail to start with error ORA-600\n[pesldl03_MMap: errno 1 errmsg Operation not permitted] when PL/SQL compiled\nin NATIVE mode attempts execution during startup. This issue typically occurs\nwhen a database has all PL/SQL compiled in NATIVE mode and the Exadata\nsoftware on the database server is updated.\n\nAction / Repair:\n\nSee Exadata Critical Issue EX75 in MOS note 1270094.1."}, {"id": "b901a3f2-86ac-45bb-aeec-b2abc1ab66bf", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= &id=1270094.1", "text": "Note: 1270094.1 - Exadata Critical Issues"}]}]}]}, {"subSectionName": "Cluster Wide", "checksList": [{"id": "a43d6b71-45a8-4eff-8631-ed2281c85c5d", "checkCategory": "HOST", "checkID": "0C80EB438F539110E0639D12F50AA884", "checkType": "CROSS_NODE_CHECK", "checkName": "Exadata Critical Issue EX83", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "System is not exposed to Exadata Critical Issue EX83"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - EXADATA CRITICAL ISSUE EX83\n\n\n\nCDB11.inmemory_size = 0\nCDB12.inmemory_size = 0\nCDB11.inmemory_force = DEFAULT\nCDB12.inmemory_force = DEFAULT"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nA system exposed to a critical issue may experience system-wide impact to\nperformance or availability.\n\nRisk:\n\nDue to bug 35938811, and bug 36073771, and bug 36073739, after storage servers are upgraded to certain Exadata 23.1 versions, wrong results may occur when the Exadata Smart Scan feature In-Memory Columnar Caching is enabled and In-Memory Columnar Caching or Storage Indexes are used to produce query results.  Exadata In-Memory Columnar Caching is used when the Database In-Memory option is enabled.\n \n\nAction / Repair:\n\nSee Exadata Critical Issue EX83 in MOS note 1270094.1."}]}]}]}, {"sectionId": "679b2cf2-ebf7-4b09-a6e2-84fe67934678", "sectionName": "Database Server", "subsection": [{"subSectionName": "Database Server", "checksList": [{"id": "9d89add3-9999-4b8a-b8d7-e06893279dc6", "checkCategory": "RDBMS", "checkID": "19DA5169713DA63BE0530A98EB0AAE45", "checkType": "OS", "checkName": "Verify Hidden Database Initialization Parameter Usage", "checkStatus": "FAIL", "status": "danger", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "danger", "statusLabel": "FAIL", "output": "AHF-4896: Hidden database Initialization Parameter usage is not correct"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Verify Hidden Database Initialization Parameter Usage\n\n\n\n\nThe Following Underscore Parameters are incorrectly set\n--------------------------------------------------------\n\n\n_appqos_cdb_setting                            is Not Expected to be set at all. - Alert Level = [FAIL]\n_disable_oradebug_commands                     is Not Expected to be set at all. - Alert Level = [FAIL]\n\nFor this version of the database, 21.7.0.0.220719, the allowed underscore parameters along with their recommended values are :\n\n_assm_segment_repair_bg FALSE\n_parallel_adaptive_max_users 2\n_bct_public_dba_buffer_size 65142528\n_bct_buffer_allocation_max 1073741824\n_ipddb_enable TRUE"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "danger", "statusLabel": "FAIL", "output": "AHF-4896: Hidden database Initialization Parameter usage is not correct"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Verify Hidden Database Initialization Parameter Usage\n\n\n\n\nThe Following Underscore Parameters are incorrectly set\n--------------------------------------------------------\n\n\n_appqos_cdb_setting                            is Not Expected to be set at all. - Alert Level = [FAIL]\n_disable_oradebug_commands                     is Not Expected to be set at all. - Alert Level = [FAIL]\n\nFor this version of the database, 21.7.0.0.220719, the allowed underscore parameters along with their recommended values are :\n\n_assm_segment_repair_bg FALSE\n_parallel_adaptive_max_users 2\n_bct_public_dba_buffer_size 65142528\n_bct_buffer_allocation_max 1073741824\n_ipddb_enable TRUE"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nHidden database initialization parameters are typically set as a workaround to solve a specific problem, and should be removed once a system has been upgraded to a version level that contains the fix for the specific problem. Often they are not removed during the upgrade process to the version level that contains the correct fix. Verifying the hidden database initialization parameter usage helps avoid hidden parameters being used any longer than necessary.\n\nNOTES:\n\n1) For additional ZFS based backup configuration information, please see: Oracle ZFS Storage: FAQ: Exadata RMAN Backup with The Oracle ZFS Storage Appliance (Doc ID 1354980.1)\n\n2) This best practice check does not include any application specific hidden parameters. If an application in use requires hidden parameters that are failed by this best practice, refer to the proper documentation for the application version in use. If the extra hidden parameters are correct, then ignore the failures reported for those specific parameters.\n\nFor Oracle E-Business Suite, please see: Database Initialization Parameters for Oracle E-Business Suite Release 12 (Doc ID 396009.1)\nFor Siebel CRM Application, please see: Performance Tuning Guidelines for Siebel CRM Application on Oracle Database (Doc ID 2077227.2)\n\nRisk:\n\nUse of hidden ASM or database initialization parameters not recommended by Oracle development in an Exadata environment can cause instability, performance problems, corruptions, and crashes.\n\nAction / Repair:\n\nTo verify the hidden database initialization parameter usage in each ASM and database instance, execute the following sqlplus command as the owner of the respective home with the environment properly set to access the instance:\n\nselect name,value from v$parameter where substr(name,1,1)='_';\n\n    NOTE: v$parameter only contains hidden parameters that have been changed from the default, which are the ones of interest here.\n\nThe expected output should be a list of any hidden parameters in use that have been changed from the default value, similar to:\n\n_enable_NUMA_support  FALSE\n\nThere should be no hidden parameters in use that are not shown in the \"Generally Acceptable Hidden Parameters Table\":\n\nGenerally Acceptable Hidden Parameters Table\nParameter\nName \tValue \tOracle\nVersion \tExadata\nVersion \tInstance\nType \tNotes\n_file_size_increase_increment \t2143289344 \t&lt;= 11.2.0.3 BP11 \tALL \tDatabase \tEnables more performant rman backup allocation sizes.\n_enable_NUMA_support \tSet _enable_NUMA_support=TRUE for all hardware generation 8-socket database servers (Note - applies to non-OVM only - OVM is not supported on 8-socket servers).\n\nSet _enable_NUMA_support=TRUE for X5 and later 2-socket database servers deployed as non-OVM.\n\nIn all other cases do not explicitly set _enable_NUMA_support. \t&lt;12.1.0.2.6 \tALL \tDatabase \tFor any Exadata system using Database 12.1.0.2.6 or higher, do not explicitly set _enable_NUMA_support (includes all hardware generations, 2-socket, 8-socket, non-OVM, and OVM). _enable_NUMA_support setting is automatically configured by the database.\n\nFor any Exadata system using Database 12.1.0.2.5 or lower, reference the recommended setting in the Value column of this row.\n_asm_resyncckpt \t0 \t12.1.0.1 ONLY \tALL \tASM \tTurns off resync checkpointing\n_smm_auto_max_io_size \t1024 \t\n\n12.1 and lower\n\tALL \tDatabase \tThis permits 1MB IOs for hash joins that spill to disk, which can increase performance up to 40% due to increased throughput. These performance increases can prevent the need to move TEMP to flash.\n\nInternal only note: this will no longer be needed when bug 20925115 is fixed.\n_parallel_adaptive_max_users \t2 \t12.1 and higher \tALL \tDatabase \tCheck to ensure not more than the recommended value. Setting this higher than this recommended value can deplete memory and impact performance.*\n\nParameter PARALLEL_MAX_SERVERS is evaluated based on the below calculation method:\nparallel_threads_per_cpu*cpu_count*concurrent_parallel_users*5\n\nParameter PARALLEL_SERVERS_TARGET is evaluated based on the below calculation method:\nparallel_threads_per_cpu*cpu_count*concurrent_parallel_users*2\n\n_PARALLEL_ADAPTIVE_MAX_USERS provides the value of concurrent_parallel_users in the calculation. The value of this parameter is set to 4 in most cases which would result in a higher than recommended maximum number of parallel servers, therefore the recommended value is 2.\n\nPARALLEL_MAX_SERVERS would be calculated as below assuming cpu_count is set to all available CPUs:\nX2-2: 1 * 24 * 2 * 5 = 240\nX6-2: 1 * 88 * 2 * 5 = 880\nX2-8: 1 * 128 * 2 * 5 = 1280\nX6-8: 1 * 288 * 2 * 5 = 2880\n_assm_segment_repair_bg \tFALSE \t12.2 and higher \tALL \tDatabase \twork-around for bug 23734075\n_asm_max_connected_clients \tDynamically changes \t12.2. and 18.1 ONLY \tALL \tASM \tUsed internally; Removed in release 19c\n_backup_disk_bufcnt \t64 \t12.1 and lower \tALL \tDatabase \tOnly when ZFS based backups are in use (NOTE: 1)\n_backup_disk_bufsz \t1048576 \t12.1 and lower \tALL \tDatabase \tOnly when ZFS based backups are in use (NOTE: 1)\n_backup_file_bufcnt \t64 \t12.1 and lower \tALL \tDatabase \tOnly when ZFS based backups are in use (NOTE: 1)\n_backup_file_bufsz \t1048576 \t12.1 and lower \tALL \tDatabase \tOnly when ZFS based backups are in use (NOTE: 1) \n"}, {"id": "67978577-955f-42f8-8d3c-5985d391c2dd", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=2094946.1", "text": "Note: 2094946.1 - High Waits On 'block change tracking buffer space' - Checkpoint Contention With BLOCK CHANGE TRACKING"}]}]}, {"id": "1178e3e8-6f21-47f1-abbb-4981a48c763d", "checkCategory": "HOST", "checkID": "135F449E978C3B44E05313C0E50ABE53", "checkType": "OS", "checkName": "Verify Database Memory Allocation", "checkStatus": "FAIL", "status": "danger", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "warning", "statusLabel": "WARN", "output": "AHF-4073: Verify Database Memory Allocation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY DATABASE MEMORY ALLOCATION\n\n\n\n<!-- HTML OUTPUT -->\n<pre>Instances found running:1\nNumber of nodes in the cluster (N):2\n\n\nPhysical memory:580.2 GB\nMemory reserved for the OS:40.0 GB\nHugePages allocated:293.2 GB\nTotal SGA memory:119.2 GB\nTotal PGA memory:116.0 GB\n\nTotal calculated memory required (memory reserved for the OS + HugePages allocated + total PGA memory):449.3 GB\nNon-HugePages memory available (physical memory - HugePages allocated):286.9 GB\nUnallocated memory (MAX_PGA_MEMORY - Total PGA memory):130.9 GB\nMAX_PGA_MEMORY:246.9 GB\nHA_PGA:117.2 GB\n\n<span style=\"font-weight:bold\">1. Physical Memory</span>\n<span style=\"background-color:#CEEFCE\">PASS:The sum of memory reserved for the OS (40.0 GB) + HugePages allocated (293.2 GB) + Total PGA memory (116.0 GB) (total memory required of 449.3 GB) is less than physical memory (580.2 GB)</span>\n\n<span style=\"font-weight:bold\">2. PGA Memory</span>\n<span style=\"background-color:#CEEFCE\">PASS:This check assumes that PGA allocation per node includes HA considerations to support the failure of a single node using the calculation:\nHA_PGA = (1 / N) * TOTAL_DB_PGA_AGG_LIMIT * (1 + WORKLOAD_VARIATION_PCT)\nTo support HA considerations, 117.2 GB of memory must be accounted for in PGA_AGGREGATE_LIMIT settings. There is unallocated memory of 130.9 GB for additional database allocation or other process utilization.</span>\n<span style=\"background-color:#CEEFCE\">If you have not considered the HA component in your PGA settings, you have enough unallocated memory (130.9 GB) available to increase PGA_AGGREGATE_LIMIT in all databases to support the additional workload due to a node failure (117.2 GB).</span>\n\n<span style=\"font-weight:bold\">3. SGA Memory</span>\n<span style=\"background-color:#FFFFBF\">WARN:Total SGA Allocation in running databases of 119.2 GB is less than and is not within 3% of HugePages Allocation of 293.2 GB; you may be over-allocating HugePages. Please review.</span></pre>"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "danger", "statusLabel": "FAIL", "output": "AHF-4073: Verify Database Memory Allocation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - VERIFY DATABASE MEMORY ALLOCATION\n\n\n\n<!-- HTML OUTPUT -->\n<pre>Instances found running:1\nNumber of nodes in the cluster (N):2\n\n\nPhysical memory:580.2 GB\nMemory reserved for the OS:40.0 GB\nHugePages allocated:119.1 GB\nTotal SGA memory:119.2 GB\nTotal PGA memory:116.0 GB\n\nTotal calculated memory required (memory reserved for the OS + HugePages allocated + total PGA memory):275.1 GB\nNon-HugePages memory available (physical memory - HugePages allocated):461.1 GB\nUnallocated memory (MAX_PGA_MEMORY - Total PGA memory):305.1 GB\nMAX_PGA_MEMORY:421.1 GB\nHA_PGA:117.2 GB\n\n<span style=\"font-weight:bold\">1. Physical Memory</span>\n<span style=\"background-color:#CEEFCE\">PASS:The sum of memory reserved for the OS (40.0 GB) + HugePages allocated (119.1 GB) + Total PGA memory (116.0 GB) (total memory required of 275.1 GB) is less than physical memory (580.2 GB)</span>\n\n<span style=\"font-weight:bold\">2. PGA Memory</span>\n<span style=\"background-color:#CEEFCE\">PASS:This check assumes that PGA allocation per node includes HA considerations to support the failure of a single node using the calculation:\nHA_PGA = (1 / N) * TOTAL_DB_PGA_AGG_LIMIT * (1 + WORKLOAD_VARIATION_PCT)\nTo support HA considerations, 117.2 GB of memory must be accounted for in PGA_AGGREGATE_LIMIT settings. There is unallocated memory of 305.1 GB for additional database allocation or other process utilization.</span>\n<span style=\"background-color:#CEEFCE\">If you have not considered the HA component in your PGA settings, you have enough unallocated memory (305.1 GB) available to increase PGA_AGGREGATE_LIMIT in all databases to support the additional workload due to a node failure (117.2 GB).</span>\n\n<span style=\"font-weight:bold\">3. SGA Memory</span>\n<span style=\"background-color:#FAA0A0\">FAIL:Total SGA memory in running databases 119.2 GB is greater than HugePages allocation of 119.1 GB. You have not set the USE_LARGE_PAGES database initialization parameter correctly for one or more databases. Please review the output from the check \"Check for parameter use_large_pages\".</span></pre>"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nOptimizing database memory allocation ensures that application service levels are not impacted during normal runtime as well as during planned and unplanned outages.\n\nThe main benefits of this best practice are:\n\n  1. Ensuring memory is not oversubscribed, including the scenario of losing a database node\n  2. Enabling a new formula to ensure large memory systems don't have too much memory allocated for the operating system (OS)\n  3. Reporting when hugepages are allocated, but not in use by databases, so that memory can potentially be freed up and used for SGAs or PGAs\n  4. Reporting when extra OS memory is available, but not used by databases, so it can be used for SGAs or PGAs\n\nRisk:\n\nDatabase performance and system stability can be significantly impacted when memory configuration is oversubscribed.\n\nMemory sizing should also consider high availability (HA) implications, such as the loss of a database node or instance.  In these cases, workload and their associated foreground process memory requirements will need to be redistributed over the surviving database nodes or instances. Therefore, some headroom should be allowed on each database node to ensure proper expected workload performance and stability in the case of HA impact.\n\nAction / Repair:\n\nThere are two basic requirements for estimating memory allocation:\n1) Memory reserved for the OS\n2) Memory required for databases and applications:\n    2.1) System Global Area (SGA) and\n    2.2) Program Global Area (PGA)\n\nTherefore, the total use of memory on a database node may be accounted for:\n\n    Total memory allocation = OS memory reservation + SGA (HugePages) allocation + PGA allocation\n\n\n1) Memory reserved for the OS\n\nThe following formula is used to calculate the memory reserved for the OS:\n    OS_MEMORY_RESERVATION = MIN(20 GB per CPU socket, ROUNDUP(25% of physical memory))\n\nExample 1: 2-socket VM with 75 GB of memory\n    OS_MEMORY_RESERVATION = MIN(20 GB * 2, ROUNDUP(25% * 75 GB))\n                          = MIN(40 GB, ROUNDUP(18.75 GB))\n                          = 19 GB\nThe remaining memory (in this example, 75 GB - 19 GB = 56 GB) can be allocated for databases and applications.\nThe allocation of SGA and PGA is application-specific, so an exact formula is not provided.\n\nExample 2: 8-socket database node with 3 TB of memory\n    OS_MEMORY_RESERVATION = MIN(20 GB * 8, ROUNDUP(25% * 3072 GB))\n                          = MIN(160 GB, ROUNDUP(768 GB))\n                          = 160 GB\nThe remaining memory (in this example, 3072 GB - 160 GB = 2912 GB) can be allocated for databases and applications.\nThe allocation of SGA and PGA is application-specific, so an exact formula is not provided.\n\n2) Memory required for databases and applications\n\n2.1) System Global Area (SGA)\nThe memory used for SGA is allocated as HugePages.\n\n2.2) Program Global Area (PGA)\nThe remaining memory in the system can be used by foreground processes in their PGA.  The total PGA allocation must account for some variation in PGA usage due to potential connection imbalances as well as the possibility that there could be a node failure, which redistributes that node's PGA requirements over the surviving nodes. The steps below show how to determine if the sum of PGA across all instances is sized properly to ensure there is enough memory for variations in the workload as well as the failure of one node.\n\nWe use the following variables in our steps below:\n\n    MAX_PGA_MEMORY: Maximum available memory on a node that could be allocated to PGA\n    after reserving OS memory and SGA memory (discussed above as \"PGA allocation\").\n\n    TOTAL_DB_PGA_AGG_LIMIT: The total allocated PGA on a node based on the sum of\n    PGA_AGGREGATE_LIMIT for all database instances.\n\n    HA_PGA: PGA required to support one node failure.\n\n    WORKLOAD_VARIATION_PCT: Workload variation factor that takes into account\n    the uneven distribution of workload across nodes in the cluster.\n    We typically use 1% to estimate this, but it can vary for different\n    connection methods.\n\n    N: Number of nodes in the cluster.\n\n\nWe use the following 4-step procedure to determine the PGA memory allocation:\n\n1. Find the maximum amount of memory that could be allocated on a node for PGA:\n    MAX_PGA_MEMORY = physical memory - OS_MEMORY_RESERVATION - HugePages allocated\n\n2. Find TOTAL_DB_PGA_AGG_LIMIT by summing the PGA_AGGREGATE_LIMIT from all running database instances on the node.\n\n3. Find HA_PGA across all instances:\n    HA_PGA = (1 / N) * TOTAL_DB_PGA_AGG_LIMIT * (1 + WORKLOAD_VARIATION_PCT)\n\n4. Evaluate:\nIf you set PGA_AGGREGATE_LIMIT for all databases to include the HA_PGA component, and their total is less than MAX_PGA_MEMORY, then the current PGA_AGGREGATE_LIMIT setting meets our recommendation.\nIf you set PGA_AGGREGATE_LIMIT for all databases and didn't consider the HA_PGA component, make sure you have enough unallocated memory available to increase PGA_AGGREGATE_LIMIT in all databases to include the HA_PGA. If you don't have enough unallocated memory to support HA_PGA, database performance and system stability may be impacted during planned and unplanned outages.\n\nNOTE: The following formula can be applied to an individual database to calculate per database HA_PGA\n    Per database HA_PGA = (1 / N) * PGA_AGGREGATE_LIMIT * (1 + WORKLOAD_VARIATION_PCT)\n\nExample 1: 2-socket VM 4-node cluster with 75 GB per VM\nIn the first example above for a 2-socket VM with 75 GB of memory, 56 GB of memory is available for SGA and PGA after computing the OS_MEMORY_RESERVATION of 19 GB. We assume that we allocate 36 GB for SGA (HugePages allocated) and 14 GB for PGA (TOTAL_DB_PGA_AGG_LIMIT). MAX_PGA_MEMORY is 20 GB (75 - 19 - 36).\nWe further assume a 1% workload variation (WORKLOAD_VARIATION_PCT) and the potential loss of one node. This means the sum of HA_PGA of all instances is\n    HA_PGA = (1 / N) *  TOTAL_DB_PGA_AGG_LIMIT * (1 + WORKLOAD_VARIATION_PCT)\n           = (1/4) * 14 GB * (1 + 1%) = 3.54 GB\nIn this example we set TOTAL_DB_PGA_AGG_LIMIT without considering the HA_PGA component. We need to change all database to account for the potential loss of one node, so the sum of all PGA_AGGREGATE_LIMIT values across all instances is increased by the HA_PGA value. The total of PGA_AGGREGATE_LIMIT across all databases would need to be 17.54 GB (3.54 + 14). The memory available for PGAs is 20 GB which means we have enough unallocated memory available to increase the PGA_AGGREGATE_LIMIT to support the additional workload due to a node failure.\n\n\nExample 2: 8-socket database node 2-node cluster with 3 TB per node\nIn the second example above for an 8-socket database node with 3 TB of memory, 2912 GB of memory is available for SGA and PGA after computing the OS_MEMORY_RESERVATION of 160 GB. We assume that we allocate 50% to SGA (i.e., 1456 GB) and 50% to TOTAL_DB_PGA_AGG_LIMIT (i.e., 1456 GB). MAX_PGA_MEMORY is 1456 GB (3TB - 160 GB - 1456 GB).\nWe further assume a 1% workload variation (WORKLOAD_VARIATION_PCT) and the potential loss of one node. This means the sum of HA_PGA of all instances is:\n    HA_PGA = (1 / N) * TOTAL_DB_PGA_AGG_LIMIT * (1 + WORKLOAD_VARIATION_PCT)\n           = (1/2) * 1456 GB * (1 + 1%) = 735.3 GB\nIn this example we set TOTAL_DB_PGA_AGG_LIMIT without considering the HA_PGA component. We need to change all database to account for the potential loss of one node, so the sum of all PGA_AGGREGATE_LIMIT values across all instances is increased by the HA_PGA value. The total of PGA_AGGREGATE_LIMIT across all databases would need to be 2191.3  GB (735.3 + 1456). The memory available for PGAs is 1420 GB which means we don't have enough unallocated memory available to increase the PGA_AGGREGATE_LIMIT to support the additional workload due to a node failure.\n\n\n\n\nThis check performs three comparisons:\n\n1. On each node within the cluster, compare the allocated memory against the physical memory on each node within the cluster using the following formula:\n    OS_MEMORY_RESERVATION + HugePages allocation + TOTAL_DB_PGA_AGG_LIMIT + HA_PGA is less than or equal to the physical memory on the database node\n\nThe expected output for each node would be:\n    PASS: The sum of memory reserved for the OS (XX.XX GB) + HugePages allocated (XX.XX GB) + Total PGA memory (XX.XX GB) (total memory required of XX.XX GB) is less than or equal to physical memory (XX.XX GB)\n\nIf a node has overallocated memory, the following output would be displayed:\n    FAIL: The sum of memory reserved for the OS (XX.XX GB) + HugePages allocated (XX.XX GB) + Total PGA memory (XX.XX GB) (total memory required of XX.XX GB) is greater than physical memory (XX.XX GB)\n\n2. On each node within the cluster, calculate MAX_PGA_MEMORY and TOTAL_DB_PGA_AGG_LIMIT.\nNOTE: If the comparison for physical memory fails, this check will be skipped and you will see the following output:\n    WARN: This check has been skipped due to failure of the previous \"Physical Memory\" check. Failure of the \"Physical Memory\" check already asserts that there is not enough memory to support PGA HA considerations.\n\n\nIf there is enough unallocated memory to support PGA HA considerations, the following output for each node would be:\n    PASS: This check assumes that PGA allocation per node includes HA\n    considerations to support the failure of a single node using the calculation:\n        HA_PGA = (1 / N) * TOTAL_DB_PGA_AGG_LIMIT * (1 + WORKLOAD_VARIATION_PCT)\n    To support HA considerations, XX.XX GB of memory must be accounted for\n    in PGA_AGGREGATE_LIMIT settings.There is unallocated memory of XX.XX GB for additional database allocation or other process utilization.\n    If you considered the HA component in your Total PGA memory from all databases (XX.XX GB),\n    then the current PGA_AGGREGATE_LIMIT setting meets our recommendation.\n    If you have not considered the HA component in your PGA settings, you have\n    enough unallocated memory (XX.XX) available to increase PGA_AGGREGATE_LIMIT in\n    all databases to support the additional workload due to a node failure (XX.XX).\n\nIf there is not enough unallocated memory to support PGA HA considerations, the following output for each node would be:\n    WARN: This check assumes that PGA allocation per node includes HA\n    considerations to support the failure of a single node using the calculation:\n       HA_PGA = (1 / N) * TOTAL_DB_PGA_AGG_LIMIT * (1 + WORKLOAD_VARIATION_PCT)\n    To support HA considerations, XX.XX GB of memory must be accounted for\n    in PGA_AGGREGATE_LIMIT settings.There is unallocated memory of XX.XX GB for additional database allocation or other process utilization.\n    If you have not considered the HA component in your PGA settings, you don't have\n    enough unallocated memory (XX GB) available to increase PGA_AGGREGATE_LIMIT in\n    all databases to support the additional workload due to a node failure (XX.XX).\n\n\n3. On each node within the cluster, compare the SGA allocation against the HugePages allocation.\n\nThe expected output for each node would be:\n    PASS: Total SGA memory in running databases XX.XX GB is equal to\n    or within 3% of HugePages allocation of XX.XX GB; you do not appear to be\n    over-allocating HugePages.\n\nIf you are potentially wasting memory by allocating more HugePages than SGA is requesting, the output for the node would be:\n    WARN: Total SGA Allocation in running databases of XX.XX GB is less than and is not within 3% \n    of HugePages Allocation of XX.XX GB; you may be over-allocating HugePages. Please review.\n\nIf the SGA allocation is greater than the HugePages allocation, the USE_LARGE_PAGES database initialization parameter is not correctly configured:\n    FAIL: Total SGA memory in running databases XX.XX GB is greater than\n    HugePages allocation of XX.XX GB. You have not set the\n    USE_LARGE_PAGES database initialization parameter correctly for one or\n    more databases. Please review the output from the check \u201cCheck for\n    parameter use_large_pages\u201d.\n\nFor any failures encountered in the list of nodes, review the settings per database and per node and adjust the memory allocations as required.  Note that reducing SGA_TARGET settings may also require a reduction in the HugePages allocation.\n\n\n\nAfter making the appropriate changes, rerun this check as follows:\n\n# exachk -check 9AD95A48A4CAE029E040E50A1EC062A1,9AD94FEDF63F8296E040E50A1EC06A28,54D911C87C5A4C85E0530C98EB0A78D4,135F449E978C3B44E05313C0E50ABE53\n"}]}, {"id": "d1e530e0-3513-4088-bde3-7f5c3ef0ec83", "checkCategory": "RDBMS", "checkID": "9ECBA2152E92F6B1E040E50A1EC00DFB", "checkType": "SQL", "checkName": "Non-autoextensible data and temp files", "checkStatus": "FAIL", "status": "danger", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "danger", "statusLabel": "FAIL", "output": "AHF-2565: Some data or temp files are not autoextensible"}, "children": [{"attr": {"consoleOutput": "\n\nFILE_NAME\n-----------------------------------------------------\n/u01/app/oracle/product/21.0.0.0/dbhome_1/foobar.dbf\n/u01/app/oracle/product/21.0.0.0/dbhome_1/ahftest.dbf"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThe benefit of having \"AUTOEXTEND\" on is that applications may avoid out of space errors.\nThe impact of verifying that the \"AUTOEXTEND\" attribute is \"ON\" is minimal. The impact of setting \"AUTOEXTEND\" to \"ON\" varies depending upon if it is done during database creation, file addition to a tablespace, or added to an existing file.\n\n\n\nRisk:\n\nThe risk of running out of space in either the tablespace or diskgroup varies by application and cannot be quantified here. A tablespace that runs out of space will interfere with an application, and a diskgroup running out of space could impact the entire database as well as ASM operations (e.g., rebalance operations).\n\n\n\nAction / Repair:\n\nTo obtain a list of tablespaces that are not set to \"AUTOEXTEND\", enter the following sqlplus command logged into the database as sysdba:\nselect file_id, file_name, tablespace_name from dba_data_files where autoextensible &lt;&gt;'YES'\nunion\nselect file_id, file_name, tablespace_name from dba_temp_files where autoextensible &lt;&gt; 'YES'; \nThe output should be:\nno rows selected\nIf any rows are returned, investigate and correct the condition.\nNOTE: Configuring \"AUTOEXTEND\" to \"ON\" requires comparing space utilization growth projections at the tablespace level to space available in the diskgroups to permit the expected projected growth while retaining sufficient storage space in reserve to account for ASM rebalance operations that occur either as a result of planned operations or component failure. The resulting growth targets are implemented with the \"MAXSIZE\" attribute that should always be used in conjunction with the \"AUTOEXTEND\" attribute. The \"MAXSIZE\" settings should allow for projected growth while minimizing the prospect of depleting a disk group. The \"MAXSIZE\" settings will vary by customer and a blanket recommendation cannot be given here.\n\nNOTE: When configuring a file for \"AUTOEXTEND\" to \"ON\", the size specified for the \"NEXT\" attribute should cover all disks in the diskgroup to optimize balance. For example, with a 4MB AU size and 168 disks, the size of the \"NEXT\" attribute should be a multiple of 672M (4*168).\n\nAlso this misconfiguration can be repaired with repair functionality in AHF using \"ahfctl compliance -repair -check 9ECBA2152E92F6B1E040E50A1EC00DFB\".\nTo see the repair command, run \"ahfctl compliance -showrepair 9ECBA2152E92F6B1E040E50A1EC00DFB\"."}]}, {"id": "55fe7a6d-6139-49ef-a742-27ff7f5da21e", "checkCategory": "RDBMS", "checkID": "BDBF09D11651504EE053D198EB0A4E84", "checkType": "OS", "checkName": "Verify open PDBs to target_pdbs configured", "checkStatus": "FAIL", "status": "danger", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "danger", "statusLabel": "FAIL", "output": "AHF-6563: Database parameter target_pdbs is not set within best practice thresholds"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Verify open PDBs to target_pdbs configured\n\n\n\nFAILURE:Instance CDB11 parameter target_pdbs=232 is not set within best practice thresholds considering the number of open PDBs 1. For more information on target_pdbs, see MOS Note above in links section of recommendation."}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "danger", "statusLabel": "FAIL", "output": "AHF-6563: Database parameter target_pdbs is not set within best practice thresholds"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Verify open PDBs to target_pdbs configured\n\n\n\nFAILURE:Instance CDB12 parameter target_pdbs=232 is not set within best practice thresholds considering the number of open PDBs 1. For more information on target_pdbs, see MOS Note above in links section of recommendation."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThe target_pdbs parameter controls internal memory resources allocated for every open non-seed PDB. Setting it correctly ensures those resources are used efficiently providing high availability and performance.\n\nRisk:\n\nIf target_pdbs is too high compared to the number of open non-seed PDBs, it can impact RAC database instance and PDB level reconfigurations causing application brownouts.\n\nIf target_pdbs is too low compared to the number of open non-seed PDBs, it can cause shared pool memory depletion which in turn can generate errors and/or impact application performance.\n\nAction / Repair:\n\n1. Determine the correct setting for target_pdbs. The best practice is to have target_pdbs within 1 order of magnitude of the number of open non-seed PDBs (note open PDBs can vary by instance). So, for example, with 100 open PDBS open in a given RAC instance, an acceptable value for target_pdbs would be between 10 and 1000.   Target_pdbs should be set considering both the current configuration and future needs.   Note number of open PDBs will be impacted by Clusterware service failover especially in cases where application services are defined in one RAC instance or subset of RAC instances in the cluster.   Services may be relocated during unplanned outages (e.g. node/instance failure) and planned maintenance activities that require a RAC instance restart.\n\n2. Set target_pdbs in the spfile. If all database instances have the same number of open PDBs, then target_pdbs should be set with the sid='*' specification (ex: alter system set target_pdbs = &lt;# of pdbs&gt; scope = spfile sid='*';). If database instances have a different number of open PDBs, then target_pdbs should be set with the sid='&lt;instance name&gt;' specification for each affected instance (ex: alter system set target_pdbs = &lt;# of pdbs&gt; scope = spfile sid='&lt;instance name&gt;';\n\n3. Restart the affected RAC database instances so the new parameter setting takes effect.  This change can be done in a rolling manner to prevent application service level impact.. If you are not encountering the issues associated with an incorrect setting of the target_pdbs parameter, consider implementing this change during the next planned maintenance window to avoid having to take an extra outage.\n\n\nTo verify target_pdbs is set correctly, run a full Exachk report, or just the following check:\nexachk -check BDBF09D11651504EE053D198EB0A4E84\n\nExpected output:\nSUCCESS... parameter target_pdbs $targetpdb is set within best practice thresholds considering the number of open PDBs in this instance, $open_pdbs.\n\nUnexpected output needing attention/repair:\nFAILURE... parameter target_pdbs $targetpdb is not set within best practice thresholds considering the number of open PDBs in this instance, $open_pdbs.For more information on target_pdbs, see MOS Note: 2644243.1 - Performance Issues when using PDBs with Oracle RAC 19c and 18c (Doc ID 2644243.1) in link section\n"}, {"id": "e4b03d2e-79be-4de5-8048-589ca1d95a66", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=2644243.1", "text": "Note: 2644243.1 - Performance Issues when using PDBs with Oracle RAC 19c and 18c (Doc ID 2644243.1)"}]}]}, {"id": "bd88286e-d387-49f7-9a06-89d7c2aed312", "checkCategory": "RDBMS", "checkID": "21EF944E31B953CAE0530E98EB0A416B", "checkType": "OS", "checkName": "Verify one or more non-default AWR baselines were created", "checkStatus": "INFO", "status": "info", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "info", "statusLabel": "INFO", "output": "AHF-5649: One or more non-default AWR baselines should be created"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Verify one or more non-default AWR baselines were created\n\n\n\nNumber of non-default AWR baselines =  0"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nCapturing baselines when performance is good will help speed up the diagnosis of performance problems by permitting the comparison of a period of bad performance to a known good one. We recommend capturing representative AWR and ExaWatcher (or OSWatcher for Non-Exadata systems) baselines for each workload type as discussed below: \n\nRisk:\n\nPerformance analysis and diagnosis is much more difficult and time consuming when there is no data for a time when performance was acceptable.\n\nAction / Repair:\n\nTo use Enterprise Manager to create and manage baselines, see the Managing Baselines section under \"Resolving Performance Degradation Over Time\" of the Database 2Day + Performance Tuning Guide for more information on this procedure. For a command-line approach, see this procedure in the \"Managing the Automatic Workload Repository\" section of the Database Performance Tuning Guide. These procedures may vary for earlier versions of EM and the Oracle database.\n\nYou will now be able to refer to this baseline when creating a report using EM, and the baseline will not be purged by the AWR purging job. If you are generating a report using the awr*.sql scripts in $ORACLE_HOME/rdbms/admin (such as awrrpt.sql), then you will need to know the snapshots in the baseline before you run the script. You can find out which snapshots are in a baseline by running this query:\n\nset linesize 150\nset pagesize 10\ncol baseline_name form a30\n\nselect baseline_name, start_snap_id, to_char(start_snap_time,'mm/dd/yyyy hh24:mi') start_snap_time\n, end_snap_id, to_char(end_snap_time,'mm/dd/yyyy hh24:mi') end_snap_time\nfrom dba_hist_baseline\n\nBASELINE_NAME                  START_SNAP_ID START_SNAP_TIME  END_SNAP_ID END_SNAP_TIME\n------------------------------ ------------- ---------------- ----------- ----------------\nGood Performance - OLTP                 1439 02/15/2011 03:00        1440 02/15/2011 04:00\nBad Performance 1                       1446 02/15/2011 10:00        1447 02/15/2011 11:00\nSYSTEM_MOVING_WINDOW                    1451 02/15/2011 15:00        1640 02/23/2011 14:00 \n\nAs the owner userid of the Oracle home for a given database, and with the environment properly set to access that database, execute the following script once to see whether any non-default baselines were created (there is always a default system-generated baseline, SYSTEM_MOVING_WINDOW):\n\nunset NON_DEFAULT_BLINE_CNT;\nNON_DEFAULT_BLINE_CNT=$($ORACLE_HOME/bin/sqlplus -s \"/ as sysdba\" &lt;&lt;EOF\nset head off lines 80 feedback off timing off serveroutput on\nselect count(1) from dba_hist_baseline where baseline_name &lt;&gt; 'SYSTEM_MOVING_WINDOW';\nexit\nEOF);\nif [ $NON_DEFAULT_BLINE_CNT = \"0\" ]\nthen \n     echo -e \"FAILURE: No user-generated AWR baselines were created. Number of non-default baselines = \"$NON_DEFAULT_BLINE_CNT\"\"\nelse \n     echo -e \"SUCCESS: User-generated AWR baselines were created. Number of non-default baselines = \"$NON_DEFAULT_BLINE_CNT\"\"\nfi;\n\nThe expected output should be similar to:\n\nSUCCESS: User-generated AWR baselines were created. Number of non-default baselines = 4"}]}, {"id": "adf567e5-c5aa-495e-b4ca-c6a25bc54937", "checkCategory": "HOST", "checkID": "DD2218F08173398FE053D398EB0A0D11", "checkType": "OS", "checkName": "Active CPU counts", "checkStatus": "INFO", "status": "info", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "info", "statusLabel": "INFO", "output": "AHF-8188: CPU Capacity sizing data activity monitoring information"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - ACTIVE CPU COUNTS\n\n\n\n2024:08:29 - 92"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": ""}]}, {"id": "7e92ec80-bc54-4d43-af80-ca1a16303dc2", "checkCategory": "RDBMS", "checkID": "E60A5838BBE772AAE04312C0E50A297F", "checkType": "SQL", "checkName": "Database feature usage statistics", "checkStatus": "INFO", "status": "info", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "info", "statusLabel": "INFO", "output": "AHF-2508: Database feature usage statistics"}, "children": [{"attr": {"consoleOutput": "\n\nFeature Name                                           USED_COUNT INUSE FIRST_USAGE_DATE     LAST_USAGE_DATE\n------------------------------------------------------ ---------- ----- -------------------- --------------------\nACFS                                                           89 TRUE  16-DEC-22            24-AUG-24\nAdaptive Plans                                                 89 TRUE  16-DEC-22            24-AUG-24\nApprox QP                                                      86 TRUE  23-DEC-22            24-AUG-24\nAutomatic Maintenance - Optimizer Statistics Gathering         89 TRUE  16-DEC-22            24-AUG-24\nAutomatic Maintenance - SQL Tuning Advisor                     89 TRUE  16-DEC-22            24-AUG-24\nAutomatic Maintenance - Space Advisor                          89 TRUE  16-DEC-22            24-AUG-24\nAutomatic Reoptimization                                       89 TRUE  16-DEC-22            24-AUG-24\nAutomatic SGA Tuning                                           89 TRUE  16-DEC-22            24-AUG-24\nAutomatic SQL Execution Memory                                 89 TRUE  16-DEC-22            24-AUG-24\nAutomatic SQL Tuning Advisor                                   88 TRUE  23-DEC-22            24-AUG-24\nAutomatic Segment Space Management (user)                      59 TRUE  15-JUL-23            24-AUG-24\nAutomatic Storage Management                                   89 TRUE  16-DEC-22            24-AUG-24\nBigfile Tablespace                                             89 TRUE  16-DEC-22            24-AUG-24\nChange-Aware Incremental Backup                                89 TRUE  16-DEC-22            24-AUG-24\nCharacter Set                                                  89 TRUE  16-DEC-22            24-AUG-24\nDeferred Segment Creation                                      89 TRUE  16-DEC-22            24-AUG-24\nExadata                                                        89 TRUE  16-DEC-22            24-AUG-24\nFlex ASM                                                       89 TRUE  16-DEC-22            24-AUG-24\nInternode Parallel Execution                                   87 TRUE  16-DEC-22            24-AUG-24\nLocally Managed Tablespaces (user)                             89 TRUE  16-DEC-22            24-AUG-24\nMTTR Advisor                                                   89 TRUE  16-DEC-22            24-AUG-24\nOracle Multitenant                                             89 TRUE  16-DEC-22            24-AUG-24\nParallel SQL Query Execution                                   89 TRUE  16-DEC-22            24-AUG-24\nPartitioning (system)                                          89 TRUE  16-DEC-22            24-AUG-24\nQuality of Service Management                                  82 TRUE  04-FEB-23            24-AUG-24\nReal Application Clusters (RAC)                                89 TRUE  16-DEC-22            24-AUG-24\nReal-Time SQL Monitoring                                       89 TRUE  16-DEC-22            24-AUG-24\nRecovery Area                                                  89 TRUE  16-DEC-22            24-AUG-24\nResource Manager                                               88 TRUE  23-DEC-22            24-AUG-24\nSQL Plan Directive                                             89 TRUE  16-DEC-22            24-AUG-24\nSQL Tuning Set (system)                                        89 TRUE  16-DEC-22            24-AUG-24\nSecureFiles (system)                                           89 TRUE  16-DEC-22            24-AUG-24\nSecureFiles (user)                                             89 TRUE  16-DEC-22            24-AUG-24\nServer Parameter File                                          89 TRUE  16-DEC-22            24-AUG-24\nStatistics Advisor                                             88 TRUE  23-DEC-22            24-AUG-24\nTraditional Audit                                              89 TRUE  16-DEC-22            24-AUG-24\nUnified Audit                                                  89 TRUE  16-DEC-22            24-AUG-24"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": ""}]}, {"id": "14f286e7-94b2-47c8-910c-043bf3454f3b", "checkCategory": "HOST", "checkID": "018D274D1212689AE05313C0E50AB893", "checkType": "OS_OUT_CHECK", "checkName": "Validate key sysctl.conf parameters on database servers", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "sysctl.conf parameters on database servers are configured as recommended"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR VALIDATE KEY SYSCTL.CONF PARAMETERS ON DATABASE SERVERS\n\n\n\nSUCCESS:all sysctl.conf formatting checks succeeded"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "sysctl.conf parameters on database servers are configured as recommended"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR VALIDATE KEY SYSCTL.CONF PARAMETERS ON DATABASE SERVERS\n\n\n\nSUCCESS:all sysctl.conf formatting checks succeeded"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nKernel parameter settings in /etc/sysctl.conf are applied to the kernel automatically at boot time and manually via the sysctl utility at runtime. The semantics of each kernel parameter are known only to the kernel, so the sysctl utility passes all values directly to the kernel with minimal processing and validation. Invalid values can be misinterpreted by the kernel, leading to unexpected results. For certain key parameters, such invalid values can have an immediate and critical impact on the system. Invalid values stored in /etc/sysctl.conf at boot time can prevent the system from booting, making it difficult to identify and correct the problem. Validating the format of some key parameters periodically or after changes to sysctl.conf can prevent unexpected outages due to human error. \n\nRisk:\n\nApplying improperly formatted or incorrect value settings to kernel parameters can render a system unusable.\n\nAction / Repair:\n\nKey sysctl.conf parameters on database servers vary by Exadata software version level, hardware type, and whether or not virtualization is used. Exachk runs the appropriate checks based upon the discovered environment configuration. To validate Key sysctl.conf parameters on database servers, run Exachk and review the provided report.\n\nThe expected output in the Exachk report should be as follows:\n\nIn the \"Findings Passed\" summary section of the report, the overall result should be \"PASS\":\n\nPASS   OS Check   sysctl.conf parameters on database servers are configured as recommended   All Database Servers   View\n\nIn the \"View\" detail section of the report for each individual database server:\n\nStatus on randomadm01:\nPASS =&gt; sysctl.conf parameters on database servers are configured as recommended\n\nDATA FROM RANDOMADM01 FOR VALIDATE KEY SYSCTL.CONF PARAMETERS ON DATABASE SERVERS \n\nAll sysctl.conf formatting checks succeeded\n\nIf there are issues discovered, the overall result will be \"FAIL\" and more information will be listed in the \"View\" detail section. Investigate the reported issues for root cause and take appropriate corrective action.\n\nNOTE: If after corrective actions are completed, you wish to run just this review manually without a full Exachk run, as the \"root\" userid in the directory in which Exachk was installed, execute the following:\n\n    ./exachk -check 018D274D1212689AE05313C0E50AB893"}]}, {"id": "39d4b347-a800-434d-8ef2-9cbf9e1a4c18", "checkCategory": "RDBMS", "checkID": "AA8C83A023362C5EE040E50A1EC0146A", "checkType": "OS", "checkName": "Recovery and Create File Destinations", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Database DB_CREATE_FILE_DEST and DB_RECOVERY_FILE_DEST are in different diskgroups"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Recovery and Create File Destinations\n\n\n\ndb_recovery_file_dest = +RECOC1 db_create_file_dest = +DATAC1"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Database DB_CREATE_FILE_DEST and DB_RECOVERY_FILE_DEST are in different diskgroups"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Recovery and Create File Destinations\n\n\n\ndb_recovery_file_dest = +RECOC1 db_create_file_dest = +DATAC1"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nExperience and testing has shown that certain database initialization parameters should be set at specific values. These are the best practice values set at deployment time. By setting these database initialization parameters as recommended, known problems may be avoided and performance maximized. The parameters are common to all database instances. The impact of setting these parameters is minimal. The performance related settings provide guidance to maintain highest stability without sacrificing performance. Changing the default performance settings can be done after careful performance evaluation and clear understanding of the performance impact.\n\n\nRisk:\n\nIf the database initialization parameters are not set as recommended, a variety of issues may be encountered, depending upon which initialization parameter is not set as recommended, and the actual set value.\n\n\n\nAction / Repair:\n\n\"DATA\" diskgroup is recommended for db_create_file_dest, but may be set to any valid diskgroup that is not the diskgroup specified by db_recovery_file_dest.\n\n\"RECO\" diskgroup is recommended for db_recovery_file_dest, but may be set to any valid diskgroup that is not the diskgroup specified by db_create_file_dest. \n"}]}, {"id": "6b9a4204-6a0b-4866-84e0-e477c2584b90", "checkCategory": "HOST", "checkID": "022D2A2DE267D8D7E0639912F50AB908", "checkType": "OS_OUT_CHECK", "checkName": "Verify Oracle High Availability Services Automatic Startup Configuration", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Oracle High Availability Services autostart is enabled"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR VERIFY ORACLE HIGH AVAILABILITY SERVICES AUTOMATIC STARTUP CONFIGURATION\n\n\n\nSUCCESS:Oracle High Availability Services autostart is enabled."}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Oracle High Availability Services autostart is enabled"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR VERIFY ORACLE HIGH AVAILABILITY SERVICES AUTOMATIC STARTUP CONFIGURATION\n\n\n\nSUCCESS:Oracle High Availability Services autostart is enabled."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThis check checks if Oracle High Availability Services autostart is enabled.\n\n\nRisk:\n\nFor Oracle Exadata Database Service, quarterly infrastructure maintenance will fail if Oracle High Availability Services autostart is disabled.\n\nFor on-premise Exadata systems, the cluster will not start automatically in case of a restart of a database server if Oracle High Availability Services autostart is disabled.\n\nAction / Repair:\n\nRun the command \"crsctl enable crs\" to enable Oracle High Availability Services autostart."}]}, {"id": "fe75cd2a-4b69-4861-807e-1c9c1fb77ec5", "checkCategory": "RDBMS", "checkID": "02857D4DD0834DB8E0639A12F50A4EF0", "checkType": "OS", "checkName": "Verify health of data dictionary for multi tenant database", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Database dictionary consistency check for multitenant database was successful"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Verify health of data dictionary for multi tenant database\n\n"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nHelps you identify database dictionary inconsistencies that are manifested in unexpected entries in the RDBMS dictionary tables or invalid references between dictionary tables. \n\n\n\nRisk:\n\nDatabase dictionary inconsistencies can lead to failures and impact life cycle management of the database.\nInconsistencies reported with FAIL or CRITICAL may be exposed with internal ORA-600 errors.\n\nAction / Repair:\n\nReview the results provided in the report output for guidance on the issue observed and actions recommended. \nIn most cases guided remediation is provided to resolve the problem.\nData dictionary health can be verified using script provided in MOS Note : 136697.1. \n\nTo rerun this check along use the following:\nahfctl compliance -check 02857D4DD0834DB8E0639A12F50A4EF0"}, {"id": "d3a1d9fa-b525-439f-bc6d-64c539bf57c2", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=136697.1", "text": "Note: 136697.1 - hcheck.sql - Script to Check Data Dictionary for Known Problems"}]}]}, {"id": "35cfb300-63a6-49ad-8560-f41cbc35d5b3", "checkCategory": "RDBMS", "checkID": "1005EE0B4A44119CE05312C0E50AE55B", "checkType": "OS", "checkName": "Verify bundle patch version installed matches bundle patch version registered in database", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "The bundle patch version installed matches the bundle patch version registered in the database"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Verify bundle patch version installed matches bundle patch version registered in database\n\n\n\nBundle patch installed in software home (OPatch):34160444 21.7.0.0.220719\nBundle patch installed in database registry     :34160444 21.7.0.0.220719"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "The bundle patch version installed matches the bundle patch version registered in the database"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Verify bundle patch version installed matches bundle patch version registered in database\n\n\n\nBundle patch installed in software home (OPatch):34160444 21.7.0.0.220719\nBundle patch installed in database registry     :34160444 21.7.0.0.220719"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nCrosschecking the software bundle patch version installed with the bundle patch registered in the database to make sure they match ensures software correctness and stability. If a bundle patch is being installed in a Data Guard configuration in a standby-first manner where the SQL portion of the bundle patch is not installed inside the database until the primary and all standby software homes have the same version installed, then this crosscheck is expected to fail until both the binary and SQL portion of the bundle patch application is fully installed.\n\nRisk:\n\nIncomplete bug fixes, software instability,unexpected behavior. For cloud environments, the dbaas tooling lifecycle management operations like patching, upgrade, Data Guard, etc. may fail.\n\nAction / Repair:\n\nTo verify that the bundle patch version installed matches bundle patch version registered in database, as the oracle home owner for the primary database, and with ORACLE_SID and ORACLE_HOME properly set, execute the following command:\n\ne.g:\n- Run opatch as below to get applied patch details  \n  $ORACLE_HOME/OPatch/opatch lspatches 2&gt;/dev/null|grep -iwv javavm|grep -wi database\n        34133642;Database Release Update : 19.16.0.0.220719 (34133642)\n\n- Run database SQL below to verify patch information in database  \nselect PATCH_ID,ACTION, STATUS from (select * from dba_registry_sqlpatch where PATCH_ID = &lt;&lt;OPactch Patchid&gt;&gt; order by action_time desc) where rownum=1 ; \n\nPATCH_ID         ACTION         STATUS\n--------------------------------------------------------------------------\n34133642           APPLY         SUCCESS\n\nThe output should be similar to:\n\nSUCCESS: The bundle patch version installed matches the bundle patch version registered in the database \nFAILURE:    The bundle patch version installed does not match the bundle patch version registered in the database\n\nIf FAILURE is reported, then investigate and correct the discrepancy. "}]}, {"id": "637c60a3-800b-4520-ba4d-3434432fa38c", "checkCategory": "ASM", "checkID": "19D74D0A1C99F8BBE0530E98EB0A884C", "checkType": "OS", "checkName": "Verify Hidden ASM Initialization Parameter Usage", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "Hidden ASM Initialization Parameter usage is correct"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY HIDDEN ASM INITIALIZATION PARAMETER USAGE\n\n\n\n\nFor this version of ASM, 21.7.0.0.220719, no underscore parameters should be set\nTest Passed. No ASM underscore parmaters are set"}}]}, {"attr": {"target": "scaqal03adm06vm01:+ASM2", "status": "success", "statusLabel": "PASS", "output": "Hidden ASM Initialization Parameter usage is correct"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - VERIFY HIDDEN ASM INITIALIZATION PARAMETER USAGE\n\n\n\n\nFor this version of ASM, 21.7.0.0.220719, no underscore parameters should be set\nTest Passed. No ASM underscore parmaters are set"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nHidden database initialization parameters are typically set as a workaround to solve a specific problem, and should be removed once a system has been upgraded to a version level that contains the fix for the specific problem. Often they are not removed during the upgrade process to the version level that contains the correct fix. Verifying the hidden database initialization parameter usage helps avoid hidden parameters being used any longer than necessary.\n\nNOTES:\n\n1) For additional ZFS based backup configuration information, please see: Oracle ZFS Storage: FAQ: Exadata RMAN Backup with The Oracle ZFS Storage Appliance (Doc ID 1354980.1)\n\n2) This best practice check does not include any application specific hidden parameters. If an application in use requires hidden parameters that are failed by this best practice, refer to the proper documentation for the application version in use. If the extra hidden parameters are correct, then ignore the failures reported for those specific parameters.\n\nFor Oracle E-Business Suite, please see: Database Initialization Parameters for Oracle E-Business Suite Release 12 (Doc ID 396009.1)\n\nFor Siebel CRM Application, please see: Performance Tuning Guidelines for Siebel CRM Application on Oracle Database (Doc ID 2077227.2)\n\nRisk:\n\nUse of hidden ASM or database initialization parameters not recommended by Oracle development in an Exadata environment can cause instability, performance problems, corruptions, and crashes.\n\nAction / Repair:\n\n To verify the hidden database initialization parameter usage in each ASM and database instance, execute the following sqlplus command as the owner of the respective home with the environment properly set to access the instance:\n\nselect name,value from v$parameter where substr(name,1,1)='_';\n\n    NOTE: v$parameter only contains hidden parameters that have been changed from the default, which are the ones of interest here.\n\nThe expected output should be a list of any hidden parameters in use that have been changed from the default value, similar to:\n\n_enable_NUMA_support  FALSE\n\nThere should be no hidden parameters in use that are not shown in the \"Generally Acceptable Hidden Parameters Table\":\n\nGenerally Acceptable Hidden Parameters Table\nParameter\nName \tValue \tOracle\nVersion \tExadata\nVersion \tInstance\nType \tNotes\n_file_size_increase_increment \t2143289344 \t&lt;= 11.2.0.3 BP11 \tALL \tDatabase \tEnables more performant rman backup allocation sizes.\n_enable_NUMA_support \tSet _enable_NUMA_support=TRUE for all hardware generation 8-socket database servers (Note - applies to non-OVM only - OVM is not supported on 8-socket servers).\n\nSet _enable_NUMA_support=TRUE for X5 and later 2-socket database servers deployed as non-OVM.\n\nIn all other cases do not explicitly set _enable_NUMA_support. \t&lt;12.1.0.2.6 \tALL \tDatabase \tFor any Exadata system using Database 12.1.0.2.6 or higher, do not explicitly set _enable_NUMA_support (includes all hardware generations, 2-socket, 8-socket, non-OVM, and OVM). _enable_NUMA_support setting is automatically configured by the database.\n\nFor any Exadata system using Database 12.1.0.2.5 or lower, reference the recommended setting in the Value column of this row.\n_asm_resyncckpt \t0 \t12.1.0.1 ONLY \tALL \tASM \tTurns off resync checkpointing\n_smm_auto_max_io_size \t1024 \t\n\n12.1 and lower\n\tALL \tDatabase \tThis permits 1MB IOs for hash joins that spill to disk, which can increase performance up to 40% due to increased throughput. These performance increases can prevent the need to move TEMP to flash.\n\nInternal only note: this will no longer be needed when bug 20925115 is fixed.\n_parallel_adaptive_max_users \t2 \t12.1 and higher \tALL \tDatabase \tCheck to ensure not more than the recommended value. Setting this higher than this recommended value can deplete memory and impact performance.*\n\nParameter PARALLEL_MAX_SERVERS is evaluated based on the below calculation method:\nparallel_threads_per_cpu*cpu_count*concurrent_parallel_users*5\n\nParameter PARALLEL_SERVERS_TARGET is evaluated based on the below calculation method:\nparallel_threads_per_cpu*cpu_count*concurrent_parallel_users*2\n\n_PARALLEL_ADAPTIVE_MAX_USERS provides the value of concurrent_parallel_users in the calculation. The value of this parameter is set to 4 in most cases which would result in a higher than recommended maximum number of parallel servers, therefore the recommended value is 2.\n\nPARALLEL_MAX_SERVERS would be calculated as below assuming cpu_count is set to all available CPUs:\nX2-2: 1 * 24 * 2 * 5 = 240\nX6-2: 1 * 88 * 2 * 5 = 880\nX2-8: 1 * 128 * 2 * 5 = 1280\nX6-8: 1 * 288 * 2 * 5 = 2880\n_assm_segment_repair_bg \tFALSE \t12.2 and higher \tALL \tDatabase \twork-around for bug 23734075\n_asm_max_connected_clients \tDynamically changes \t12.2. and 18.1 ONLY \tALL \tASM \tUsed internally; Removed in release 19c\n_backup_disk_bufcnt \t64 \t12.1 and lower \tALL \tDatabase \tOnly when ZFS based backups are in use (NOTE: 1)\n_backup_disk_bufsz \t1048576 \t12.1 and lower \tALL \tDatabase \tOnly when ZFS based backups are in use (NOTE: 1)\n_backup_file_bufcnt \t64 \t12.1 and lower \tALL \tDatabase \tOnly when ZFS based backups are in use (NOTE: 1)\n_backup_file_bufsz \t1048576 \t12.1 and lower \tALL \tDatabase \tOnly when ZFS based backups are in use (NOTE: 1) "}]}, {"id": "e3f2a603-9f17-4a21-bb8a-0635d6fba85c", "checkCategory": "RDBMS", "checkID": "18B839DC1B43E5E0E0530B98EB0AAB97", "checkType": "SQL_PARAM", "checkName": "Check for parameter db_block_size", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Database parameter DB_BLOCK_SIZE is set to the recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Database parameter DB_BLOCK_SIZE is set to the recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThe default and generally recommended DB_BLOCK_SIZE for Oracle databases is 8192(bytes). \n\nA different block size may be specified at database creation if it is proven by thorough testing to be more efficient for a given database design and application set.\n\n\nRisk:\n\nSub-optimal performance.\n\nAction / Repair:\n\nDB_BLOCK_SIZE cannot be modified after database creation.  If it is desired to change the DB_BLOCK_SIZE from it's current value, the database will have to be rebuilt."}]}, {"id": "45e74f96-76de-4b31-8090-7676ffe8abe7", "checkCategory": "RDBMS", "checkID": "A98AD732FD4FF308E040E50A1EC01B2C", "checkType": "SQL_PARAM", "checkName": "Check for parameter open_cursors", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Database parameter OPEN_CURSORS is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nExperience and testing has shown that certain database initialization parameters should be set at specific values. These are the best practice values set at deployment time. By setting these database initialization parameters as recommended, known problems may be avoided and performance maximized.\nThe parameters are common to all database instances. The impact of setting these parameters is minimal.\nThe performance related settings provide guidance to maintain highest stability without sacrificing performance. Changing the default performance settings can be done after careful performance evaluation and clear understanding of the performance impact.\n\nRisk:\n\nIf the database initialization parameters are not set as recommended, a variety of issues may be encountered, depending upon which initialization parameter is not set as recommended, and the actual set value.\n\n\n\nAction / Repair:\n\nOPEN_CURSORS &gt;= 300.  Initial deployment database uses 1000"}]}, {"id": "fc71cedb-9f11-44a4-a296-e732c9d9b7e7", "checkCategory": "ASM", "checkID": "29DCE334FDD680CEE0530B98EB0A52A3", "checkType": "OS", "checkName": "Verify there are no failed diskgroup rebalance operations", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "There are no failed diskgroup rebalance operations"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY THERE ARE NO FAILED DISKGROUP REBALANCE OPERATIONS\n\n\n\nSUCCESS:There were no failed rebalance operations found."}}]}, {"attr": {"target": "scaqal03adm06vm01:+ASM2", "status": "success", "statusLabel": "PASS", "output": "There are no failed diskgroup rebalance operations"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - VERIFY THERE ARE NO FAILED DISKGROUP REBALANCE OPERATIONS\n\n\n\nSUCCESS:There were no failed rebalance operations found."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nVerifying there are no failed diskgroup rebalance operations helps to ensure that all diskgroups have the chosen redundancy. The impact of correcting any failed diskgroup rebalance operations depends upon the error responsible for the failure\n\nRisk:\n\nA failed diskgroup rebalance operation could leave the diskgroup without the proper redundancy, exposing the diskgroup to a loss of data if another partner disk fails.\n\nAction / Repair:\n\nTo verify there are no failed diskgroup rebalance operations, as the owner of the grid home and with the environment set to access one ASM instance, execute the following command set:\n\n#!/bin/bash\nunset REBALANCE_ERROR;\nREBALANCE_ERROR=`$ORACLE_HOME/bin/sqlplus -s \"/ as sysasm\" &lt;&lt; EOF\nset head off pagesize 0 timing off serveroutput on feedback off\nselect group_number,error_code from gv$asm_operation where error_code is not null and upper(state) not in ('DONE','WAIT','RUN');\nexit\nEOF`;\nif [ -z `echo $REBALANCE_ERROR | tr -d ' \\t\\n\\r\\f'` ]\nthen\n  echo -e \"\\nSUCCESS: There were no failed rebalance operations found.\\n\"\nelse\n  echo -e \"\\nFAILURE: Failed rebalance operations were found:\\n\"\n  echo -e \"REBALANCE_ERROR:\\n$REBALANCE_ERROR\\n\"\nfi;\n\nThe output should be similar to:\n\nSUCCESS: There were no failed rebalance operations found.\n\nIf the output is not \"SUCCESS...\", investigate the reported errors and correct appropriately. "}]}, {"id": "74b917c9-b9a1-4303-aa51-5986343eff23", "checkCategory": "HOST", "checkID": "339FE456FBDC3549E0530D98EB0AD21F", "checkType": "OS", "checkName": "Verify database server quorum disks configuration", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "Quorum disks are configured as recommended"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY DATABASE SERVER QUORUM DISKS CONFIGURATION\n\n\n\nHighRedCount_name:DATAC1 RECOC1 HighRedCount:2\nVoting File redundancy check Passed\n\n##  STATE    File Universal Id                File Name Disk group\n--  -----    -----------------                --------- ---------\n1. ONLINE   3ed80c17d6594f76bfa8a5f8ff412009 (o/192.168.11.134;192.168.11.135/DATAC1_CD_05_scaqal03celadm07) [DATAC1]\n2. ONLINE   cc00f5e903664f21bf0d0fd74d88335d (o/192.168.11.136;192.168.11.137/DATAC1_CD_04_scaqal03celadm08) [DATAC1]\n3. ONLINE   45df7cf661cf4f26bf8b6094f2f3796e (o/192.168.11.138;192.168.11.139/DATAC1_CD_04_scaqal03celadm09) [DATAC1]\n4. ONLINE   6f7718c0dff44f37bf7245560e6e6bc8 (/dev/exadata_quorum/QD_DATAC1_SCAQAL03ADM06VM01) [DATAC1]\n5. ONLINE   1b50e812d2644f93bf3fe5f623977382 (/dev/exadata_quorum/QD_DATAC1_SCAQAL03ADM05VM01) [DATAC1]\nLocated 5 voting disk(s)."}}]}, {"attr": {"target": "scaqal03adm06vm01:+ASM2", "status": "success", "statusLabel": "PASS", "output": "Quorum disks are configured as recommended"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - VERIFY DATABASE SERVER QUORUM DISKS CONFIGURATION\n\n\n\nHighRedCount_name:DATAC1 RECOC1 HighRedCount:2\nVoting File redundancy check Passed\n\n##  STATE    File Universal Id                File Name Disk group\n--  -----    -----------------                --------- ---------\n1. ONLINE   3ed80c17d6594f76bfa8a5f8ff412009 (o/192.168.11.134;192.168.11.135/DATAC1_CD_05_scaqal03celadm07) [DATAC1]\n2. ONLINE   cc00f5e903664f21bf0d0fd74d88335d (o/192.168.11.136;192.168.11.137/DATAC1_CD_04_scaqal03celadm08) [DATAC1]\n3. ONLINE   45df7cf661cf4f26bf8b6094f2f3796e (o/192.168.11.138;192.168.11.139/DATAC1_CD_04_scaqal03celadm09) [DATAC1]\n4. ONLINE   6f7718c0dff44f37bf7245560e6e6bc8 (/dev/exadata_quorum/QD_DATAC1_SCAQAL03ADM06VM01) [DATAC1]\n5. ONLINE   1b50e812d2644f93bf3fe5f623977382 (/dev/exadata_quorum/QD_DATAC1_SCAQAL03ADM05VM01) [DATAC1]\nLocated 5 voting disk(s)."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nQuorum disks should exist for ALL high redundancy disk groups with less than five failure groups and ALL normal redundancy disk groups with less than three failure groups.  This configuration has the following benefits:\n\n    Protects the Grid Infrastructure (voting disks) and ASM metadata (PST) in the event of a double partner storage failure or an event involving Exadata storage server being offline due to planned maintenance and a subsequent partner storage failure.\n    Expanding diskgroups to use a higher number of failgroups and the subsequent shrinking to use less than five failgroups, will avoid the diskgroup dismount during planned or unplanned maintenance. This is due to changes introduced in bug 26199003\n\n    NOTE: This check will only pass if the following are all true:\n    1) /opt/oracle.SupportTools/quorumdiskmgr exists on the db nodes\n    2) The GI BP version is above 12.1.0.2.160119\n    3) At least one HIGH redundancy diskgroup exists\n    4) Quorum disks on DB nodes are implemented when there are less than 5 storage cells in the high redundancy disk group.\n    5) All HIGH redundancy diskgroups contain quorum disks\n    6) If the number of cells is greater than or equal to 5, all the voting files are in the cells\n    7) If normal diskgroups configured using XT storage cells with less than 3 failgroups and Quorum disks are implemented.\n\n    NOTE: sparse diskgroups cannot contain quorum disks and are excluded from this analysis.\n\n    NOTE WELL: For a complete picture, please also reference: Verify all voting disks are online\n\nRisk:\n\nWithout this feature, voting files get stored in a normal redundancy diskgroup on Exadata racks with less than 5 storage servers which makes the Grid Infrastructure vulnerable to a cluster outage if multiple vote disks are inaccessible.\nDiskgroups used on a flex configuration (expanding/shrinking) are exposed to be dismounted during planned or unplanned maintenance.\n\nAction / Repair:\n\nTo verify the database server quorum disks configuration, run Exachk and review the provided report.\n\nThe expected output in the Exachk report should be as follows:\n\nThe overall result should be \"PASS\" or \"WARNING\" or \"FAIL\":\n\nIn the \"View\" detail section of the report for this check the expected output should be similar to:\n\n\nVoting File redundancy check Passed\n\n##  STATE    File Universal Id                File Name Disk group\n--  -----    -----------------                --------- ---------\n 1. ONLINE   11ccca4125424fb1bfec2180a22e24cb (/dev/exadata_quorum/QD_DATAC1_SCAQAE05ADM01VM01) [DATAC1]\n 2. ONLINE   5da7f33dc5f64f64bfb2b756787a6b48 (o/192.168.221.137;192.168.221.138/DATAC1_FD_05_scaqae05celadm03) [DATAC1]\n 3. ONLINE   1eefa3ec1ebc4fd3bf8933ca0c587e13 (o/192.168.221.133;192.168.221.134/DATAC1_FD_04_scaqae05celadm01) [DATAC1]\n 4. ONLINE   6d65ea6de3eb4fcebf3e7984d62d51b9 (/dev/exadata_quorum/QD_DATAC1_SCAQAE05ADM02VM01) [DATAC1]\n 5. ONLINE   de0d94da4fc94f57bf2a12dbc46a3603 (o/192.168.221.135;192.168.221.136/DATAC1_FD_04_scaqae05celadm02) [DATAC1]\nLocated 5 voting disk(s).\n\nIn the \"View\" detail section of the report for this check a \"WARNING\" example will be similar to:\n\n\nA database server quorum disk configuration is not applicable to this system because no high redundancy diskgroups were found.\nHigh redundancy is a MAA best practice.  \nFor details, see http://www.oracle.com/technetwork/database/features/availability/exadata-maa-131903.pdf\n\n##  STATE    File Universal Id                File Name Disk group\n--  -----    -----------------                --------- ---------\n 1. ONLINE   5da7f33dc5f64f64bfb43434787a6b48 (o/192.168.221.137;192.168.221.138/RECOC1_FD_05_scaqae05celadm03) [RECOC1]\n 2. ONLINE   1eefa3ec1dffe4d3bf8933ca0c587e13 (o/192.168.221.133;192.168.221.134/RECOC1_FD_04_scaqae05celadm01) [RECOC1]\n 3. ONLINE   de0d94da4fc94f52332dr2dbc46a3603 (o/192.168.221.135;192.168.221.136/RECOC1_FD_04_scaqae05celadm02) [RECOC1]\nLocated 3 voting disk(s).\n\n\nIn the \nView\n detail section of the report for this check, below are examples for a \nFAILURE\n case:\n\nMissing Quorum Disks for High Redundancy diskgroup\n\nA database server quorum disk configuration is applicable to this system.\nBut an optimal Quorum disk setup is not found as seen below.\nAn optimal quorum disk setup should include 2 quorum disks along with 5 voting files, with 2 of the voting files placed on the 2 quorum disks and the 3 remaining voting files on 3 different cells.\n\n##  STATE    File Universal Id                File Name Disk group\n--  -----    -----------------                --------- ---------\n 1. ONLINE   5da7f33dc5f64f64bfb43434787a6b48 (o/192.168.221.137;192.168.221.138/RECOC1_FD_05_scaqae05celadm03) [RECOC1]\n 2. ONLINE   1eefa3ec1dffe4d3bf8933ca0c587e13 (o/192.168.221.133;192.168.221.134/RECOC1_FD_04_scaqae05celadm01) [RECOC1]\n 3. ONLINE   de0d94da4fc94f52332dr2dbc46a3603 (o/192.168.221.135;192.168.221.136/RECOC1_FD_04_scaqae05celadm02) [RECOC1]\nLocated 3 voting disk(s).\n\nFollow the steps provided to add database server quorum disks in the \"Adding Quorum Disks to Database Servers\" section of the \"Oracle Exadata Database Machine Maintenance Guide\"\n\n    \nQuorum Disks configured for High Redundancy diskgroups having 5 or more storage cells\n\nQuorum Disks are still configured but not required: /dev/exadata_quorum/QD_RECOC1_SCAQAH01DV0101 /dev/exadata_quorum/QD_RECOC1_SCAQAH01DV0201 /dev/exadata_quorum/QD_RECOC1_SCAQAH01DV0301 \nProceed to drop them from ASM (if needed) then from the OS configuration through quorumdiskmgr\n\n\n\n\nNOTE: If after corrective actions are completed, you wish to run this one check without a full Exachk run execute the following command as the \"root\" userid in the directory in which Exachk was installed:\n\n    ./exachk -check 339FE456FBDC3549E0530D98EB0AD21F\n\n"}, {"id": "12c95246-0d4f-4148-bc92-529c824660f2", "title": "Links", "links": [{"hyperlink": "http://docs.oracle.com/cd/E50790_01/doc/doc.121/e51951/db_server.htm#CCHDJDEI", "text": "Managing Oracle VM User Domains"}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= &id=888828.1", "text": "Note: 888828.1 - \tDatabase Machine and Exadata Storage Server 11g Release 2 (11.2) Supported Versions"}, {"hyperlink": "https://www.oracle.com/technetwork/database/exadata/maa-exadata-asm-cloud-3656632.pdf", "text": "Oracle ASM Considerations for Exadata Deployments: On-premises and Cloud"}]}]}, {"id": "f5621362-a1a7-4a1a-84af-0846e8d9843d", "checkCategory": "ASM", "checkID": "41FFD6C322D697A8E0530C98EB0A3D96", "checkType": "SQL_PARAM", "checkName": "Check for parameter sga_target", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "ASM parameter SGA_TARGET is set according to recommended value."}, "children": [{"attr": {"consoleOutput": "\n+ASM1.allow_group_access_to_sga = FALSE\n+ASM2.allow_group_access_to_sga = FALSE\n+ASM1.asm_diskgroups = RECOC1\n+ASM2.asm_diskgroups = RECOC1\n+ASM1.asm_diskstring = o/*/DATAC1_*, o/*/RECOC1_*, /dev/exadata_quorum/*\n+ASM2.asm_diskstring = o/*/DATAC1_*, o/*/RECOC1_*, /dev/exadata_quorum/*\n+ASM1.asm_power_limit = 4\n+ASM2.asm_power_limit = 4\n+ASM1.asm_preferred_read_failure_groups =\n+ASM2.asm_preferred_read_failure_groups =\n+ASM1.audit_file_dest = /u01/app/21.0.0.0/grid/rdbms/audit\n+ASM2.audit_file_dest = /u01/app/21.0.0.0/grid/rdbms/audit\n+ASM1.audit_sys_operations = TRUE\n+ASM2.audit_sys_operations = TRUE\n+ASM1.audit_syslog_level = LOCAL0.INFO\n+ASM2.audit_syslog_level = LOCAL0.INFO\n+ASM1.audit_trail = NONE\n+ASM2.audit_trail = NONE\n+ASM1.background_core_dump = partial\n+ASM2.background_core_dump = partial\n+ASM1.background_dump_dest = /u01/app/21.0.0.0/grid/rdbms/log\n+ASM2.background_dump_dest = /u01/app/21.0.0.0/grid/rdbms/log\n+ASM1.cdb_cluster = FALSE\n+ASM2.cdb_cluster = FALSE\n+ASM1.cluster_database = TRUE\n+ASM2.cluster_database = TRUE\n+ASM1.cluster_interconnects = 192.168.11.128:192.168.11.129\n+ASM2.cluster_interconnects = 192.168.11.132:192.168.11.133\n+ASM1.connection_brokers = ((TYPE=DEDICATED)(BROKERS=1)), ((TYPE=EMON)(BROKERS=1))\n+ASM2.connection_brokers = ((TYPE=DEDICATED)(BROKERS=1)), ((TYPE=EMON)(BROKERS=1))\n+ASM1.core_dump_dest = /u01/app/oracle/diag/asm/+asm/+ASM1/cdump\n+ASM2.core_dump_dest = /u01/app/oracle/diag/asm/+asm/+ASM2/cdump\n+ASM1.cpu_count = 4\n+ASM2.cpu_count = 4\n+ASM1.db_cache_size = 0\n+ASM2.db_cache_size = 0\n+ASM1.db_ultra_safe = OFF\n+ASM2.db_ultra_safe = OFF\n+ASM1.db_unique_name = +ASM\n+ASM2.db_unique_name = +ASM\n+ASM1.diagnostic_dest = /u01/app/oracle\n+ASM2.diagnostic_dest = /u01/app/oracle\n+ASM1.diagnostics_control = IGNORE\n+ASM2.diagnostics_control = IGNORE\n+ASM1.event =\n+ASM2.event =\n+ASM1.file_mapping = FALSE\n+ASM2.file_mapping = FALSE\n+ASM1.filesystemio_options = none\n+ASM2.filesystemio_options = none\n+ASM1.forward_listener =\n+ASM2.forward_listener =\n+ASM1.heartbeat_batch_size = 5\n+ASM2.heartbeat_batch_size = 5\n+ASM1.ifile =\n+ASM2.ifile =\n+ASM1.instance_abort_delay_time = 0\n+ASM2.instance_abort_delay_time = 0\n+ASM1.instance_name = +ASM1\n+ASM2.instance_name = +ASM2\n+ASM1.instance_number = 1\n+ASM2.instance_number = 2\n+ASM1.instance_type = ASM\n+ASM2.instance_type = ASM\n+ASM1.large_pool_size = 16777216\n+ASM2.large_pool_size = 16777216\n+ASM1.ldap_directory_sysauth = no\n+ASM2.ldap_directory_sysauth = no\n+ASM1.listener_networks = ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (LOCAL_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr)(REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\"))\n+ASM2.listener_networks = ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (LOCAL_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr)(REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\"))\n+ASM1.local_listener =  (ADDRESS=(PROTOCOL=TCP)(HOST=10.214.209.68)(PORT=1521))\n+ASM2.local_listener =  (ADDRESS=(PROTOCOL=TCP)(HOST=10.214.209.69)(PORT=1521))\n+ASM1.lock_name_space =\n+ASM2.lock_name_space =\n+ASM1.lock_sga = FALSE\n+ASM2.lock_sga = FALSE\n+ASM1.max_dump_file_size = unlimited\n+ASM2.max_dump_file_size = unlimited\n+ASM1.memoptimize_pool_size = 0\n+ASM2.memoptimize_pool_size = 0\n+ASM1.memory_max_target = 0\n+ASM2.memory_max_target = 0\n+ASM1.memory_target = 0\n+ASM2.memory_target = 0\n+ASM1.nls_calendar =\n+ASM2.nls_calendar =\n+ASM1.nls_comp = BINARY\n+ASM2.nls_comp = BINARY\n+ASM1.nls_currency =\n+ASM2.nls_currency =\n+ASM1.nls_date_format =\n+ASM2.nls_date_format =\n+ASM1.nls_date_language =\n+ASM2.nls_date_language =\n+ASM1.nls_dual_currency =\n+ASM2.nls_dual_currency =\n+ASM1.nls_iso_currency =\n+ASM2.nls_iso_currency =\n+ASM1.nls_language = AMERICAN\n+ASM2.nls_language = AMERICAN"}}]}, {"attr": {"target": "scaqal03adm06vm01:+ASM2", "status": "success", "statusLabel": "PASS", "output": "ASM parameter SGA_TARGET is set according to recommended value."}, "children": [{"attr": {"consoleOutput": "\n+ASM1.allow_group_access_to_sga = FALSE\n+ASM2.allow_group_access_to_sga = FALSE\n+ASM1.asm_diskgroups = RECOC1\n+ASM2.asm_diskgroups = RECOC1\n+ASM1.asm_diskstring = o/*/DATAC1_*, o/*/RECOC1_*, /dev/exadata_quorum/*\n+ASM2.asm_diskstring = o/*/DATAC1_*, o/*/RECOC1_*, /dev/exadata_quorum/*\n+ASM1.asm_power_limit = 4\n+ASM2.asm_power_limit = 4\n+ASM1.asm_preferred_read_failure_groups =\n+ASM2.asm_preferred_read_failure_groups =\n+ASM1.audit_file_dest = /u01/app/21.0.0.0/grid/rdbms/audit\n+ASM2.audit_file_dest = /u01/app/21.0.0.0/grid/rdbms/audit\n+ASM1.audit_sys_operations = TRUE\n+ASM2.audit_sys_operations = TRUE\n+ASM1.audit_syslog_level = LOCAL0.INFO\n+ASM2.audit_syslog_level = LOCAL0.INFO\n+ASM1.audit_trail = NONE\n+ASM2.audit_trail = NONE\n+ASM1.background_core_dump = partial\n+ASM2.background_core_dump = partial\n+ASM1.background_dump_dest = /u01/app/21.0.0.0/grid/rdbms/log\n+ASM2.background_dump_dest = /u01/app/21.0.0.0/grid/rdbms/log\n+ASM1.cdb_cluster = FALSE\n+ASM2.cdb_cluster = FALSE\n+ASM1.cluster_database = TRUE\n+ASM2.cluster_database = TRUE\n+ASM1.cluster_interconnects = 192.168.11.128:192.168.11.129\n+ASM2.cluster_interconnects = 192.168.11.132:192.168.11.133\n+ASM1.connection_brokers = ((TYPE=DEDICATED)(BROKERS=1)), ((TYPE=EMON)(BROKERS=1))\n+ASM2.connection_brokers = ((TYPE=DEDICATED)(BROKERS=1)), ((TYPE=EMON)(BROKERS=1))\n+ASM1.core_dump_dest = /u01/app/oracle/diag/asm/+asm/+ASM1/cdump\n+ASM2.core_dump_dest = /u01/app/oracle/diag/asm/+asm/+ASM2/cdump\n+ASM1.cpu_count = 4\n+ASM2.cpu_count = 4\n+ASM1.db_cache_size = 0\n+ASM2.db_cache_size = 0\n+ASM1.db_ultra_safe = OFF\n+ASM2.db_ultra_safe = OFF\n+ASM1.db_unique_name = +ASM\n+ASM2.db_unique_name = +ASM\n+ASM1.diagnostic_dest = /u01/app/oracle\n+ASM2.diagnostic_dest = /u01/app/oracle\n+ASM1.diagnostics_control = IGNORE\n+ASM2.diagnostics_control = IGNORE\n+ASM1.event =\n+ASM2.event =\n+ASM1.file_mapping = FALSE\n+ASM2.file_mapping = FALSE\n+ASM1.filesystemio_options = none\n+ASM2.filesystemio_options = none\n+ASM1.forward_listener =\n+ASM2.forward_listener =\n+ASM1.heartbeat_batch_size = 5\n+ASM2.heartbeat_batch_size = 5\n+ASM1.ifile =\n+ASM2.ifile =\n+ASM1.instance_abort_delay_time = 0\n+ASM2.instance_abort_delay_time = 0\n+ASM1.instance_name = +ASM1\n+ASM2.instance_name = +ASM2\n+ASM1.instance_number = 1\n+ASM2.instance_number = 2\n+ASM1.instance_type = ASM\n+ASM2.instance_type = ASM\n+ASM1.large_pool_size = 16777216\n+ASM2.large_pool_size = 16777216\n+ASM1.ldap_directory_sysauth = no\n+ASM2.ldap_directory_sysauth = no\n+ASM1.listener_networks = ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (LOCAL_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr)(REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\"))\n+ASM2.listener_networks = ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (LOCAL_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr)(REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\"))\n+ASM1.local_listener =  (ADDRESS=(PROTOCOL=TCP)(HOST=10.214.209.68)(PORT=1521))\n+ASM2.local_listener =  (ADDRESS=(PROTOCOL=TCP)(HOST=10.214.209.69)(PORT=1521))\n+ASM1.lock_name_space =\n+ASM2.lock_name_space =\n+ASM1.lock_sga = FALSE\n+ASM2.lock_sga = FALSE\n+ASM1.max_dump_file_size = unlimited\n+ASM2.max_dump_file_size = unlimited\n+ASM1.memoptimize_pool_size = 0\n+ASM2.memoptimize_pool_size = 0\n+ASM1.memory_max_target = 0\n+ASM2.memory_max_target = 0\n+ASM1.memory_target = 0\n+ASM2.memory_target = 0\n+ASM1.nls_calendar =\n+ASM2.nls_calendar =\n+ASM1.nls_comp = BINARY\n+ASM2.nls_comp = BINARY\n+ASM1.nls_currency =\n+ASM2.nls_currency =\n+ASM1.nls_date_format =\n+ASM2.nls_date_format =\n+ASM1.nls_date_language =\n+ASM2.nls_date_language =\n+ASM1.nls_dual_currency =\n+ASM2.nls_dual_currency =\n+ASM1.nls_iso_currency =\n+ASM2.nls_iso_currency =\n+ASM1.nls_language = AMERICAN\n+ASM2.nls_language = AMERICAN"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nExperience and testing has shown that certain ASM initialization parameters \nshould be set at specific values. These are the best practice values set at \ndeployment time. By setting these ASM initialization parameters as \nrecommended, known problems may be avoided and performance maximized. The \nparameters are specific to the ASM instances. Unless otherwise specified, the \nvalue is for both X2-2 and X2-8 Database Machines. The impact of setting \nthese parameters is minimal. \n \n\n\nRisk:\n\nIf the ASM initialization parameters are not set as recommended, a variety of \nissues may be encountered, depending upon which initialization parameter is \nnot set as recommended, and the actual set value. \n \n\n\nAction / Repair:\n\nThis disables memory_target for the ASM instance and setting SGA_TARGET to 3G provides the ASM instance sufficient SGA memory.\n \nNOTE: The proper way to implement the memory related parameters is as follows. This is important as it works around an issue where memory_target remains set despite setting it to 0.\n\nalter system set sga_target=3G sid='*' scope=spfile;\nalter system set pga_aggregate_target=400M sid='*' scope=spfile;\nalter system set memory_target=0 sid='*' scope=spfile;\nalter system set memory_max_target=0 sid='*' scope=spfile;\nalter system reset memory_max_target sid='*' scope=spfile;"}]}, {"id": "8eb49140-6a3c-4661-9c7e-55d93124011c", "checkCategory": "ASM", "checkID": "437EE7C5ACFF9663E0530A98EB0A4169", "checkType": "OS", "checkName": "Verify Flex ASM Cardinality Is Set to \u201cALL\u201d", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "Flex ASM cardinality is set to \"ALL\""}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY FLEX ASM CARDINALITY IS SET TO \u201cALL\u201d\n\n\n\nPASS:Flex ASM cardinality is properly set to ALL"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nBy default, Flex ASM cardinality is set to 3. The impact of verifying that Flex ASM cardinality is set to \"ALL\" is minimal. The impact of setting the Flex ASM cardinality to \"ALL\" from a lower value is minimal and can be done online; ASM will bring up the additional instances required to fullfil the cardinality setting.\n\nRisk:\n\nNot having Flex ASM cardinality set to \"ALL\" could result in a higher number of client (DB) connections on some ASM instances and may result in longer client reconnection times should an ASM instance crash.\n\nAction / Repair:\n\nTo verify Flex ASM cardinality is set to \"ALL\", confirm that the report output shows a PASS message:\n    PASS: Flex ASM cardinality is properly set to ALL\n\nIf a FAIL message appears:\n    FAIL: Flex ASM cardinality is incorrectly set to &lt;cardinality&gt; when it should be set to ALL \ncheck additional details using the following commands:\n    srvctl status asm -detail\n    srvctl config asm -detail\nand adjust the Flex ASM cardinality to \"ALL\" using the following command:\n    srvctl modify asm -count ALL\n\nAfter making the change to ASM cardinality, verify that each node has an ASM instance running using the following command:\n    $ srvctl status asm -detail | grep \"is running\"\n    ASM is running on mydbnode06,mydbnode05,mydbnode08,mydbnode07,mydbnode02,mydbnode01,mydbnode04,mydbnode03 \n    ASM instance +ASM2 is running on node mydbnode02 \n    ASM instance +ASM1 is running on node mydbnode01 \n    ASM instance +ASM4 is running on node mydbnode04 \n    ASM instance +ASM3 is running on node mydbnode03 \n    ASM instance +ASM5 is running on node mydbnode05 \n    ASM instance +ASM6 is running on node mydbnode06 \n    ASM instance +ASM7 is running on node mydbnode07 \n    ASM instance +ASM8 is running on node mydbnode08"}]}, {"id": "10ad87c8-a61f-48fd-9f87-9e84969eacd4", "checkCategory": "HOST", "checkID": "4D6475EC02E8231AE0530B98EB0AD9A1", "checkType": "OS_OUT_CHECK", "checkName": "Verify database server file systems have \"Maximum mount count\" = \"-1\"", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "The database server file systems have \"Maximum mount count\" = \"-1\""}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR VERIFY DATABASE SERVER FILE SYSTEMS HAVE MAXIMUM MOUNT COUNT = -1\n\n"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "The database server file systems have \"Maximum mount count\" = \"-1\""}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR VERIFY DATABASE SERVER FILE SYSTEMS HAVE MAXIMUM MOUNT COUNT = -1\n\n"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nA filesystem will be checked for consistency (fsck) after the number of times it is mounted exceeds the \"Maximum mount count\" setting, typically at reboot time. On a database server, the \"Maximum mount count\" is set to \"-1\" by default.\n\nVerifying that the database server file systems all have \"Maximum mount count\" set to \"-1\" helps to avoid an unexpectedly long reboot sequence as an fsck of the file system completes. The Impact of verifying the database server file systems \"Maximum mount count\" is minimal. The impact of changing the \"Maximum mount count\" value is minimal as it can be changed dynamically. \n\nNOTE: fsck should be periodically executed as part of the regular maintenance schedule for an Oracle Exadata Database Machine, where the timing is controlled by the customer. This check only verifies that the timing of the run should be controlled and not unexpected.\n\nRisk:\n\nA database server reboot may take an unexpectedly long time as an fsck operation completes, potentially extending an outage or maintenance window.\n\nAction / Repair:\n\nTo verify the database server file systems \"Maximum mount count\" configuration, execute the following command as the \"root\" userid on all database servers:\n\nLVM_IN_USE=$(parted -ls 2&gt;/dev/null | egrep -i lvm | wc -l);\nif [ $LVM_IN_USE -ge 1 ]\n  then\n  if test -f /proc/xen/capabilities && grep -q \"control_d\" /proc/xen/capabilities\n  then  # dom0 case\n    which tune4fs 2&gt;/dev/null 1&gt;/dev/null\n    if [ $? -eq 0 ] #tune4fs exists\n    then\n      FS_COMMAND=tune4fs \n    else\n      FS_COMMAND=tune2fs\n    fi\n  else # physical, domU case\n    FS_COMMAND=tune2fs\n  fi;\n  LOGICAL_VOLUME_ARRAY=$(lvscan | cut -d\"'\" -f2);\n  for INDIVIDUAL_LOGICAL_VOLUME in $LOGICAL_VOLUME_ARRAY\n    do\n    if [ `file -sL $INDIVIDUAL_LOGICAL_VOLUME | egrep -wc \"ext3|ext4\" 2&gt; /dev/null` -eq 1 ]\n    then\n    FILESYSTEM_ARRAY+=\"$INDIVIDUAL_LOGICAL_VOLUME \"\n    fi;\n    done; \n  MNT_CNT_CHK_RSLT=0;\n  for INDIVIDUAL_LOGICAL_VOLUME in `echo ${FILESYSTEM_ARRAY[@]}`\n    do\n    if [ \"`$FS_COMMAND -l $INDIVIDUAL_LOGICAL_VOLUME | egrep \"^Maximum mount\" | cut -d \":\" -f 2 | sed -e 's/^[ \\t]*//'`\" -ne \"-1\" ]\n      then MNT_CNT_CHK_RSLT=1;\n    fi;\n    done;\n  if [ \"$MNT_CNT_CHK_RSLT\" -eq \"0\" ]\n  then\n    echo -e \"\\nSUCCESS:  All database server logical volumes found with filesystems had \"Maximum mount count\" equal to -1\";\n  else\n    echo -e \"\\nFAILURE:  One or more database server logical volumes found with filesystems had \"Maximum mount count\" not equal to -1\";\n  fi;\n    for INDIVIDUAL_LOGICAL_VOLUME in `echo ${FILESYSTEM_ARRAY[@]}`\n    do\n      echo \"$INDIVIDUAL_LOGICAL_VOLUME: `$FS_COMMAND -l $INDIVIDUAL_LOGICAL_VOLUME | egrep \"^Maximum mount\" | cut -d \":\" -f 2 | sed -e 's/^[ \\t]*//'`\";\n    done;\nelse\n  export SWAP_DEVICE=`swapon -s | grep -v Filename | cut -d\" \" -f1`\n  export PARTITIONED_DEVICE_ARRAY=`fdisk -l 2&gt;/dev/null | egrep ^/dev | egrep -v $SWAP_DEVICE | cut -d\" \" -f1`;\n  export MNT_CNT_CHK_RSLT=0;\n  for INDIVIDUAL_PARTITIONED_DEVICE in $PARTITIONED_DEVICE_ARRAY\n  do\n    if [ \"`tune2fs -l $INDIVIDUAL_PARTITIONED_DEVICE | egrep \"^Maximum mount\" | cut -d \":\" -f 2 | sed -e 's/^[ \\t]*//'`\" -ne \"-1\" ]\n      then MNT_CNT_CHK_RSLT=1;\n    fi;\n  done;\n  if [ \"$MNT_CNT_CHK_RSLT\" -eq \"0\" ]\n  then\n    echo -e \"\\nSUCCESS:  All database server partitioned devices (other than swap) found had \"Maximum mount count\" equal to -1\";\n    for INDIVIDUAL_PARTITIONED_DEVICE in $PARTITIONED_DEVICE_ARRAY\n    do\n      echo \"$INDIVIDUAL_PARTITIONED_DEVICE: `tune2fs -l $INDIVIDUAL_PARTITIONED_DEVICE | egrep \"^Maximum mount\" | cut -d \":\" -f 2 | sed -e 's/^[ \\t]*//'`\";\n    done;\n  else\n    echo -e \"\\nFAILURE:  One or more database partitioned devices (other than swap) found had \"Maximum mount count\" not equal to -1\";\n    for INDIVIDUAL_PARTITIONED_DEVICE in $PARTITIONED_DEVICE_ARRAY\n    do\n      echo \"$INDIVIDUAL_PARTITIONED_DEVICE: `tune2fs -l $INDIVIDUAL_PARTITIONED_DEVICE | egrep \"^Maximum mount\" | cut -d \":\" -f 2 | sed -e 's/^[ \\t]*//'`\";\n    done;\n  fi;\nfi;\n\nThe output should be similar to:\n\nSUCCESS:  All database server logical volumes found with filesystems had \"Maximum mount count\" equal to -1\n/dev/VGExaDb/LVDbSys1: -1\n/dev/VGExaDb/LVDbSys2: -1\n/dev/VGExaDb/LVDbOra1: -1\n\n- OR -\n\nSUCCESS:  All database server partitioned devices (other than swap) found had \"Maximum mount count\" equal to -1\n/dev/sda1: -1\n/dev/sda3: -1\n\nIf the output is not as expected, you can change the \"Maximum mount count\" value as the \"root\" userid using the appropriate command for your environment (\"tune2fs\" or \"tune4fs\") on the database server for either partitioned or logical volume devices. Only the device name portion of the command differs. For example, if the appropriate command for your environment is \"tune2fs\":\n\n# tune2fs -c -1 /dev/mapper/VGExaDb-LVDbOra1\ntune2fs 1.39 (29-May-2006)\nSetting maximal mount count to -1"}]}, {"id": "10864908-8c20-4d61-889a-972593205cc6", "checkCategory": "HOST", "checkID": "51EB9D56C19DF926E0530A98EB0A6A90", "checkType": "OS_OUT_CHECK", "checkName": "Verify IP routing configuration on database servers", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "The IP routing configuration is correct"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR VERIFY IP ROUTING CONFIGURATION ON DATABASE SERVERS\n\n"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "The IP routing configuration is correct"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR VERIFY IP ROUTING CONFIGURATION ON DATABASE SERVERS\n\n"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nTo ensure network traffic received on a particular Ethernet interface has responses sent out over the same Ethernet interface, configure route and rule files in /etc/sysconfig/network-scripts for each Ethernet interface. \n\nRisk:\n\nIncorrect Linux routing configuration can lead to asymmetric routing where network traffic is received through a particular Ethernet interface, but responses for the same connection are sent through a different Ethernet interface (e.g. the default route). Asymmetric routing can cause poor network performance. See configuration details in MOS Note 1306154.1. \n\nAction / Repair:\n\n To verify the IP routing configuration, run Exachk and review the provided report.\n\nThe expected output in the Exachk report should be as follows:\n\nIn the \"Findings Passed\" summary section of the report, the overall result should be \"PASS\":\n\nPASS   OS Check   The IP routing configuration is correct   All Database Servers   View\n\nIn the \"View\" detail section of the report for each individual database server:\n\nStatus on random01client02:\nPASS =&gt; The IP routing configuration is correct\n\nDATA FROM RANDOM01CLIENT02 FOR VERIFY IP ROUTING CONFIGURATION ON DATABASE SERVERS\n\nInterface: bondeth0\n    SUCCESS: rule-bondeth0 is configured with IPv4 rules.\n    SUCCESS: route-bondeth0 is configured with IPv4 routes.\n      Note: bondeth0 is not configured for IPv6\nInterface: eth0\n    SUCCESS: rule-eth0 is configured with IPv4 rules.\n    SUCCESS: route-eth0 is configured with IPv4 routes.\n      Note: eth0 is not configured for IPv6\nInterface: eth1\n      Note: eth1 is not configured for IPv4\n      Note: eth1 is not configured for IPv6\n&lt;NOTE: similar output truncated in this example, check output is not truncated&gt;\nInterface: eth3\n      Note: eth3 is not configured for IPv4\n      Note: eth3 is not configured for IPv6\nInterface: eth4\n      Note: Slave Interfaces (eth4) do not have rule or route files\nInterface: eth5\n      Note: Slave Interfaces (eth5) do not have rule or route files\n\nA \"FAIL\" result view detail example:\n\nStatus on random01client02:\nFAIL =&gt; The IP routing configuration is not correct\n\nDATA FROM RANDOM01CLIENT02 FOR VERIFY IP ROUTING CONFIGURATION ON DATABASE SERVERS\n\nInterface: bondeth0\n  FAILURE: Need to create the IPv4 rule configuration for rule-bondeth0 per 1306154.1\n    SUCCESS: route-bondeth0 is configured with IPv4 routes.\n      Note: bondeth0 is not configured for IPv6\nInterface: eth0\n    SUCCESS: rule-eth0 is configured with IPv4 rules.\n    SUCCESS: route-eth0 is configured with IPv4 routes.\n      Note: eth0 is not configured for IPv6\nInterface: eth1\n      Note: eth1 is not configured for IPv4\n      Note: eth1 is not configured for IPv6\n&lt;NOTE: similar output truncated in this example, check output is not truncated&gt;\nInterface: eth4\n      Note: Slave Interfaces (eth4) do not have rule or route files\nInterface: eth5\n      Note: Slave Interfaces (eth5) do not have rule or route files\n&lt;NOTE: similar output truncated in this example, check output is not truncated&gt;\nInterface: eth8\n      Note: Skipping eth8 as this interface is not configured.\nInterface: vmeth100\n      Note: Skipping vmeth100 as this configuration check is not relevant.\n\n    NOTE: If any \"FAILURE:\" results are returned, follow the guidance provided in the message.\n\n    NOTE: If after corrective actions are completed you wish to run just this check without a full Exachk run, execute the following:\n\n    ./exachk -check 91AF9702E37ABC49E053D498EB0A2AC7,51EB9D56C19DF926E0530A98EB0A6A90"}]}, {"id": "98a14139-aba3-425b-a1a3-a366507b9187", "checkCategory": "RDBMS HOME", "checkID": "540A623C4B3A8D1FE0530C98EB0A3FFC", "checkType": "OS", "checkName": "Verify the ownership and permissions of the \"oradism\" file", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:/u01/app/oracle/product/21.0.0.0/dbhome_1", "status": "success", "statusLabel": "PASS", "output": "The \"oradism\" file is correctly configured"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - /u01/app/oracle/product/21.0.0.0/dbhome_1 DATABASE_HOME - Verify the ownership and permissions of the \"oradism\" file\n\n\n\nSUCCESS:\"oradism\" file is correctly configured:\nowner userid:\troot\nsetuid bit:\ts"}}]}, {"attr": {"target": "scaqal03adm06vm01:/u01/app/oracle/product/21.0.0.0/dbhome_1", "status": "success", "statusLabel": "PASS", "output": "The \"oradism\" file is correctly configured"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - /u01/app/oracle/product/21.0.0.0/dbhome_1 DATABASE_HOME - Verify the ownership and permissions of the \"oradism\" file\n\n\n\nSUCCESS:\"oradism\" file is correctly configured:\nowner userid:\troot\nsetuid bit:\ts"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nMaintaining the correct ownership and permissions of the \"oradism\" file is essential for the proper operation of Direct NFS and achieving the highest possible throughput. The file should be owned the the \"root\" userid and have the setuid bit enabled in the permissions mask. The impact of validating file ownership and permission is minimal. Changing the file ownership and permissions requires a restart of the Oracle stack running out of the adjusted $ORACLE_HOME. \n\nRisk:\n\nIf the ownership and permissions of the \"oradism\" file are not correct, the performance of Direct NFS will be severely impacted.\n\nAction / Repair:\n\nTo verify the ownership and permissions of the \"oradism\" file, as the appropriate oracle home owner userid on each database server, execute the following command set on each $ORACLE_HOME:\n\nOWNER_USERID=$(ls -l $ORACLE_HOME/bin/oradism |awk '{print $3}')\nSETUID_BIT=$(ls -l $ORACLE_HOME/bin/oradism | cut -c4)\nDETAIL=$(echo -e \"owner userid:\\t$OWNER_USERID\\nsetuid bit:\\t$SETUID_BIT\")\nif [[ $OWNER_USERID = \"root\" && $SETUID_BIT = \"s\" ]]\nthen\n  echo -e \"SUCCESS: \"oradism\" file is correctly configured:\\n$DETAIL\"\nelse\n  echo -e \"FAILURE: \"oradism\" file is not correctly configured:\\n$DETAIL\"\nfi\n\nThe output should be similar to:\n\nSUCCESS: \"oradism\" file is correctly configured:\nowner userid:   root\nsetuid bit:     s\n\nExamples of \"FAILURE\" results:\n\nFAILURE: \"oradism\" file is not correctly configured:\nowner userid:   root\nsetuid bit:     x\n\nFAILURE: \"oradism\" file is not correctly configured:\nowner userid:   oracle\nsetuid bit:     x\n\nIf the output is a \"FAILURE\" result, investigate and take corrective action. "}]}, {"id": "b41f8ca9-75d4-436b-b31b-e875f4dc8542", "checkCategory": "HOST", "checkID": "540C9592D9A74BC4E0530B98EB0A7C98", "checkType": "OS_OUT_CHECK", "checkName": "Verify the vm.min_free_kbytes configuration", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "The vm.min_free_kbytes configuration is set as recommended"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR VERIFY THE VM.MIN_FREE_KBYTES CONFIGURATION\n\n\n\nSUCCESS:vm.min_free_kbytes is configured as recommended.  Details:\n\nTotal Memory:      608378776\nNUMA node count:   2\nNUMA calculated:   2097152\nmemory calculated: 3041893\nrecommended value: 3041893\npermitted range:   2889799 to 3193987\nat boot (sysctl):  3041893\nsysctl in range?:  YES\nin active memory:  3041893\nmemory in range?:  YES"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "The vm.min_free_kbytes configuration is set as recommended"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR VERIFY THE VM.MIN_FREE_KBYTES CONFIGURATION\n\n\n\nSUCCESS:vm.min_free_kbytes is configured as recommended.  Details:\n\nTotal Memory:      608378768\nNUMA node count:   2\nNUMA calculated:   2097152\nmemory calculated: 3041893\nrecommended value: 3041893\npermitted range:   2889799 to 3193987\nat boot (sysctl):  3041893\nsysctl in range?:  YES\nin active memory:  3041893\nmemory in range?:  YES"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nMaintaining vm.min_free_kbytes as recommended helps a Linux system to reclaim memory more efficiently.\n\nThe impact of verifying the vm.min_free_kbytes configuration is minimal.\n\nThe impact of adjusting vm.min_free_kbytes should include a reboot to verify the configuration is correctly configured and retained during the boot cycle.\n\n    NOTE: It is possible, but NOT recommended, especially for a system already under memory pressure, to modify the setting interactively in active kernel memory.\n\nThe recommended values are shown in the following table:\n\nvm.min_free_kbytes value (Kb)\nMAX(1GB * number_numa_nodes, 0.5% * total_memory) \n\nRisk:\n\nExposure to unexpected node eviction and reboot.\n\nAction / Repair:\n\nTo verify the vm.min_free_kbytes configuration, as the \"root\" userid on each database server, execute the following command set:\nMIN_FREE_KBYTES_SYSCTL=$(egrep ^vm.min_free_kbytes &lt;([ -e /etc/sysctl.d/99-sysctl.conf ] && cat /etc/sysctl.d/* || cat /etc/sysctl.conf) | awk -F'=' '{print $2}' | tr -d ' ')\nMIN_FREE_KBYTES_MEMORY=$(cat /proc/sys/vm/min_free_kbytes)\nNUMA_NODE_COUNT=$(numactl --hardware | grep available: | awk '{print $2}')\nTOTAL_MEMORY_KBYTES=$(free -k | awk '/Mem:/ {print $2}')\nNUMA_BASED=$(( $NUMA_NODE_COUNT * 1048576 ))\nMEMORY_BASED=$(( $TOTAL_MEMORY_KBYTES / 200 ))\nif [[ $NUMA_BASED -ge $MEMORY_BASED ]]\nthen\n  RECOMMEND_VALUE=$NUMA_BASED\nelse\n  RECOMMEND_VALUE=$MEMORY_BASED\nfi\nOFFSET=$(echo $RECOMMEND_VALUE*.05 | bc | cut -d\".\" -f1)\nLOWER_BOUND=$(echo $RECOMMEND_VALUE-$OFFSET | bc)\nUPPER_BOUND=$(echo $RECOMMEND_VALUE+$OFFSET | bc)\nif [[ $MIN_FREE_KBYTES_SYSCTL -ge LOWER_BOUND && $MIN_FREE_KBYTES_SYSCTL -le UPPER_BOUND ]]\nthen\n  SYSCTL_IN_RANGE=YES\nelse\n  SYSCTL_IN_RANGE=NO\nfi\n#sysctl in range?\nif [[ $MIN_FREE_KBYTES_MEMORY -ge LOWER_BOUND && $MIN_FREE_KBYTES_MEMORY -le UPPER_BOUND ]]\nthen\n  MEMORY_IN_RANGE=YES\nelse\n  MEMORY_IN_RANGE=NO\nfi\nDETAIL=$(\necho -e \"Total Memory:       $TOTAL_MEMORY_KBYTES\";\necho -e \"NUMA node count:    $NUMA_NODE_COUNT\";\necho -e \"NUMA calculated:    $NUMA_BASED\";\necho -e \"memory calculated:  $MEMORY_BASED\";\necho -e \"recommended value:  $RECOMMEND_VALUE\";\necho -e \"permitted range:    $LOWER_BOUND to $UPPER_BOUND\";\necho -e \"at boot (sysctl):   $MIN_FREE_KBYTES_SYSCTL\";\necho -e \"sysctl in range?:   $SYSCTL_IN_RANGE\";\necho -e \"in active memory:   $MIN_FREE_KBYTES_MEMORY\";\necho -e \"memory in range?:   $MEMORY_IN_RANGE\";\n)\nif [[ $SYSCTL_IN_RANGE = YES && $MEMORY_IN_RANGE = YES ]]\nthen\n  echo -e \"SUCCESS: vm.min_free_kbytes is configured as recommended.  Details:\\n\\n$DETAIL\"\nelif [[ $MIN_FREE_KBYTES_SYSCTL -lt $LOWER_BOUND || $MIN_FREE_KBYTES_MEMORY -lt $LOWER_BOUND ]]\nthen\n  echo -e \"FAILURE: vm.min_free_kbytes is not configured as recommended.  Details:\\n\\n$DETAIL\"\nelif  [[ $MIN_FREE_KBYTES_SYSCTL -gt $UPPER_BOUND && $MIN_FREE_KBYTES_MEMORY -gt $UPPER_BOUND ]]\nthen\n  echo -e \"WARNING: vm.min_free_kbytes is not configured as recommended.  Details:\\n\\n$DETAIL\"\nelse\n  echo -e \"ERROR: Inconsistent results.  Details:\\n\\n$DETAILS\"\nfi\nThe output should be similar to:\nSUCCESS: vm.min_free_kbytes is configured as recommended.  Details:\n\nTotal Memory:       790834860\nNUMA node count:    2\nNUMA calculated:    2097152\nmemory calculated:  3954174\nrecommended value:  3954174\npermitted range:    3756466 to 4151882\nat boot (sysctl):   3954174\nsysctl in range?:   YES\nin active memory:   3954174\nmemory in range?:   YES\nExample of a \"FAILURE\" result:\nFAILURE: vm.min_free_kbytes is not configured as recommended.  Details:\n\nTotal Memory:       263649268\nNUMA node count:    1\nNUMA calculated:    1048576\nmemory calculated:  1318246\nrecommended value:  1318246\npermitted range:    1252334 to 1384158\nat boot (sysctl):   524288\nsysctl in range?:   NO\nin active memory:   524288\nmemory in range?:   NO\nNOTE: In the above \"FAILURE\" example, the setting at boot (sysctl) and active memory are both lower than the permitted range.\nExample of a \"WARNING\" result:\nWARNING: vm.min_free_kbytes is not configured as recommended.  Details:\n\nTotal Memory:       263649268\nNUMA node count:    1\nNUMA calculated:    1048576\nmemory calculated:  1318246\nrecommended value:  1318246\npermitted range:    1252334 to 1384158\nat boot (sysctl):   1412346\nsysctl in range?:   NO\nin active memory:   1412346\nmemory in range?:   NO\nNOTE: In the above \"WARNING\" example, the setting at boot (sysctl) and active memory are both higher than the permitted range.\nIf the output is a \"FAILURE\" result, set the recommended vm.min_free_kbytes value for the given configuration at boot (sysctl) and reboot the database server.\nIf numactl is unavailable, check uses lscpu."}]}, {"id": "63367235-477b-4466-a3fd-f3bcd8c7202a", "checkCategory": "RDBMS", "checkID": "54323C3D59E14EBDE0530B98EB0AAAEE", "checkType": "OS", "checkName": "Verify the SYSTEM, SYSAUX, USERS and TEMP tablespaces are of type bigfile", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "SYSTEM, SYSAUX, USERS, TEMP tablespaces are of type bigfile"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Verify the SYSTEM, SYSAUX, USERS and TEMP tablespaces are of type bigfile\n\n\n\nSUCCESS:SYSTEM, SYSAUX, USERS, TEMP tablespaces are of type bigfile:\n\nTABLESPACE_NAME BIGFILE\n--------------- -------\nSYSAUX          YES\nSYSTEM          YES\nTEMP            YES\nUSERS           YES"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "SYSTEM, SYSAUX, USERS, TEMP tablespaces are of type bigfile"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Verify the SYSTEM, SYSAUX, USERS and TEMP tablespaces are of type bigfile\n\n\n\nSUCCESS:SYSTEM, SYSAUX, USERS, TEMP tablespaces are of type bigfile:\n\nTABLESPACE_NAME BIGFILE\n--------------- -------\nSYSAUX          YES\nSYSTEM          YES\nTEMP            YES\nUSERS           YES"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nConfiguring the SYSTEM, SYSAUX, USERS, and TEMP tablespaces to be of type bigfile simplifies maintenance and operations which involve these tablespaces. The impact of verifying the SYSTEM, SYSAUX, USERS, and TEMP tablespaces are of type bigfile is minimal.\n\nRisk:\n\nIf the SYSTEM, SYSAUX, USERS, and TEMP tablespaces are not of type bigfile, maintenance operations are more complicated and a tablespace running out of free space is more possible.\n\nAction / Repair:\n\n To verify the SYSTEM, SYSAUX, USERS, and TEMP tablespaces are of type bigfile, as the ORACLE_HOME owner userid on one database server in the cluster, execute the following command set once for each database running out of a given ORACLE_HOME, with the environment properly configured to access each given database:\n\nBIGFILE_DATA=$($ORACLE_HOME/bin/sqlplus -s \"/ as sysdba\" &lt;&lt;EOF\nset newpage none lines 80 feedback off timing off serveroutput on\nSELECT tablespace_name, bigfile FROM dba_tablespaces\nWHERE tablespace_name in ('SYSTEM', 'SYSAUX', 'USERS', 'TEMP');\nexit\nEOF\n)\nif [ `echo \"$BIGFILE_DATA\" | grep -ic \"NO\"` -gt 0 ]\nthen \n     echo -e \"FAILURE: One or more of SYSTEM, SYSAUX, USERS, TEMP tablespaces are not of type bigfile:\\n\\n$BIGFILE_DATA\"\nelse \n     echo -e \"SUCCESS: SYSTEM, SYSAUX, USERS, TEMP tablespaces are of type bigfile:\\n\\n$BIGFILE_DATA\" \nfi\n\nThe output should be similar to:\n\nSUCCESS: the SYSTEM, SYSAUX, USERS, and TEMP tablespaces are of type bigfile:\n\nTABLESPACE_NAME                BIG\n------------------------------ ---\nSYSTEM                         YES\nSYSAUX                         YES\nTEMP                           YES\nUSERS                          YES\n\nExamples of a \"FAILURE\" result:\n\nFAILURE: One or more of SYSTEM, SYSAUX, USERS, TEMP tablespaces are not of type bigfile:\n\nTABLESPACE_NAME                BIG\n------------------------------ ---\nSYSTEM                         NO\nSYSAUX                         NO\nTEMP                           NO\nUSERS                          NO\n\nIf the output is a \"FAILURE\" result, investigate and take corrective action. "}]}, {"id": "c3285307-8d30-4309-b25d-1326879ee65a", "checkCategory": "CRS HOME", "checkID": "5679AC78C4AA1A7CE053D598EB0A1914", "checkType": "OS", "checkName": "Verify \"asm_power_limit\" is greater than zero", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "\"asm_power_limit\" is greater than zero and there are no rebalance operations in the queue with the attribute POWER or ACTUAL = 0"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY \"ASM_POWER_LIMIT\" IS GREATER THAN ZERO\n\n\n\nSUCCESS:asm_power_limit is set to 4 and there are no rebalance operations in the queue with the attribute POWER or ACTUAL = 0"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nSetting \"asm_power_limit=0\" disables rebalance operations. Verifying that \"asm_power_limit\" is greater than zero confirms that rebalance operations are enabled. The impact of verifying that \"asm_power_limit\" is greater than zero is minimal, as is the impact of setting it to a value greater than zero.\n\n    NOTE: Changing the default value via the initialization parameter \"asm_power_limit\" is not the same as changing the power for an actively running rebalance operation. \n\nRisk:\n\n\"asm_power_limit=0\" disables rebalance operations, which can lead to data loss in the event of multiple hardware failures over time. \n\nAction / Repair:\n\nTo verify \"asm_power_limit\" is greater than zero, as the grid home owner userid, execute the following command set once for each ASM instance with the environment properly configured to access that given instance:\n\n    NOTE: This code will not execute properly if executed on a database server in a flex ASM environment where an ASM instance is not running. \n\nASMPL_PARAM_DATA=$($ORACLE_HOME/bin/sqlplus -s \"/ as sysdba\" &lt;&lt;EOF\nset newpage none heading off lines 80 feedback off timing off serveroutput on\nselect value from v$parameter where name = 'asm_power_limit';\nexit\nEOF\n)\nASMPL_QUEUE_DATA=$($ORACLE_HOME/bin/sqlplus -s \"/ as sysdba\" &lt;&lt;EOF\nset newpage none heading off lines 80 feedback off timing off serveroutput on\nselect count(*) from gv$asm_operation where power=0 or actual=0;\nexit\nEOF\n)\nif [[ $ASMPL_PARAM_DATA -gt 0 && $ASMPL_QUEUE_DATA -eq 0 ]]\nthen \n  echo -e \"SUCCESS: \"asm_power_limit\" is set to $ASMPL_PARAM_DATA and there are no rebalance operations in gv$asm_operation with the attribute POWER or ACTUAL = 0\"\nelse \n  echo -e \"FAILURE:\"\n  if [ $ASMPL_PARAM_DATA -eq 0 ]\n  then\n    echo -e \"The intitialization parameter \"asm_power_limit\" is set to zero\"\n  fi\n  if [ $ASMPL_QUEUE_DATA -gt 0 ]\n  then\n    echo -e \"There are rebalance operation(s) in gv$asm_operation with the attribute POWER or ACTUAL = 0\"\n  fi\nfi;\n\nThe output should be similar to:\n\nSUCCESS: \"asm_power_limit\" is set to 32 and there are no rebalance operations in gv$asm_operation with the attribute POWER or ACTUAL = 0\n\nExamples of \"FAILURE\" results:\n\nFAILURE:\nThe intitialization parameter \"asm_power_limit\" is set to zero\nThere are rebalance operation(s) in gv$asm_operation with the attribute POWER or ACTUAL = 0\n\nFAILURE:\nThe intitialization parameter \"asm_power_limit\" is set to zero\n\nFAILURE:\nThere are rebalance operation(s) in gv$asm_operation with the attribute POWER or ACTUAL = 0\n\nIf the output is a \"FAILURE\" result, investigate and take corrective action. "}]}, {"id": "a442dbb2-4fa2-4378-8ddd-73ab959f2b0e", "checkCategory": "HOST", "checkID": "655C2F41EBD4D8D2E053D398EB0A46B7", "checkType": "OS", "checkName": "Verify there is enough disk group free space for a rebalance operation", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "There is enough disk group free space for a rebalance operation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY THERE IS ENOUGH DISK GROUP FREE SPACE FOR A REBALANCE OPERATION\n\n\n\nSUCCESS:Disk group DATAC1 has 99.5% free space which is enough to complete a rebalance operation if a disk fails\nDisk group DATAC1 HIGH Redundancy, Required Minimum Percent Free = 15%, Required Minimum Free MB = 28250726\nDisk group DATAC1 has Total MB = 188338176, Free MB = 187473912, Usable MB = 53074395\nNumber of failgroups = 3\n\nSUCCESS:Disk group RECOC1 has 99.8% free space which is enough to complete a rebalance operation if a disk fails\nDisk group RECOC1 HIGH Redundancy, Required Minimum Percent Free = 15%, Required Minimum Free MB = 42373324\nDisk group RECOC1 has Total MB = 282488832, Free MB = 281788212, Usable MB = 79804962\nNumber of failgroups = 3\n\nModel       :Oracle Corporation ORACLE SERVER X8-2L High Capacity\nEighth Rack :FALSE"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nHaving enough disk group free space available to accomodate a rebalance operation helps to prevent an outage or loss of data.\n\nIt is important to know if there is sufficient disk group free space to allow for ASM rebalance to complete after disk failure so that full redundancy is restored.  This is critical to avoid data loss or complete outage if a subsequent partner disk failure occurs in the future. \n\nThe impact of verifying that there is enough disk group free space available for a rebalance operation is minimal. The impact of correcting a lack of free space will vary depending upon the reason for the lack of free space, and cannot be estimated here. \n\nThe following table displays the required free space percentage for a complete rebalance operation after one disk failure with various combinations of Exadata configurations.\n\nThe percentages listed should be multiplied by the total raw disk group size (ie., v$asm_diskgroup.total_mb) to compute the amount of space to keep free in the diskgroup.\n\nApplicable to Exadata X9 and Earlier High Capacity or Extreme Flash, or Exadata X10 High Capacity:\n\n\nGrid Infrastructure Version     Number of Failgroups     Required % free\n~~~~~~~~~~~~~~~~~~~~~~~~~~~     ~~~~~~~~~~~~~~~~~~~~     ~~~~~~~~~~~~~~~\n12.1.0                             any                    15%\ngreater than or equal to 12.2     less than 5             15%\ngreater than or equal to 12.2     5 or more                9% \n\nNote: Eighth Rack systems require 20% free space regardless of version.\n\n\nApplicable to Exadata X10 Extreme Flash Only with Grid Infrastructure version 19.x or higher:\n\nNumber of Failgroups       Redundancy        Required % free\n~~~~~~~~~~~~~~~~~~~~       ~~~~~~~~~~        ~~~~~~~~~~~~~~~\n&lt; 5                        NORMAL               15%\n&lt; 5                        HIGH                 29%\n&gt;= 5                       NORMAL                9%\n&gt;= 5                       HIGH                 11%\n\nNOTE: In X10-EF systems for GI versions prior to 19.17, or 21.x, please apply patch 34281503 so the above percentages are applicable.\n\nPlease refer to MOS note \"Understanding ASM Capacity and Reservation of Free Space in Exadata (Doc ID 1551288.1)\" for more information.\n\nRisk:\n\nIf there is not enough diskgroup free space available for a rebalance operation, there is an increased risk of an outage or loss of data with an additional disk failure.\n\nAction / Repair:\n\nIf a diskgroup does not have sufficient free space, you should do one of the following:\n\n    - evaluate the space usage within the diskgroup and free up space by removing tablespaces that are no longer needed\n    - move datafiles to another diskgroup that has enough space (datafile moves can be done on-line as of Oracle 12.1 )\n    - increase the size of the diskgroup, assuming that some other diskgroup can be shrunk or, there is unallocated freespace on celldisks \n    - add additional capacity\n\n\nExamples of the output returned by the script:\n\n( NOTE: we are removing the code sample and instead will rely only on the Exachk code to compute the values )\n\nSUCCESS: Diskgroup DATAC5 has 94.9% free space which is enough to complete a rebalance operation if a disk fails\n\t Diskgroup DATAC5 HIGH Redundancy, Required Minimum Percent Free = 15%, Required Minimum Free MB = 18872524.8\n\t Diskgroup DATAC5 has Total MB = 125816832, Free MB = 119405532, Usable MB = 33511002.4\n\nSUCCESS: Diskgroup RECOC5 has 98.6% free space which is enough to complete a rebalance operation if a disk fails\n\t Diskgroup RECOC5 HIGH Redundancy, Required Minimum Percent Free = 15%, Required Minimum Free MB = 2119996.8\n\t Diskgroup RECOC5 has Total MB = 14133312, Free MB = 13934628, Usable MB = 3938210.4\n\nFAILURE: Diskgroup TESTC5 has 14% free space which is lower than the 15% free space threshold. A rebalance may fail with ORA-15041\n\t Diskgroup TESTC5 HIGH Redundancy, Required Minimum Percent Free = 15%, Required Minimum Free MB = 7396185.6\n\t Diskgroup TESTC5 has Total MB = 49307904, Free MB = 6901548, Usable MB = -164879.2\n\nIf a diskgroup does not have sufficient free space, you should do one or more of the following:\n\n    Evaluate the space usage within the diskgroup and free up space by removing tablespaces that are no longer needed\n    Increase the size of the disk group, assuming that some other diskgroup can be shrunk or, there is already unallocated free space on celldisks that can be used\n\n\n"}, {"id": "00f455b1-8dbd-4e4c-95b8-c9877ead64dc", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1351036.1", "text": "Note: 1351036.1 - Validate and Fix Proper ASM Failure Group Configuration on Oracle Exadata Database Machine"}]}]}, {"id": "5fb82035-c6b1-4357-89dd-8c837af078bd", "checkCategory": "HOST", "checkID": "656199B11AE12339E053D198EB0AD957", "checkType": "OS", "checkName": "Verify fast recovery area allocation totals are not greater than the total space of the DB_RECOVERY_FILE_DEST disk group", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "Fast recovery area allocation totals are not greater than the total space of the DB_RECOVERY_FILE_DEST disk group"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY FAST RECOVERY AREA ALLOCATION TOTALS ARE NOT GREATER THAN THE TOTAL SPACE OF THE DB_RECOVERY_FILE_DEST DISK GROUP\n\n"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThe space committed in DB_RECOVERY_FILE_DEST_SIZE for all database combined should not be larger than the total usable space in the DB_RECOVERY_FILE_DEST disk group. This ensures room for archive log creation and proper automatic space management. \n\nRisk:\n\nDatabase operation can be hampered by running out of space in the Fast Recovery Area (FRA). \n\nAction / Repair:\n\n To verify that the space committed by diskgroup to Fast Recovery Area is less than the space available, run Exachk and review the provided report.\n\nThe expected output in the Exachk report should be as follows:\n\nPASS   ASM Check   Fast recovery area allocation totals are not greater than the total space of the DB_RECOVERY_FILE_DEST disk group   All ASM Instances   \nView\n\nIf more space is committed to Fast Recovery Area than is actually available and usable in the diskgroup the Exachk report will return something similar to the following:\n\n[FAILURE] Disk group RECO over-committed on db_recovery_file_dest : space committed = 768012 MB, space available = 275754 MB\n\nIf the total space requested for the Fast Recovery Area by diskgroup for the databases is greater than the space defined for the diskgroup, analyze your database Fast Recovery Area requirements and adjust the DB_RECOVERY_FILE_DEST_SIZE setting in one of more databases to reduce the space committed. To determine the space committed by database, connect to one database instance for each database and run the following:\n\ncol \"FRA Diskgroup\" format a30\nselect fra_name.value as \"FRA Diskgroup\", round(fra_space.value/1048576)||' mb' as \"FRA Space Committed\"\nfrom v$parameter fra_name, v$parameter fra_space\nwhere fra_name.name = 'db_recovery_file_dest' and\nfra_space.name = 'db_recovery_file_dest_size';\n\nThe output should be similar to the following:\n\nFRA Diskgroup                  FRA Space Committed\n------------------------------ -------------------------------------------\n+RECO                          1048576 mb\n\nTo alter the amount of space committed to the Fast Recovery Area by a database run a command similar to the following with an appropriate value for the size.\n\nSQL&gt; alter system set db_file_recovery_dest_size=250g scope=both;\n\nIf after corrective actions are completed, you wish to run this one check without a full Exachk run execute the following command as the \"root\" userid in the directory in which Exachk was installed:\n\n./exachk -check 9AD94FEDF63F8296E040E50A1EC06A28,655C2F41EBD4D8D2E053D398EB0A46B7,656199B11AE12339E053D198EB0AD957"}]}, {"id": "97dbb46a-b908-4b1d-8184-97adb40cf973", "checkCategory": "HOST", "checkID": "6BDB40764A4DFC3AE053D198EB0A4E15", "checkType": "OS_OUT_CHECK", "checkName": "Verify proper ACFS drivers are installed for Spectre v2 mitigation", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "All database servers are using the expected Spectre v2 mitigation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR VERIFY PROPER ACFS DRIVERS ARE INSTALLED FOR SPECTRE V2 MITIGATION\n\n\n\nSUCCESS:Spectre v2 mitigation is using Mitigation:Enhanced IBRS, IBPB:conditional, RSB filling"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "All database servers are using the expected Spectre v2 mitigation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR VERIFY PROPER ACFS DRIVERS ARE INSTALLED FOR SPECTRE V2 MITIGATION\n\n\n\nSUCCESS:Spectre v2 mitigation is using Mitigation:Enhanced IBRS, IBPB:conditional, RSB filling"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nOn Exadata database servers that have an Exadata version installed that provides mitigation for Spectre v2 vulnerability, proper ACFS drivers or other customer-installed kernel drivers must be installed in order for the proper Spectre v2 mitigation to be used.\n\nInstalling proper ACFS drivers requires server (or VM) reboot. The impact of installing proper customer-installed kernel drivers cannot be estimated here.\n\nRisk:\n\nNot using the proper ACFS drivers or other customer-installed kernel drivers can prevent the desired Spectre v2 mitigation, which can lead to severely degraded performance for all database workloads, even if ACFS is not being used.\n\nAction / Repair:\n\nTo verify proper ACFS drivers are installed for Spectre v2 mitigation, execute the following command set as the \"root\" userid on all database servers:\n\n#!/bin/bash\n# CPU model numbers (/proc/cpuinfo)\n# V2:26 X2-2:44 X2-8:46 X2-8M2:47 X3:45 X4:62 X5:63 X6:79 X7:85\nmodelsUseRetpoline='26|44|46|47|45|62|63|79'\nthisModel=$(egrep \"^model[[:space:]]*:\" /proc/cpuinfo | sort -u | awk '{print $NF}')\n# kernels without spectrev2 mitigation will not have this file\nif [[ ! -e /sys/devices/system/cpu/vulnerabilities/spectre_v2 ]]; then\n echo \"WARNING: System is not capable of Spectre v2 mitigation. See minimum version requirements in MOS document 2356385.1.\"\nelse\n v2mitigation=$(&lt;/sys/devices/system/cpu/vulnerabilities/spectre_v2)\n # dom0 should use retpoline for all hardware\n # X6 and older should use retpoline\n wantRetpoline=no\n  if (  [[ -d /proc/xen/capabilities ]] && grep -q 'control_d' /proc/xen/capabilities ) || echo \"$thisModel\" | egrep -q \"$modelsUseRetpoline\"; then\n  wantRetpoline=yes\n fi\n if [[ $wantRetpoline == yes ]]; then\n  if ! echo $v2mitigation | grep -qi retpoline; then\n   echo \"FAIL: Spectre v2 mitigation is expected to be retpoline, but is not.\"\n   if dmesg | grep -q 'Disabling Spectre v2 mitigation retpoline'; then\n    echo \"Spectre v2 mitigation retpoline was disabled after system boot.\"\n    # look for modules not compiled with retpoline\n    badmodules=$(dmesg | grep 'loading module not compiled with retpoline compiler' | awk -F '[]:]' '{print $2}' | tr '012' ' ')\n    echo \"Modules loaded not compiled with retpoline compiler: $badmodules. These modules must be updated.\"\n    if [[ $badmodules =~ oracleoks ]]; then\n     echo \"oracleoks module will be updated by installing updated ACFS drivers. See MOS document 2356385.1.\"\n    fi\n   fi\n  else\n   echo \"SUCCESS: Spectre v2 mitigation is using $v2mitigation\"\n  fi\n else\n  echo \"SUCCESS: Spectre v2 mitigation is using $v2mitigation\"\n fi\nfi\n\nThe expected output is:\n\nSUCCESS: Spectre v2 mitigation is using Mitigation: Full generic retpoline, IBRS_FW, IBPB\n\n-OR-\n\nSUCCESS: Spectre v2 mitigation is using Mitigation: IBRS, IBRS_FW, IBPB\n\nExample of a \"WARNING\" result:\n\nWARNING: System is not capable of Spectre v2 mitigation.  See minimum version requirements in MOS document 2356385.1.\n\nIn the above \"WARNING\" example, the system should be upgraded per the MOS note.\n\nExample of a \"FAIL\" result:\n\nFAIL: Spectre v2 mitigation is expected to be retpoline, but is not.  Spectre v2 mitigation retpoline was disabled after system boot.  Modules loaded not compiled with retpoline compiler: oracleoks. These modules must be updated.  oracleoks module will be updated by installing updated ACFS drivers.  See: MOS document 2356385.1.\n\nIn the above FAIL, the system was expected to be using retpoline mitigation for Spectre v2, but was not. The system initially booted with retpoline mitigation, but it was disabled when an improper kernel module was loaded that caused retpoline mitigation to be disabled. "}, {"id": "115ed220-7950-4c0c-8e5f-97d30fd154e3", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1633603.1", "text": "Note: 1633603.1 - How to Setup Diagnostic Directory Group Permissions for Platinum Automated Diagnostic Upload"}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=2356385.1", "text": "Note: 2356385.1 - Oracle Exadata Database Machine Patch Availability Document for CVE-2017-5715, CVE-2017-5753, and CVE-2017-5754"}]}]}, {"id": "e64d08f7-6674-405d-a58a-70741f413d1d", "checkCategory": "RDBMS", "checkID": "7D3A3A8C16CCE03BE053D398EB0A5D64", "checkType": "OS", "checkName": "Verify database parameter AUDIT_TRAIL", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Database parameter AUDIT_TRAIL is set to the recommended value"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Verify database parameter AUDIT_TRAIL\n\n\n\nSUCCESS:database parameter AUDIT_TRAIL is set to DB"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Database parameter AUDIT_TRAIL is set to the recommended value"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Verify database parameter AUDIT_TRAIL\n\n\n\nSUCCESS:database parameter AUDIT_TRAIL is set to DB"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nSetting the database parameter AUDIT_TRAIL to either \"db\" or \"db, extended\" is a recommended security optimization.\n\nRisk:\n\nLack of database activity audit records.\n\nAction / Repair:\n\nIf AUDIT_TRAIL is not set as recommended, correct the setting."}]}, {"id": "6ae9ac90-de47-444e-98c4-6e8f01bd7102", "checkCategory": "HOST", "checkID": "841A3A9F4A74AC6AE040E50A1EC03FC0", "checkType": "OS", "checkName": "Oracle database software owner hard nofile shell limits", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Oracle database software owner hard nofile shell limit is configured according to recommendation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - ORACLE DATABASE SOFTWARE OWNER HARD NOFILE SHELL LIMITS\n\n\n\n\noracle user's hard nofile shell limit = 400000"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Oracle database software owner hard nofile shell limit is configured according to recommendation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - ORACLE DATABASE SOFTWARE OWNER HARD NOFILE SHELL LIMITS\n\n\n\n\noracle user's hard nofile shell limit = 400000"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThe hard nofile shell limit for the Oracle database software install owner as defined in /etc/security/limits.conf should be &gt;= 65536.\n\nRisk:\n\nResource starvation (file descriptors) leading to node instability\n"}, {"id": "e13bda17-c0d1-440d-9981-048ea7455681", "title": "Links", "links": [{"hyperlink": "http://docs.oracle.com/cd/E11882_01/install.112/e41961/prelinux.htm#CWLIN249", "text": "Setting Resource Limits for the Oracle Software Installation Users"}]}]}, {"id": "5e2dd182-c8ac-417f-8944-65a2038cbb07", "checkCategory": "HOST", "checkID": "841F0977B92F0185E040E50A1EC070BB", "checkType": "OS", "checkName": "Oracle database software owner soft nproc shell limit", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Oracle database software owner soft nproc shell limit  is configured according to recommendation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - ORACLE DATABASE SOFTWARE OWNER SOFT NPROC SHELL LIMIT\n\n\n\n\noracle user's soft nproc shell limit = 400000"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Oracle database software owner soft nproc shell limit  is configured according to recommendation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - ORACLE DATABASE SOFTWARE OWNER SOFT NPROC SHELL LIMIT\n\n\n\n\noracle user's soft nproc shell limit = 400000"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThe soft nproc shell limit for the Oracle DB software install owner as defined in /etc/security/limits.conf should be &gt;= 2047.\n\nRisk:\n\nThe soft nproc shell limit for the Oracle DB software install owner as defined in /etc/security/limits.conf should be &gt;= 2047.  As long as the soft nproc limit is 2047 or above then the configuration should be OK.\n\n\n\nAction / Repair:\n\nChange DB software install owner soft nproc shell limit\n\n$ ulimit -Su\n2047\n\n"}, {"id": "98f3cc09-bea7-4f89-a1ac-f60d7dd246cc", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=169706.1", "text": "Note: 169706.1 - Oracle Database OS Installation and Configuration Requirements Quick Reference"}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=788480.1", "text": "Note: 788480.1 - Resource Limits Using /etc/security/limits.conf and /etc/profile"}]}]}, {"id": "6ceafc91-0b9a-49b2-aa45-9ca3298db5a7", "checkCategory": "HOST", "checkID": "90BD82FA9652F1ABE053D298EB0A8589", "checkType": "OS_OUT_CHECK", "checkName": "Verify available ksplice fixes are installed [Database Server]", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "All available ksplice fixes are installed, or ksplice not in use"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR VERIFY AVAILABLE KSPLICE FIXES ARE INSTALLED [DATABASE SERVER]\n\n\n\nSUCCESS:All available ksplice updates are installed."}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "All available ksplice fixes are installed, or ksplice not in use"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR VERIFY AVAILABLE KSPLICE FIXES ARE INSTALLED [DATABASE SERVER]\n\n\n\nSUCCESS:All available ksplice updates are installed."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nOn Exadata systems some Oracle Linux operating system updates are delivered via ksplice. All available ksplice updates should be installed to ensure issues fixed in the installed Exadata release are not encountered.\n\nRisk:\n\nNot having all available ksplice updates installed can lead to unexpected behavior caused by encountering issues that are expected to be fixed in the installed Exadata release. The risk of checking that all available ksplice updates are installed is minimal.\n\nAction / Repair:\n\nTo verify all available ksplice updates are installed run the following command set as the root user on each database and storage server:\n\nif rpm -qa|grep -q uptrack-updates-$(uname -r)\nthen\n  RAW_UPTRACK_SHOW=$(uptrack-show --available 2&gt;&1)\n  availUpdates=$(echo \"$RAW_UPTRACK_SHOW\" | grep -A1 'Available updates:' | tail -1)\n  if [[ \"$availUpdates\" == 'None' ]]\n  then\n    echo 'SUCCESS: All available ksplice updates are installed.'\n  else\n    echo -e \"FAIL: All available ksplice updates are not installed. Run 'uptrack-install --all -y' as the root user.  Details:\\n$RAW_UPTRACK_SHOW\"\n  fi\nelse\n  echo 'SUCCESS: ksplice updates are not used on this system.'\nfi\n\nThe expected output is the following:\n\nSUCCESS: All available ksplice updates are installed.\n\n-- OR --\n\nSUCCESS: ksplice updates are not used on this system.\n\nExample of a FAIL result:\n\nFAIL: All available ksplice updates are not installed. Run 'uptrack-install --all -y' as the root user.  Details:\nAvailable updates:\n[8x4eqo27] Improved fix to CVE-2018-3620, CVE-2018-3646: Information leak in Intel CPUs under terminal fault.\n\nEffective kernel version is 4.1.12-94.8.6.el6uek\n\nIf there are available ksplice updates not installed then run uptrack-install as the root user, as follows:\n\n# uptrack-install --all -y"}]}, {"id": "9a10dd78-ac7f-4e0c-90ca-be2d08b078be", "checkCategory": "HOST", "checkID": "935C913EDAB919C3E053D198EB0A3995", "checkType": "OS", "checkName": "Verify Exafusion Memory Lock Configuration", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:/u01/app/oracle/product/21.0.0.0/dbhome_1", "status": "success", "statusLabel": "PASS", "output": "Memlock settings meet the Oracle best practice recommendations"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - /u01/app/oracle/product/21.0.0.0/dbhome_1 DATABASE_HOME - Verify Exafusion Memory Lock Configuration\n\n\n\n\nSUCCESS:Memlock settings meet the Oracle best practices\nSettings found:\n\n* hard memlock 32768\n* soft memlock 32768\noracle    soft     memlock     unlimited\noracle    hard     memlock     unlimited\n*    soft     memlock  32768\n*    hard     memlock  32768"}}]}, {"attr": {"target": "scaqal03adm06vm01:/u01/app/oracle/product/21.0.0.0/dbhome_1", "status": "success", "statusLabel": "PASS", "output": "Memlock settings meet the Oracle best practice recommendations"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - /u01/app/oracle/product/21.0.0.0/dbhome_1 DATABASE_HOME - Verify Exafusion Memory Lock Configuration\n\n\n\n\nSUCCESS:Memlock settings meet the Oracle best practices\nSettings found:\n\n* hard memlock 32768\n* soft memlock 32768\noracle    soft     memlock     unlimited\noracle    hard     memlock     unlimited\n*    soft     memlock  32768\n*    hard     memlock  32768"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nHaving memlock set correctly is required for a successful upgrade to releases 12.2 and higher, and also to prevent ORA- errors associated with IPC context initialization. The impact of verifying the Exafusion memory lock configuration is minimal. Following any modifications to the limits.conf settings, a logout/login is required for the OS user to ensure the changes take effect.\n\n    NOTE: The memlock settings should be correct according to recommendations regardless of whether Exafusion is actually being used or not (it is enabled by default in 12.2).\n\nRisk:\n\nInstance startup will fail, and/or clients will fail to connect if memlock settings are insufficient. \n\nAction / Repair:\n\nTo verify Exafusion memory lock configuration, run Exachk and review the provided report.\n\nIn the \"Findings Passed\" summary section of the report, the overall result should be \"PASS\":\n\nPASS   OS Check   Memlock settings meet the Oracle best practice recommendations      All Database Servers   View\n\nIn the \"View\" detail section of the report for this check the expected output should be similar to:\n\nStatus on randomadm05vm01:\nPASS =&gt; Memlock settings meet the Oracle best practice recommendations\n\nDATA FROM RANDOMADM05VM01 - VERIFY EXAFUSION MEMORY LOCK CONFIGURATION \n\nSUCCESS: Memlock settings meet the Oracle best practices\n\nIn the \"View\" detail section of the report for this check a \"FAILURE\" example will be similar to:\n\nStatus on random01client01:/u01/app/ora11g/product/11.2.0.4/dbhome_1:\nFAIL =&gt; Memlock settings do not meet the Oracle best practice recommendations\n\nDATA FROM random01client01 - /u01/app/ora11g/product/11.2.0.4/dbhome_1 DATABASE_HOME - Verify Exafusion Memory Lock Configuration \n\n\n\n\nFAILURE: the following required memlock settings are missing in ()\n------\noradb11g hard memlock unlimited\noradb11g soft memlock unlimited\n------\n FAILURE: oradb11g must have an unlimited setting (oradb11g hard memlock 237284280 file:/opt/vw_30657605/.exachk_120720_180218/.exachk_120720_180218/limits_copy.conf)\n FAILURE: oradb11g must have an unlimited setting (oradb11g soft memlock 237284280 file:/opt/vw_30657605/.exachk_120720_180218/.exachk_120720_180218/limits_copy.conf)\n\nIf a \"FAILURE\" or \"WARNING\" message appears, make the necessary edits to \"/etc/security/limits.conf\" and files under \"/etc/security/limits.d/\" as directed.\n\n    NOTE: If after corrective actions are completed, you wish to run just this review manually without a full Exachk run, as the \"root\" userid in the directory in which Exachk was installed, execute the following:\n\n    ./exachk -check 935C913EDAB919C3E053D198EB0A3995"}]}, {"id": "20d15e67-2ede-405a-8c4f-733812202022", "checkCategory": "ASM", "checkID": "9AC3FDBB9F8B8500E040E50A1EC06311", "checkType": "OS", "checkName": "ASM allocation unit size for all disk groups", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "All disk groups have allocation unit size set to 4MB"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - ASM ALLOCATION UNIT SIZE FOR ALL DISK GROUPS\n\n\n\nASM DATAC1.au_size = 4194304\nASM RECOC1.au_size = 4194304"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nIn order to achieve fast disk scan rates with today's disk technology, it is important that segments be laid out on disk with at least 4MB of contiguous disk space. This allows disk scans to read 4MB of data from disk before having to perform a seek to another location on disk and therefore ensures that most of the time during a scan is spent transferring data from disk.\n\n\n\nRisk:\n\nTime could be spent seeking between disk locations for data. \n\n\n\nAction / Repair:\n\nTo ensure that segments are laid out with 4MB of contiguous data on disk, you will need to set the ASM allocation unit (AU) size to 4MB and ensure that data file extents are at least 4MB in size. The ASM allocation unit can be specified when a disk group is created. For Exadata, we recommend setting the AU size to 4MB. The ASM allocation unit size (AU_SIZE) can be set at disk group creation time as can be seen in the following example:\n\nCREATE diskgroup data normal redundancy \nDISK 'o/*/DATA*'\nATTRIBUTE \n          'AU_SIZE' = '4M',\n          'cell.smart_scan_capable'='TRUE',\n          'compatible.rdbms'='11.2.0.0', \n          'compatible.asm'='11.2.0.0';"}]}, {"id": "e5bc2dcf-b540-4430-b5ec-88d9fb6800a2", "checkCategory": "ASM", "checkID": "9AC6EB87F321A478E040E50A1EC03CC3", "checkType": "OS", "checkName": "ASM Cell smart scan", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "All disk groups have CELL.SMART_SCAN_CAPABLE parameter set to true"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - ASM CELL SMART SCAN\n\n\n\nASM DATAC1.cell.smart_scan_capable = TRUE\nASM RECOC1.cell.smart_scan_capable = TRUE"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThe components in the I/O stack are tightly integrated in Exadata. You must use the proper versions of software both on the storage servers and the database servers. Setting compatible attributes defines available functionality. Setting CELL.SMART_SCAN_CAPABLE enables the offloading of certain query work to the storage servers. Setting AU_SIZE maximizes available disk technology and throughput by reading 4MB of data before performing a disk seek to a new sector location.\nThere is minimal impact to verify and configure these settings.\n\n\nRisk:\n\nIf these attributes are not set as directed, performance will be sub-optimal.\n\n\n\nAction / Repair:\n\nFor the ASM disk group containing Oracle Exadata Storage Server grid disks, verify the attribute settings as follows:\nCOMPATIBLE.ASM attribute is set to the Oracle ASM software version in use.\nCOMPATIBLE.RDBMS attribute is set to the Oracle database software version in use.\nCELL.SMART_SCAN_CAPABLE attribute is TRUE.\nAU_SIZE attribute is 4M.\nIf these attributes are not set properly, correct the condition."}]}, {"id": "e1ae8855-1346-494c-bc89-d70006e8d427", "checkCategory": "ASM", "checkID": "E1343A1CE2383400E04313C0E50A0F82", "checkType": "OS", "checkName": "ASM disk group compatible.asm attribute", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "All disk groups have compatible.asm attribute set to recommended values"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - ASM DISK GROUP COMPATIBLE.ASM ATTRIBUTE\n\n\n\nOracle Clusterware active version on the cluster is [21.0.0.0.0]\n\nASM DATAC1.compatible.asm = 21.0.0.0.0\nASM RECOC1.compatible.asm = 21.0.0.0.0"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThe components in the I/O stack are tightly integrated in Exadata. You must use the proper versions of software both on the storage servers and the database servers. Setting compatible attributes defines available functionality. Setting CELL.SMART_SCAN_CAPABLE enables the offloading of certain query work to the storage servers. Setting AU_SIZE maximizes available disk technology and throughput by reading 4MB of data before performing a disk seek to a new sector location.\n\nThere is minimal impact to verify and configure these settings.\n\n\n\nRisk:\n\nIf these attributes are not set as directed, performance will be sub-optimal.\n\n\n\nAction / Repair:\n\nFor the ASM disk group containing Oracle Exadata Storage Server grid disks, verify the attribute settings as follows: \n\n     * COMPATIBLE.ASM attribute is set to the Oracle ASM version in use.\n     * COMPATIBLE.RDBMS attribute is set to the minimum Oracle database software version in use. \n     * CELL.SMART_SCAN_CAPABLE attribute is TRUE. \n     * AU_SIZE attribute is 4M. \n\nIf compatible.rdbms is not set properly, then the rdbms software version and database must be upgraded or the diskgroup must be recreated. "}]}, {"id": "c0179722-c972-423c-9156-7835630848dc", "checkCategory": "CRS", "checkID": "9AD3948CEED6219DE040E50A1EC030AA", "checkType": "OS", "checkName": "Verify Cluster Synchronization Services (CSS) misscount value", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Cluster Synchronization Services (CSS) misscount value is set as recommended"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY CLUSTER SYNCHRONIZATION SERVICES (CSS) MISSCOUNT VALUE\n\n\n\nSUCCESS:recommended value:30  Value found:30"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nCluster Synchronization Services (CSS) misscount affects the impact and timing of a clusterware node eviction. Please see the table below for recommendations and comments.\n\n    NOTE: Exadata has a feature called Instant Failure Detection (or Fast Node Death Detection) which does not rely on CSS misscount. The node evictions referenced in this section are only the more rare types that cannot use this feature. \n\nCSS Misscount Value Table\n\nVALUE \tALERT LEVEL \tNOTES\n15 \tSUCCESS \tThis value is only for Autonomous Database Cloud environments which are specifically designed to optimize availability using a lower CSS misscount\n30 \tSUCCESS \tRecommended to minimize application service level impact during node evictions\nless than 30 \tCRITICAL \tIncreases the risk of a false postive node eviction\n(except the value of 15 for Autonomous Database Cloud environments)\ngreater than 60 \tFAILURE \tDelays a node eviction longer than necessary, and can impact many application service levels\n31 to 60 \tWARNING \tDelays a node eviction, and can impact some application service levels\n\n    NOTE: In grid version 11.2.x 60 is the default and recommended value. If you are still running 11.2.x grid, a value of \"60\" will return \"SUCCESS\". Customers are urged to upgrade to more recent grid versions that support a CSS misscount value of 30.\n\n\n\nRisk:\n\nThe risk of setting CSS misscount too low is hitting false positive node evictions. The risk of setting CSS misscount too high is delaying node evictions which can impact application service levels.\n\n\n\nAction / Repair:\n\nTo verify Cluster Synchronization Services (CSS) misscount value, run Exachk and review the provided report.\n\nThe expected output in the Exachk report should be as follows:\n\nIn the \"Findings Passed\" summary section of the report, the overall result should be \"PASS\":\n\nPASS   OS Check   Cluster Synchronization Services (CSS) misscount value is set as recommended   All Database Servers   \nView\n\nIn the \"View\" detail section of the report for each individual database server:\n\nStatus on random01client01:\nPASS =&gt; Cluster Synchronization Services (CSS) misscount value is set as recommended\n\nDATA FROM RANDOM01CLIENT01 - VERIFY CLUSTER SYNCHRONIZATION SERVICES (CSS) MISSCOUNT VALUE \nSUCCESS: recommended value: 30  Value found: 30\n\nExamples of other \"SUCCESS\" details:\n\nSUCCESS: ADB only recommended value: 15  Value found: 15\n\n-- OR --\n\nSUCCESS: 11.2 only recommended value: 60  Value found: 60\n\nExample of a \"CRITICAL\" result:\n\nCRITICAL: recommended value: 30  Value found: 25\n\n-- OR --\n\nCRITICAL: ADB only recommended value: 15  Value found: 30\n\n-- OR --\n\nCRITICAL: 11.2 only recommended value: 60  Value found: 90\n\nExample of a \"FAILURE\" result:\n\nFAILURE: recommended value: 30  Value found: 65\n\nExample of a \"WARNING\" result:\n\nWARNING: recommended value: 30  Value found: 45\n\nTo set the recommended CSS misscount value, as the owner userid of the grid home and with the environment properly set, execute the following code on a database server (takes effect on all nodes in a cluster without an Oracle Clusterware restart):\n\n$&lt;GI_HOME&gt;/bin/crsctl set css misscount 30\n\nThe output will be similar to:\n\nCRS-4684: Successful set of parameter misscount to 30 for Cluster Synchronization Services\n\n    NOTE: If after corrective actions are completed, you wish to run just this review manually without a full Exachk run, as the \"root\" userid execute the following Exachk command:\n\n    exachk -check 9AD3948CEED6219DE040E50A1EC030AA\n"}, {"id": "3f87f916-d4b3-4d6a-98c6-0912508aae44", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1274322.1", "text": "Note: 1274322.1 - Oracle Sun Database Machine X2-2/X2-8 , X3-2/X3-8 and X4-2 High Availability Best Practices"}]}]}, {"id": "52ccc89a-caa2-4ec1-bb9a-8e2443b991a3", "checkCategory": "ASM", "checkID": "9AEA5B4309122458E040E50A1EC00947", "checkType": "OS", "checkName": "ASM Version", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "ASM Version is 11.2.0.2 or higher as expected"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - ASM VERSION\n\n\n\nversion = 21.0.0.0.0"}}]}, {"attr": {"target": "scaqal03adm06vm01:+ASM2", "status": "success", "statusLabel": "PASS", "output": "ASM Version is 11.2.0.2 or higher as expected"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - ASM VERSION\n\n\n\nversion = 21.0.0.0.0"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThe components in the I/O stack are tightly integrated in Exadata. You must use the proper versions of software both on the storage servers and the database servers.\nThere is minimal impact to verify the ASM version.\n\n\n\nRisk:\n\nIf the ASM version is not correct, the database(s) will not be able to communicate with the storage servers via ASM.\n\n\n\nAction / Repair:\n\nVerify the Oracle ASM software is version 11.2.0.2 or higher\nIf it is not, correct the condition."}]}, {"id": "a7472132-215c-424f-a460-eb4b0f200378", "checkCategory": "RDBMS", "checkID": "9AEC773863DD7767E040E50A1EC07703", "checkType": "SQL", "checkName": "RDBMS Version", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "success", "statusLabel": "PASS", "output": "RDBMS Version is 11.2.0.2 or higher as expected"}, "children": [{"attr": {"consoleOutput": "\n\nRDBMS_VERSION\n--------------------------\nRDBMS Version = 21.0.0.0.0"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "The RBMS version for X2-2 is expected to be 11.2.0.2 or higher."}]}, {"id": "36d6d0de-d666-4fd5-b111-e6002b872998", "checkCategory": "RDBMS", "checkID": "9B7D18667DE524ACE040E50A1EC07F2B", "checkType": "SQL_PARAM", "checkName": "Check for parameter filesystemio_options", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "filesystemio_options is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "filesystemio_options is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Ensures both async and direct IO are used when accessing filesystems. This improves performance for filesystem I/O (ex: data loads). This does not affect database IO for Exadata because the database is stored in ASM."}, {"id": "85b87bdf-22a1-43b3-b4a5-2b05d72a72f6", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1274318.1", "text": "Note: 1274318.1 - Oracle Sun Database Machine X2-2 Setup/Configuration Best Practices (Doc ID 1274318.1)"}]}]}, {"id": "d097346d-eac3-48ae-b1db-3a84656a6a69", "checkCategory": "RDBMS HOME", "checkID": "9BB83C959994CEE5E040E50A1EC0094E", "checkType": "OS", "checkName": "Verify RDS Protocol is used for interprocess communication [Database Home]", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:/u01/app/oracle/product/21.0.0.0/dbhome_1", "status": "success", "statusLabel": "PASS", "output": "Oracle database(s) are using RDS protocol for inter process communication"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - /u01/app/oracle/product/21.0.0.0/dbhome_1 DATABASE_HOME - Verify RDS Protocol is used for interprocess communication [Database Home]\n\n\n\nrds"}}]}, {"attr": {"target": "scaqal03adm06vm01:/u01/app/oracle/product/21.0.0.0/dbhome_1", "status": "success", "statusLabel": "PASS", "output": "Oracle database(s) are using RDS protocol for inter process communication"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - /u01/app/oracle/product/21.0.0.0/dbhome_1 DATABASE_HOME - Verify RDS Protocol is used for interprocess communication [Database Home]\n\n\n\nrds"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThe RDS protocol provides superior performance because it avoids additional memory buffering operations when moving data from process memory to the network interface for IO operations. This includes both IO operations between the Oracle instance and the storage servers, as well as instance to instance block transfers via Cache Fusion.\n\nThere is minimal impact to verify that the RDS protocol is in use. Implementing the RDS protocol requires an outage to relink the Oracle software.\n\nRisk:\n\nIf the RDS protocol is not used, IO operations will be sub-optimal.\n\n\nAction / Repair:\n\nTo validate an ORACLE_HOME:\nAs the owner userid of the ORACLE_HOME, set the ORACLE_HOME and LD_LIBRARY_PATH variables properly and execute the following command:\n\n$ORACLE_HOME/bin/skgxpinfo\n\nThe output should be:\n\nrds\n\nTo validate a CRS_HOME:\nAs the owner userid of the CRS_HOME, set the CRS_HOME and LD_LIBRARY_PATH variables properly and execute the following command:\n\n$CRS_HOME/bin/skgxpinfo\n\nThe output should be:\n\nrds\n\nIf the RDS protocol is not being used, the appropriate binaries must be relinked.\n\n    NOTE: In all cases, do not use the \"relink all\" command due to various issues. Use the make commands provided. \n\nTo relink an ORACLE_HOME:\nAs the owner userid of the ORACLE_HOME execute the following steps with all necessary variables properly set:\n\n    Shutdown any processes using the ORACLE_HOME\n    \"cd $ORACLE_HOME/rdbms/lib\"\n    \"make -f ins_rdbms.mk ipc_rds ioracle\"\n    Restart any processes using the ORACLE_HOME \n\nTo relink a CRS_HOME:\n\n    NOTE: The following instructions are for Oracle stack versions 12.2 or higher:\n\nAs the owner userid of the CRS_HOME (and the \"root\" userid for some steps) execute the following steps with all necessary variables properly set:\n\n    As the \"root\" userid, stop the clusterware runnning out of the CRS_HOME\n    As the \"root\" userid, execute \"$CRS_HOME/crs/install/rootcrs.sh -unlock\"\n    \"cd $CRS_HOME/rdbms/lib\"\n    \"make -f ins_rdbms.mk ipc_rds ioracle\"\n    As the \"root\" userid, execute \"$CRS_HOME/crs/install/rootcrs.sh -lock\"\n    As the \"root\" userid, start the clusterware runnning out of the CRS_HOME\n    After a few minutes, as the \"root\" userid verify all expected resources are executing with \"$CRS_HOME/bin/crsctl stat res -t\" \n\n    NOTE: The following instructions are for Oracle stack versions 12.1 or lower (including 11.2.x):\n\nAs the owner userid of the CRS_HOME (and the \"root\" userid for some steps) execute the following steps with all necessary variables properly set:\n\n    As the \"root\" userid, stop the clusterware runnning out of the CRS_HOME\n    As the \"root\" userid, execute \"$CRS_HOME/crs/install/rootcrs.pl -unlock\"\n    \"cd $CRS_HOME/rdbms/lib\"\n    \"make -f ins_rdbms.mk ipc_rds ioracle\"\n    As the \"root\" userid, \"$CRS_HOME/crs/install/rootcrs.pl -patch\"\n    After a few minutes, as the \"root\" userid verify all expected resources are executing with \"$CRS_HOME/bin/crsctl stat res -t\" "}]}, {"id": "830cb818-cb70-412f-8fa1-d501f68f6f93", "checkCategory": "HOST", "checkID": "9BB8CFEE59ECE60DE040E50A1EC01D04", "checkType": "OS", "checkName": "Free space in root file system", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Free space in root(/) filesystem meets or exceeds recommendation."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - FREE SPACE IN ROOT FILE SYSTEM\n\n\n\nFilesystem                    Size  Used Avail Use% Mounted on\n/dev/mapper/VGExaDb-LVDbSys1   15G  9.3G  5.8G  62% /"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Free space in root(/) filesystem meets or exceeds recommendation."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - FREE SPACE IN ROOT FILE SYSTEM\n\n\n\nFilesystem                    Size  Used Avail Use% Mounted on\n/dev/mapper/VGExaDb-LVDbSys1   15G  7.7G  7.4G  51% /"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nBest Practice, Proactive problem avoidance\n\n\n\nRisk:\n\nroot filesystem has 20% or less free space remaining.  Action should be taken to free up space in order to avoid potential problems from lack of space in the root filesystem.\n\n\n\nAction / Repair:\n\nFree up space in the root filesystem"}]}, {"id": "543305d3-c868-4470-b9e8-19978697d18d", "checkCategory": "ASM", "checkID": "9DEBED7B8DAB583DE040E50A1EC01BA0", "checkType": "OS", "checkName": "Manage ASM Audit File Directory Growth with cron", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "ASM Audit file destination file count <= 100,000"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - MANAGE ASM AUDIT FILE DIRECTORY GROWTH WITH CRON\n\n\n\nNumber of audit files at /u01/app/21.0.0.0/grid/rdbms/audit = 313"}}]}, {"attr": {"target": "scaqal03adm06vm01:+ASM2", "status": "success", "statusLabel": "PASS", "output": "ASM Audit file destination file count <= 100,000"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - MANAGE ASM AUDIT FILE DIRECTORY GROWTH WITH CRON\n\n\n\nNumber of audit files at /u01/app/21.0.0.0/grid/rdbms/audit = 96"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThe audit file destination directories for an ASM instance can grow to contain a very large number of files if they are not regularly maintained. Use the Linux cron(8) utility and the find(1) command to manage the number of files in the audit file destination directories.\n\nThe impact of using cron(8) and find(1) to manage the number of files in the audit file destination directories is minimal.\n\n\n\nRisk:\n\nHaving a very large number of files can cause the file system to run out of free disk space or inodes, or can cause Oracle to run very slowly due to file system directory scaling limits, which can have the appearance that the ASM instance is hanging on startup.\n\n\n\nAction / Repair:\n\nRefer to the referenced MOS Note"}, {"id": "845a7cd8-a506-4cc1-bb6b-472cf2a54cee", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=1298957.1", "text": "Note: 1298957.1 - Manage Audit File Directory Growth with cron"}]}]}, {"id": "fdb7fb7c-aa60-4b2b-96f9-0230288bb106", "checkCategory": "HOST", "checkID": "9E004BDDCDECD90EE040E50A1EC06302", "checkType": "OS_OUT_CHECK", "checkName": "Verify Data Network is Separate from Management Network", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Management network is separate from data network"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR VERIFY DATA NETWORK IS SEPARATE FROM MANAGEMENT NETWORK\n\n\n\nifcfg-bondeth0:NETWORK=10.214.208.0\nifcfg-eth0:NETWORK=10.214.192.0\nifcfg-re0:NETWORK=192.168.0.0\nifcfg-re1:NETWORK=192.168.0.0"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Management network is separate from data network"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR VERIFY DATA NETWORK IS SEPARATE FROM MANAGEMENT NETWORK\n\n\n\nifcfg-bondeth0:NETWORK=10.214.208.0\nifcfg-eth0:NETWORK=10.214.192.0\nifcfg-re0:NETWORK=192.168.0.0\nifcfg-re1:NETWORK=192.168.0.0"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nIt is a requirement that the management network be on a different non-overlapping sub-net than the InfiniBand network and the client access network. This is necessary for better network security, better client access bandwidths, and for Auto Service Request (ASR) to work correctly.\nThe management network is comprised of the eth0 network interface in the database and storage servers, the ILOM network interfaces of the database and storage servers, and the Ethernet management interfaces of the InfiniBand switches and PDUs.\n\n\nRisk:\n\nHaving the management network on the same subnet as the client access network will reduce network security, potentially restrict the client access bandwidth to/from the Database Machine to a single 1GbE link, and will prevent ASR from working correctly.\n\n\nAction / Repair:\n\nTo verify that the management network interface (eth0) is on a separate network from other network interfaces, execute the following command as the \"root\" userid on both storage and database servers:\ngrep -i network /etc/sysconfig/network-scripts/ifcfg* | cut -f5 -d\"/\" | grep -v \"#\"\n \nThe output will be similar to:\nifcfg-bondeth0:NETWORK=10.204.77.0\nifcfg-bondib0:NETWORK=192.168.76.0\nifcfg-eth0:NETWORK=10.204.78.0\nifcfg-lo:NETWORK=127.0.0.0\nThe expected result is that the network values are different. If they are not, investigate and correct the condition."}]}, {"id": "902e2e2d-b645-4057-bb04-e6f79777f1e6", "checkCategory": "CRS HOME", "checkID": "9EB3D82B8232CFAEE040E50A1EC04D89", "checkType": "OS", "checkName": "GRID owner shell limits soft nofile", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Shell limit soft nofile for GRID owner is configured according to recommendation in /etc/security/limits.conf"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - GRID OWNER SHELL LIMITS SOFT NOFILE\n\n\n\n\n\n* hard maxlogins 1000\n\n* soft stack 10240\n\n* hard core 0\n\n* hard memlock 32768\n\n* soft memlock 32768\n\n\noracle    soft     core 0\noracle    hard     core 0\noracle    soft     nproc 400000\noracle    hard     nproc 400000\noracle    soft     nofile 400000\noracle    hard     nofile 400000\noracle    soft     memlock     unlimited\noracle    hard     memlock     unlimited\noracle    soft     stack       10240\n\n\n*    soft     memlock  32768\n*    hard     memlock  32768"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Shell limit soft nofile for GRID owner is configured according to recommendation in /etc/security/limits.conf"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - GRID OWNER SHELL LIMITS SOFT NOFILE\n\n\n\n\n\n* hard maxlogins 1000\n\n* soft stack 10240\n\n* hard core 0\n\n* hard memlock 32768\n\n* soft memlock 32768\n\n\noracle    soft     core 0\noracle    hard     core 0\noracle    soft     nproc 400000\noracle    hard     nproc 400000\noracle    soft     nofile 400000\noracle    hard     nofile 400000\noracle    soft     memlock     unlimited\noracle    hard     memlock     unlimited\noracle    soft     stack       10240\n\n\n*    soft     memlock  32768\n*    hard     memlock  32768"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "The soft nofile shell limit for the Oracle GI software install owner defined in /etc/security/limits.conf should be &gt;= 1024."}]}, {"id": "64bf9299-7dd3-4b62-aed3-626f2cacc9ea", "checkCategory": "CRS HOME", "checkID": "9EB72ABADE01FED3E040E50A1EC075AF", "checkType": "OS", "checkName": "GRID owner shell limits soft nproc", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Shell limit soft nproc for GRID owner is configured according to recommendation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - GRID OWNER SHELL LIMITS SOFT NPROC\n\n\n\n\n\n* hard maxlogins 1000\n\n* soft stack 10240\n\n* hard core 0\n\n* hard memlock 32768\n\n* soft memlock 32768\n\n\noracle    soft     core 0\noracle    hard     core 0\noracle    soft     nproc 400000\noracle    hard     nproc 400000\noracle    soft     nofile 400000\noracle    hard     nofile 400000\noracle    soft     memlock     unlimited\noracle    hard     memlock     unlimited\noracle    soft     stack       10240\n\n\n*    soft     memlock  32768\n*    hard     memlock  32768"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Shell limit soft nproc for GRID owner is configured according to recommendation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - GRID OWNER SHELL LIMITS SOFT NPROC\n\n\n\n\n\n* hard maxlogins 1000\n\n* soft stack 10240\n\n* hard core 0\n\n* hard memlock 32768\n\n* soft memlock 32768\n\n\noracle    soft     core 0\noracle    hard     core 0\noracle    soft     nproc 400000\noracle    hard     nproc 400000\noracle    soft     nofile 400000\noracle    hard     nofile 400000\noracle    soft     memlock     unlimited\noracle    hard     memlock     unlimited\noracle    soft     stack       10240\n\n\n*    soft     memlock  32768\n*    hard     memlock  32768"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "The soft nproc shell limit for the Oracle GI software install owner defined in /etc/security/limits.conf should be &gt;= 2047."}]}, {"id": "4e983648-8f38-4ebd-a47f-60ee9a6da892", "checkCategory": "CRS HOME", "checkID": "9EB7E9577DD69A73E040E50A1EC01AF6", "checkType": "OS", "checkName": "GRID owner shell limits hard nofile", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Shell limit hard nofile for GRID owner is configured according to recommendation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - GRID OWNER SHELL LIMITS HARD NOFILE\n\n\n\n\n\n* hard maxlogins 1000\n\n* soft stack 10240\n\n* hard core 0\n\n* hard memlock 32768\n\n* soft memlock 32768\n\n\noracle    soft     core 0\noracle    hard     core 0\noracle    soft     nproc 400000\noracle    hard     nproc 400000\noracle    soft     nofile 400000\noracle    hard     nofile 400000\noracle    soft     memlock     unlimited\noracle    hard     memlock     unlimited\noracle    soft     stack       10240\n\n\n*    soft     memlock  32768\n*    hard     memlock  32768"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Shell limit hard nofile for GRID owner is configured according to recommendation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - GRID OWNER SHELL LIMITS HARD NOFILE\n\n\n\n\n\n* hard maxlogins 1000\n\n* soft stack 10240\n\n* hard core 0\n\n* hard memlock 32768\n\n* soft memlock 32768\n\n\noracle    soft     core 0\noracle    hard     core 0\noracle    soft     nproc 400000\noracle    hard     nproc 400000\noracle    soft     nofile 400000\noracle    hard     nofile 400000\noracle    soft     memlock     unlimited\noracle    hard     memlock     unlimited\noracle    soft     stack       10240\n\n\n*    soft     memlock  32768\n*    hard     memlock  32768"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "The hard nofile shell limit for the Oracle GI software install owner defined in /etc/security/limits.conf should be &gt;= 65536."}]}, {"id": "47aa0b99-d90b-4dc1-b976-be70b0951a22", "checkCategory": "CRS HOME", "checkID": "9EB7E9577DD79A73E040E50A1EC01AF6", "checkType": "OS", "checkName": "GRID owner shell limits hard nproc", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Shell limit hard nproc for GRID owner  is configured according to recommendation in /etc/security/limits.conf"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - GRID OWNER SHELL LIMITS HARD NPROC\n\n\n\noracle    hard     core 0\noracle    hard     nproc 400000\noracle    hard     nofile 400000\noracle    hard     memlock     unlimited"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Shell limit hard nproc for GRID owner  is configured according to recommendation in /etc/security/limits.conf"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - GRID OWNER SHELL LIMITS HARD NPROC\n\n\n\noracle    hard     core 0\noracle    hard     nproc 400000\noracle    hard     nofile 400000\noracle    hard     memlock     unlimited"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "The hard nproc shell limit for the Oracle GI software install owner defined in /etc/security/limits.conf should be &gt;= 16384."}]}, {"id": "b1b48e36-2595-4735-a176-07a55d8bf492", "checkCategory": "HOST", "checkID": "9EB84272626BFF6EE040E50A1EC02AF3", "checkType": "OS", "checkName": "Oracle database software owner hard nproc shell limits", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Oracle database software owner hard nproc shell limits is configured according to recommendation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - ORACLE DATABASE SOFTWARE OWNER HARD NPROC SHELL LIMITS\n\n\n\n\noracle user's hard nproc shell limit = 400000"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Oracle database software owner hard nproc shell limits is configured according to recommendation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - ORACLE DATABASE SOFTWARE OWNER HARD NPROC SHELL LIMITS\n\n\n\n\noracle user's hard nproc shell limit = 400000"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nDocumented value, cluster stability\n\nThe hard nproc shell limit for the Oracle DB software install owner as defined in /etc/security/limits.conf should be &gt;= 16384.\n\n\n\nRisk:\n\nResource starvation (processes) leading to node instability\n\n\n\nAction / Repair:\n\nChange DB software install owner hard nproc shell limit\n"}]}, {"id": "b23cf7ae-58e1-4ab6-ab1e-9fcf0ab79731", "checkCategory": "HOST", "checkID": "9EB848CDD040ACADE040E50A1EC01840", "checkType": "OS", "checkName": "Oracle database software owner  soft nofile shell limits", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Oracle database software owner  soft nofile shell limits is configured according to recommendation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - ORACLE DATABASE SOFTWARE OWNER  SOFT NOFILE SHELL LIMITS\n\n\n\n\noracle user's soft nofile shell limit = 400000"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Oracle database software owner  soft nofile shell limits is configured according to recommendation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - ORACLE DATABASE SOFTWARE OWNER  SOFT NOFILE SHELL LIMITS\n\n\n\n\noracle user's soft nofile shell limit = 400000"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nDocumented value, cluster stability\n\nThe soft nofile shell limit for the Oracle DB software install owner as defined in /etc/security/limits.conf should be &gt;= 1024.\n\n\n\nRisk:\n\nResource starvation leading to node instability\n\n\n\nAction / Repair:\n\nChange DB software install owner soft nofile shell limit"}]}, {"id": "624bd4a0-a71a-43d3-abe0-fec8dc9cacfd", "checkCategory": "HOST", "checkID": "9EB883858764342DE040E50A1EC0359A", "checkType": "OS", "checkName": "Oracle database software owner hard stack shell limits", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Oracle database software owner hard stack shell limit is configured according to recommendation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - ORACLE DATABASE SOFTWARE OWNER HARD STACK SHELL LIMITS\n\n\n\n\noracle user's hard stack shell limit = unlimited"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Oracle database software owner hard stack shell limit is configured according to recommendation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - ORACLE DATABASE SOFTWARE OWNER HARD STACK SHELL LIMITS\n\n\n\n\noracle user's hard stack shell limit = unlimited"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nDocumented value is the /etc/security/limits.conf file as documented in 11gR2 Grid Infrastructure  Installation Guide, section 2.15.3 Setting Resource Limits for the Oracle Software Installation Users.  \n\nIf the /etc/security/limits.conf file is not configured as described in the documentation then log in to the system as the database software owner (e.g., oracle) and check the hard stack configuration as described below.\n\nRisk:\n\nThe hard stack shell limit for the Oracle DB software install owner as defined in /etc/security/limits.conf should be &gt;= 10240.  As long as the hard stack limit is 10240 or above then the configuration should be OK.\n\n\n\nAction / Repair:\n\nChange DB software install owner hard stack shell limit\n\n$ ulimit -Hs\n10240\n\n"}]}, {"id": "7743d52e-519a-4588-a7e3-6c3253e1a61e", "checkCategory": "HOST", "checkID": "9EB8CACD50DCE0A3E040E50A1EC040B8", "checkType": "OS_OUT_CHECK", "checkName": "GI shell limits hard stack", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Shell limit hard stack for GI is configured according to recommendation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR CRS USER LIMITS CONFIGURATION\n\n\n\nLimit                     Soft Limit           Hard Limit           Units\nMax cpu time              unlimited            unlimited            seconds\nMax file size             unlimited            unlimited            bytes\nMax data size             unlimited            unlimited            bytes\nMax stack size            1572864              unlimited            bytes\nMax core file size        unlimited            unlimited            bytes\nMax resident set          unlimited            unlimited            bytes\nMax processes             400000               400000               processes\nMax open files            400000               400000               files\nMax locked memory         unlimited            unlimited            bytes\nMax address space         unlimited            unlimited            bytes\nMax file locks            unlimited            unlimited            locks\nMax pending signals       2376104              2376104              signals\nMax msgqueue size         819200               819200               bytes\nMax nice priority         0                    0\nMax realtime priority     0                    0\nMax realtime timeout      unlimited            unlimited            us"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Shell limit hard stack for GI is configured according to recommendation"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR CRS USER LIMITS CONFIGURATION\n\n\n\nLimit                     Soft Limit           Hard Limit           Units\nMax cpu time              unlimited            unlimited            seconds\nMax file size             unlimited            unlimited            bytes\nMax data size             unlimited            unlimited            bytes\nMax stack size            1572864              unlimited            bytes\nMax core file size        unlimited            unlimited            bytes\nMax resident set          unlimited            unlimited            bytes\nMax processes             400000               400000               processes\nMax open files            400000               400000               files\nMax locked memory         unlimited            unlimited            bytes\nMax address space         unlimited            unlimited            bytes\nMax file locks            unlimited            unlimited            locks\nMax pending signals       2376104              2376104              signals\nMax msgqueue size         819200               819200               bytes\nMax nice priority         0                    0\nMax realtime priority     0                    0\nMax realtime timeout      unlimited            unlimited            us"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "The hard stack shell limit for the Oracle Grid Infrastructure software install owner as defined in /etc/security/limits.conf should be &gt;= 10240.\n\nWhat's being checked here is the /etc/security/limits.conf file as documented in 11gR2 Grid Infrastructure Installation Guide, section 2.15.3 Setting Resource Limits for the Oracle Software Installation Users.  \n\nIf the /etc/security/limits.conf file is not configured as described in the documentation then to check the hard stack configuration while logged into the software owner account (e.g., grid).\n\n$ ulimit -Hs\n10240\n\nAs long as the hard stack limit is 10240 or above then the configuration should be OK.\n"}]}, {"id": "1881aef6-29a4-40e5-983e-d418c5bc4343", "checkCategory": "CRS", "checkID": "9EC7304AE67BDC2DE040E50A1EC07772", "checkType": "OS", "checkName": "Number of SCAN listeners", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Number of SCAN listeners is equal to the recommended number of 3."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - NUMBER OF SCAN LISTENERS\n\n\n\nSCAN Listeners for network 1:\nRegistration invited nodes:\nRegistration invited subnets:\nEndpoints:TCP:1521\nSCAN Listener LISTENER_SCAN1 exists\nSCAN Listener is enabled.\nSCAN Listener LISTENER_SCAN2 exists\nSCAN Listener is enabled.\nSCAN Listener LISTENER_SCAN3 exists\nSCAN Listener is enabled."}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Number of SCAN listeners is equal to the recommended number of 3."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - NUMBER OF SCAN LISTENERS\n\n\n\nSCAN Listeners for network 1:\nRegistration invited nodes:\nRegistration invited subnets:\nEndpoints:TCP:1521\nSCAN Listener LISTENER_SCAN1 exists\nSCAN Listener is enabled.\nSCAN Listener LISTENER_SCAN2 exists\nSCAN Listener is enabled.\nSCAN Listener LISTENER_SCAN3 exists\nSCAN Listener is enabled."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nApplication scalability and/or availability\n\n\n\nRisk:\n\nPotential reduced scalability and/or availability of applications\n\n\n\nAction / Repair:\n\nThe recommended number of SCAN listeners is 3....  See the referenced document for more details."}, {"id": "6ec6ba8f-a601-4151-bc4c-13c81d86bb66", "title": "Links", "links": [{"hyperlink": "http://www.oracle.com/technetwork/products/clustering/overview/scan-129069.pdf", "text": "Single Client Access Name (SCAN)"}]}]}, {"id": "a997092d-ddfe-42a4-8626-c34657db86d6", "checkCategory": "RDBMS", "checkID": "9EC7304AE67CDC2DE040E50A1EC07772", "checkType": "SQL", "checkName": "AUDSES$ sequence cache size", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "success", "statusLabel": "PASS", "output": "SYS.AUDSES$ sequence cache size >= 10,000"}, "children": [{"attr": {"consoleOutput": "\n\n'AUDSES$.CACHE_SIZE='||CACHE_SIZE\n---------------------------------\naudses$.cache_size = 10000"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nApplication scalability\n\n\n\nRisk:\n\nProblems have been reported with AUDSES$, ORA_TQ_BASE$ and IDGEN1$, which are all internal sequences, if the cache size is too small (e.g., login storms or very high concurrency) and can manifest as waits in \"rowcache\" for \"dc_sequences\" which is a rowcache type for sequences.\n\n\n\nAction / Repair:\n\nIncrease AUDSES$ and ORA_TQ_BASE$ to 10,000\nIncrease IDGEN1$ to a value of 1000\n\nSee referenced Notes.\n"}, {"id": "c167da37-6bec-47bf-84f8-5702a4cea4a6", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=268476.1", "text": "Note: 268476.1 - LOB Performance Guideline"}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=432508.1", "text": "Note: 432508.1 - High SQ Enqueue Contention with LOBs or Advanced Replication"}]}]}, {"id": "2c27ef75-ae0c-46d8-af2f-808960347ebb", "checkCategory": "RDBMS", "checkID": "9EC835C8E11DDE5BE040E50A1EC01CA0", "checkType": "SQL", "checkName": "GC block lost", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "success", "statusLabel": "PASS", "output": "GC blocks lost is not occurring"}, "children": [{"attr": {"consoleOutput": "\n\nTOTAL_BLOCKS_LOST\n----------------------------------------\nNo of GC lost block in last 24 hours = 0"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nOptimal global cache performance \n\n\n\nRisk:\n\nThe RDBMS reports global cache lost block statistics (\"gc cr block lost\" and/or \"gc current block lost\") which could indicate a negative impact on interconnect performance and global cache processing.\n\n\n\nAction / Repair:\n\nThe vast majority of escalations attributed to RDBMS global cache lost blocks can be directly related to faulty or misconfigured interconnects. GC lost blocks diagnostics guide serves as a starting point for evaluating common (and sometimes obvious) causes.\n"}, {"id": "db16ff1f-79ce-4a86-9241-1bfde105bef6", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=563566.1", "text": "Note: 563566.1 - gc lost blocks diagnostics"}]}]}, {"id": "0be02272-bf75-4bb8-8655-99e0ec9eda43", "checkCategory": "RDBMS", "checkID": "9EC9FBCFEC52DF9DE040E50A1EC0633E", "checkType": "SQL", "checkName": "IDGEN$ sequence cache size", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "success", "statusLabel": "PASS", "output": "SYS.IDGEN1$ sequence cache size >= 1,000"}, "children": [{"attr": {"consoleOutput": "\n\n'IDGEN1$.CACHE_SIZE='||CACHE_SIZE\n---------------------------------\nidgen1$.cache_size = 1000"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Sequence contention (SQ enqueue) can occur if SYS.IDGEN1$ sequence is not cached to 1000.  This condition can lead to performance issues in RAC.  1000 is the default starting in version 11.2.0.1."}]}, {"id": "fcf14fc6-609d-422e-b80b-df931804202d", "checkCategory": "CRS", "checkID": "9ECAA32F349F9F29E040E50A1EC06B13", "checkType": "OS", "checkName": "Non-routable network for interconnect", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Interconnect is configured on non-routable network addresses"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - NON-ROUTABLE NETWORK FOR INTERCONNECT\n\n\n\nbondeth0  10.214.208.0  global  public\nre0  192.168.0.0  global  cluster_interconnect,asm\nre1  192.168.0.0  global  cluster_interconnect,asm"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Interconnect is configured on non-routable network addresses"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - NON-ROUTABLE NETWORK FOR INTERCONNECT\n\n\n\nbondeth0  10.214.208.0  global  public\nre0  192.168.0.0  global  cluster_interconnect,asm\nre1  192.168.0.0  global  cluster_interconnect,asm"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nSecure and efficient interconnect performance.\n\nRisk:\n\nInterconnect security and latency issues.\n\nAction / Repair:\n\nThe cluster interconnect should be a completely private/isolated (layer 2 packet processing), non-routable network (the only nodes connected to it are the cluster members themselves).\n\nThe 10.x.x.x, 172.x.x.x and 192.x.x.x networks are defined as non-routable networks by standard.  Customers who use other networks for the interconnect should ensure that they are not being routed, in which case this finding can be ignored."}]}, {"id": "05f237fa-33c9-448e-803f-f2da56759ace", "checkCategory": "CRS", "checkID": "9ECBA743A4BFA2F1E040E50A1EC01F9B", "checkType": "OS", "checkName": "Verify all voting disks are online", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "All voting disks are online"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY ALL VOTING DISKS ARE ONLINE\n\n\n\nSUCCESS:all voting disks are online."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nVoting disks help ensure a stable cluster. The impact of verifying all voting disks are online is minimal. The impact of bringing a given voting disk back online depends upon the reason why it went offline, and cannot be estimated here.\n\n\n\nRisk:\n\nNot having all expected voting disks online increases the risk of node eviction or cluster crash.\n\n\n\nAction / Repair:\n\nTo verify all voting disks are online, as the grid home owner userid, and with CRS_HOME and SID set to access the ASM instance, execute the following code on one database server in the cluster:\n\nVOTEDISK_OUTPUT=$($CRS_HOME/bin/crsctl query css votedisk)\nLOCATED_COUNT=$(echo \"$VOTEDISK_OUTPUT\" | egrep \"^Located\" | cut -d\" \" -f2)\nONLINE_COUNT=$(echo \"$VOTEDISK_OUTPUT\" | egrep -c ONLINE)\nif [ \"$LOCATED_COUNT\" -eq \"$ONLINE_COUNT\" ]\nthen\n  echo -e \"SUCCESS: all voting disks are online.\"\nelse\n  echo -e \"FAILURE: not all voting disks are online.\\nDETAILS:\\n$VOTEDISK_OUTPUT\"\nfi\n\nThe expected output should be:\n\nSUCCESS: all voting disks are online.\n\nExample of a \"FAILURE\" case:\n\nFAILURE: not all voting disks are online.\nDETAILS:\n##  STATE    File Universal Id                File Name Disk group\n--  -----    -----------------                --------- ---------\n 1. ONLINE   a07c741f08194f71bf7f4d14c7d67a15 (/dev/exadata_quorum/QD_DATAC1_RANDOM05ADM05) [DATAC1]\n 2. ONLINE   d1327820402f4f2fbffca97cbdef72d7 (/dev/exadata_quorum/QD_DATAC1_RANDOM05ADM06) [DATAC1]\n 3. ONLINE   748b53cfb1a64f6cbff0f71de2de89b3 (o/192.168.22.171;192.168.22.172/DATAC1_FD_05_random05celadm07) [DATAC1]\n 4. ONLINE   5fbc672724094f82bfcd4ea220ab824a (o/192.168.22.173;192.168.22.174/DATAC1_FD_05_random05celadm08) [DATAC1]\n 5. OFFLINE   e9efd3be40ad4f64bfd034233f3e37d3 (o/192.168.22.175;192.168.22.176/DATAC1_FD_05_random05celadm09) [DATAC1]\n\nIf a \"FAILURE\" result is returned, investigate to determine root cause and take appropriate corrective action. "}]}, {"id": "6e61340a-dfa9-4810-9d55-49e15c6c15de", "checkCategory": "CRS HOME", "checkID": "A07D101AC690D69BE053D198EB0A954F", "checkType": "OS", "checkName": "Verify that critical database files reside on high redundancy diskgroups", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "All disk groups which contain critical files use high redundancy"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Verify that critical database files reside on high redundancy diskgroups\n\n\n\nSUCCESS: all disk groups which contain critical files use high redundancy.\nDetails:\n\ndisk group name:DATAC1\nredundancy:HIGH\nfile type(s):CHANGETRACKING\nCONTROLFILE\nDATAFILE\nONLINELOG\nSPFILE\ndisk group name:RECOC1\nredundancy:HIGH\nfile type(s):ARCHIVELOG"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "All disk groups which contain critical files use high redundancy"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Verify that critical database files reside on high redundancy diskgroups\n\n\n\nSUCCESS: all disk groups which contain critical files use high redundancy.\nDetails:\n\ndisk group name:DATAC1\nredundancy:HIGH\nfile type(s):CHANGETRACKING\nCONTROLFILE\nDATAFILE\nONLINELOG\nSPFILE\ndisk group name:RECOC1\nredundancy:HIGH\nfile type(s):ARCHIVELOG"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThe use of high redundancy ASM disk groups provides the ultimate protection against downtime and data loss caused by partner storage failures and corruptions. High redundancy not only protects against the less likely case of a double partner disk failure, but more importantly protects from all of the other combinations of issues that can occur with partner Exadata storage. The most important case is when the Exadata storage software is updated in a rolling manner. During a rolling update of the Exadata storage servers, redundancy is temporarily reduced during the time an Exadata storage server is updated and gracefully restarted. If a partner disk on the Exadata storage server being restarted fails during the restart process, all ASM disk groups with normal redundancy will dismount and all I/O operations to that disk group will fail. If this disk group contains critical files, the database and Oracle clusterware will crash and can not be restarted until the disk group is once again available.\n\nCritical files such as datafiles, online and standby log files, control files, archivelog files, spfiles, and clusterware OCR and voting files should always reside on high redundancy disk groups.\n\nNOTE: To ensure better data protection, Oracle strongly recommends databases to be configured with ASM High Redundancy on 5+ year old Exadata systems. See MOS Document 2075007.1 for details.\n\nNOTE: For reference, the following file types are considered \"critical\": CONTROLFILE, DATAFILE, ONLINELOG, CHANGETRACKING, ARCHIVELOG, FLASHBACK, PARAMETERFILE\n\nNOTE: Clusterware has it's own best practice recommendations for the placement of critical files. Please reference:\n    Verify Oracle Clusterware files are placed appropriately\n\nOur general recommendation is that the two key disk groups supplied at Exadata deployment time for a cluster, ex: DATAC1 and RECOC1, are high redundancy. \n\nRisk:\n\nNot using high redundancy diskgroups increases the risk of downtime and data loss caused by partner storage failures and corruptions, especially those encountered during cell planned maintenance.\n\nAction / Repair:\n\nTo verify that critical files reside on high redundancy ASM disk groups, as the home owner userid with the environment configured to access a given database, connnect to a given database and execute the following code:\n\nRAW_FILE_DATA=$($ORACLE_HOME/bin/sqlplus -s \"/ as sysdba\" &lt;&lt;EOF\nset newpage none heading off lines 32000 feedback off timing off serveroutput on\nselect (name||':DATAFILE') from v$datafile;\nselect (name||':CONTROLFILE') from v$controlfile;\nselect (member||':ONLINELOG') from v$logfile;\nselect (name||':ARCHIVELOG') from v$archived_log where name is not null;\nselect (value||':SPFILE') from v$parameter where name = 'spfile';\nselect (name||':FLASHBACK') from v$flashback_database_logfile;\nselect (filename||':CHANGETRACKING') from v$block_change_tracking;\nexit\nEOF\n)\n# restrict file data to local files:\nRAW_FILE_DATA=$(echo \"$RAW_FILE_DATA\" | egrep \"^+\")\n#get the diskgroup data:\nDISKGROUP_DATA=$($ORACLE_HOME/bin/sqlplus -s \"/ as sysdba\" &lt;&lt;EOF\nset newpage none heading off lines 32000 feedback off timing off serveroutput on\nselect name,type from v$asm_diskgroup_stat;\nexit\nEOF\n)\n#trim the diskgoup data:\nDISKGROUP_DATA=$(echo \"$DISKGROUP_DATA\" | awk '$1=$1')\n#create an array of disk groups in use from the raw file data\nDG_IN_USE_ARRAY=$(echo -e \"$RAW_FILE_DATA\"| awk -F/ -v pattern=\"^+\" '$0~pattern && /[[:alnum:]]/ {sub(/^+/, \"\",$1); if ($1 != \" \" && !seen[$1]++) print $1;}')\n# trim the DG_IN_USE_ARRAY\nDG_IN_USE_ARRAY=$(echo \"$DG_IN_USE_ARRAY\" | sort -u)\n#for each dg in use, find type and build output_array\nRESULT=0\nfor INDIVIDUAL_DG in $DG_IN_USE_ARRAY\ndo\n  DG_TYPE=$(echo \"$DISKGROUP_DATA\" | grep $INDIVIDUAL_DG | cut -d \" \" -f2)\n  if [[ $DG_TYPE = \"HIGH\" ]]\n  then\n    FILE_TYPE=$(echo \"$RAW_FILE_DATA\" | grep $INDIVIDUAL_DG | cut -d \":\" -f2 | sort -u |  sed -e ':a;N;s/\\\\n/ /;ba')\n    PASS_ARRAY+=$(echo -e \"\\ndisk group name: $INDIVIDUAL_DG\\nredundancy: $DG_TYPE\\nfile type(s): $FILE_TYPE\")\n  else\n    FILE_TYPE=$(echo \"$RAW_FILE_DATA\" | grep $INDIVIDUAL_DG | cut -d \":\" -f2 | sort -u |  sed -e ':a;N;s/\\\\n/ /;ba')\n    FAIL_ARRAY+=$(echo -e \"\\ndisk group name: $INDIVIDUAL_DG\\nredundancy: $DG_TYPE\\nfile type(s): $FILE_TYPE\")\n    RESULT=1\n  fi\ndone\nif [[ $RESULT -eq 0 ]]\nthen\n  echo -e \"SUCCESS:  all disk groups which contain critical files use high redundancy.\\nDetails:\\n${PASS_ARRAY[@]}\"\nelse\n  echo -e \"FAILURE:  one or more disk groups which contain critical files do not use high redundancy.\n\\n\\nFAIL details:\\n${FAIL_ARRAY[@]}\\n\\nPASS details:\\n${PASS_ARRAY[@]}\"\nfi\n\nThe expected result is:\n\nSUCCESS:  all disk groups which contain critical files use high redundancy.\nDetails:\n\ndisk group name: DATAC1\nredundancy: HIGH\nfile type(s): CHANGETRACKING CONTROLFILE DATAFILE ONLINELOG SPFILE\ndisk group name: RECOC1\nredundancy: HIGH\nfile type(s): ARCHIVELOG FLASHBACK\n\nExample of a \"FAILURE\" result:\n\nFAILURE:  one or more disk groups which contain critical files do not use high redundancy.\n\nFAIL details:\n\ndisk group name: RECOC1\nredundancy: NORMAL\nfile type(s): ARCHIVELOG DATAFILE\n\nPASS details:\n\ndisk group name: DATAC1\nredundancy: HIGH\nfile type(s): CONTROLFILE DATAFILE ONLINELOG SPFILE\ndisk group name: DATAC2\nredundancy: HIGH\nfile type(s): ARCHIVELOG\n\n    NOTE: If a \"FAILURE\" result is returned, follow the recommended procedures in the version specific documentation to change the disk group redundancy to high or to relocate the critical file(s)."}]}, {"id": "72033c9e-ef96-4537-84d2-d2e21484b6f4", "checkCategory": "CRS", "checkID": "A096611C3310AC86E053D598EB0A3C1B", "checkType": "OS", "checkName": "Verify Oracle Clusterware files are placed appropriately", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Oracle Clusterware files are placed appropriately"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY ORACLE CLUSTERWARE FILES ARE PLACED APPROPRIATELY\n\n\n\n\nClusterware files placement check passed\n\nThe Diskgroups found are\n============================\nName Type Voting_files\nDATAC1 HIGH Y\nRECOC1 HIGH N\n\nOCR is stored in :DATAC1\n\nVoting Files are stored in :DATAC1\n\nASM spfile is stored in :DATAC1\n\nASM password file is stored in :DATAC1"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Oracle Clusterware files are placed appropriately"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - VERIFY ORACLE CLUSTERWARE FILES ARE PLACED APPROPRIATELY\n\n\n\n\nClusterware files placement check passed\n\nThe Diskgroups found are\n============================\nName Type Voting_files\nDATAC1 HIGH Y\nRECOC1 HIGH N\n\nOCR is stored in :DATAC1\n\nVoting Files are stored in :DATAC1\n\nASM spfile is stored in :DATAC1\n\nASM password file is stored in :DATAC1"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nOracle Clusterware files should always be placed in a high redundancy diskgroup with the exception of voting files for the following cases.\n\ni) For environments with less than 5 storage cells and running any Exadata software release prior to 12.1.2.3.0, the voting files need to be placed in a normal redundancy diskgroup.\n\nii) For environments with less than 5 storage cells , running any Exadata software release 12.1.2.3.0 or above and running any Oracle Grid Infrastructure version prior to 12.1.0.2.160119, the voting files need to be placed in a normal redundancy diskgroup.\n\nRisk:\n\nOracle Clusterware files placed on a normal redundancy diskgroup are exposed to the risk of of being lost in the event of diskgroup failures due to a double partner storage failure. Having the clusterware files on a high redundancy diskgroup mitigates this risk. The voting files are the only Clusterware files that are mandated to be stored in a normal redundancy diskgroup under the 2 conditions mentioned above. However, even if we lose the voting files due to a double partner storage failure under the above 2 conditions, they can be easily recreated unlike all other Clusterware files which require restore from backups.\n\nAction / Repair:\n\nTo verify Oracle Clusterware files are placed appropriately, run Exachk and review the provided report.\n\nThe expected output in the Exachk report should be as follows:\n\nIn the \"Findings Passed\" summary section of the report, the overall result should be \"PASS\":\n\nPASS   OS Check   Oracle Clusterware files are placed appropriately   All Database Servers   View\n\nIn the \"View\" detail section of the report for each individual database server:\n\nStatus on random01client01:\nPASS =&gt; Oracle Clusterware files are placed appropriately\n\nDATA FROM RANDOM01CLIENT01 - VERIFY ORACLE CLUSTERWARE FILES ARE PLACED APPROPRIATELY\n\nClusterware files placement check passed\n\nThe Diskgroups found are \n============================\n Name Type Voting_files\nACFSC1 HIGH N\nDATAC1 HIGH N\nDBFSC1 HIGH Y\nRECOC1 HIGH N\n\nOCR is stored in : DBFSC1\n\nVoting Files are stored in : DBFSC1\n\nASM spfile is stored in : DBFSC1\n\nASM password file is stored in : DBFSC1\n\nA \"FAIL\" example (view detail only):\nStatus on random01client01:\nFAIL =&gt; Oracle Clusterware files are not placed appropriately\n\nDATA FROM RANDOM01CLIENT01 - VERIFY ORACLE CLUSTERWARE FILES ARE PLACED APPROPRIATELY\n\nClusterware files placement check failed. \nThe clusterware files are not all placed in a high redundancy diskgroup.\n\nThe Diskgroups found are \n=========================\n Name Type Voting_files\nDATAC1 HIGH N\nDATAC2 HIGH N\nRECOC1 NORMAL N\nRECOC2 NORMAL Y\n\nOCR is stored in : DATAC2\n\nVoting Files are stored in : RECOC2\n\nASM spfile is stored in : DATAC2\n\nASM password file is stored in : DATAC2\n\nPlease relocate the Voting Files to a high redundancy diskgroup using /u01/app/19.0.0.0/grid/bin/crsctl as described in the link below.\nFor environments with less than 5 cells consider using Quorum devices which will enable storing the voting files in a high redundancy diskgroup.\nMinimum software versions that support Quorum devices are : Oracle Grid Infrastructure 12.1.0.2.160119 and Oracle Exadata release 12.1.2.3.0.\n\nhttps://docs.oracle.com/en/database/oracle/oracle-database/19/cwadd/managing-oracle-cluster-registry-and-voting-files.html#GUID-044D58CA-6392-40A1-AB31-C84A2A5A5CE6\n\n    NOTE: If any \"FAIL\" results are returned, follow the guidance provided in the message.\n\n    NOTE: If after corrective actions are completed you wish to run just this check without a full Exachk run, execute the following:\n\n    ./exachk -check A096611C3310AC86E053D598EB0A3C1B"}, {"id": "dea7e0b1-51f3-4689-a86f-af2e8cce2b84", "title": "Links", "links": [{"hyperlink": "https://docs.oracle.com/en/database/oracle/oracle-database/19/cwadd/managing-oracle-cluster-registry-and-voting-files.html#GUID-044D58CA-6392-40A1-AB31-C84A2A5A5CE6", "text": "Adding, Deleting, or Migrating Voting Files"}]}]}, {"id": "6ae5a460-382c-48a6-9e50-472e48bf1b51", "checkCategory": "HOST", "checkID": "A18401E2DDFF63D2E040E50A1EC077C4", "checkType": "OS", "checkName": "ORA_CRS_HOME env variable for Grid infrastructure owner", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "ORA_CRS_HOME environment variable is not set for Grid infrastructure owner"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - ORA_CRS_HOME ENV VARIABLE FOR GRID INFRASTRUCTURE OWNER\n\n\n\n\nORA_CRS_HOME environment variable not set"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "ORA_CRS_HOME environment variable is not set for Grid infrastructure owner"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - ORA_CRS_HOME ENV VARIABLE FOR GRID INFRASTRUCTURE OWNER\n\n\n\n\nORA_CRS_HOME environment variable not set"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nUnset Oracle related environment variables especially ORA_CRS_HOME before starting OUI or before executing any root script for both root and grid user.\n\nThis requirement is documented in Oracle Grid Infrastructure Installation Guide 11g Release 2 (11.2) .\n\n\"Unset Oracle environment variables. If you have set ORA_CRS_HOME as an environment variable, then unset it before starting an installation or upgrade. You should never use ORA_CRS_HOME as an environment variable.\n\nIf you have had an existing installation on your system, and you are using the same user account to install this installation, then unset the following environment variables: ORA_CRS_HOME; ORACLE_HOME; ORA_NLS10; TNS_ADMIN\"\n\nRisk:\n\nSetting this variable can cause problems for various Oracle components, and it is never necessary for CRS programs because they all have wrapper scripts.\n"}, {"id": "de9c92a4-75e2-4e95-ae4c-57762e214437", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=1502996.1", "text": "Note: 1502996.1 - Environment Variable ORA_CRS_HOME MUST be UNSET in 11gR2"}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=952925.1", "text": "Note: 952925.1 - \t NETCA & ASMCA Fail during Upgrade of CRS/ASM to Grid Infrastructure 11gR2"}, {"hyperlink": "http://docs.oracle.com/cd/E11882_01/install.112/e41961/procstop.htm#CWLIN419", "text": "Unset Oracle Environment Variables"}]}]}, {"id": "53cb3ea2-c7f3-4183-ab9e-529a18be6c1e", "checkCategory": "RDBMS", "checkID": "A2D6D174E9825001E053D398EB0A4115", "checkType": "SQL_PARAM", "checkName": "Check for parameter pre_page_sga", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Database parameter PRE_PAGE_SGA is set to the recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Database parameter PRE_PAGE_SGA is set to the recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nSetting PRE_PAGE_SGA to TRUE improves database startup time.\n\n\nRisk:\n\nIf PRE_PAGE_SGA is not set to TRUE, database startup may be delayed up to several minutes depending upon SGA size.\n\nAction / Repair:\n\nIf PRE_PAGE_SGA is not set to \"TRUE\", correct the parameter setting."}]}, {"id": "11b3da42-cbf6-4a86-a084-d595915dae83", "checkCategory": "CRS HOME", "checkID": "A30824633516E9C9E040E50A1EC02B26", "checkType": "OS", "checkName": "Verify RDS Protocol is used for interprocess communication [Grid Home]", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Oracle ASM is using RDS protocol for inter process communication"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY RDS PROTOCOL IS USED FOR INTERPROCESS COMMUNICATION [GRID HOME]\n\n\n\nrds"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Oracle ASM is using RDS protocol for inter process communication"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - VERIFY RDS PROTOCOL IS USED FOR INTERPROCESS COMMUNICATION [GRID HOME]\n\n\n\nrds"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThe RDS protocol provides superior performance because it avoids additional memory buffering operations when moving data from process memory to the network interface for IO operations. This includes both IO operations between the Oracle instance and the storage servers, as well as instance to instance block transfers via Cache Fusion.\n\nThere is minimal impact to verify that the RDS protocol is in use. Implementing the RDS protocol requires an outage to relink the Oracle software.\n\nRisk:\n\nIf the RDS protocol  is not used, IO operations will be sub-optimal.\n\nAction / Repair:\n\nTo validate an ORACLE_HOME:\nAs the owner userid of the ORACLE_HOME, set the ORACLE_HOME and LD_LIBRARY_PATH variables properly and execute the following command:\n\n$ORACLE_HOME/bin/skgxpinfo\n\nThe output should be:\n\nrds\n\nTo validate a CRS_HOME:\nAs the owner userid of the CRS_HOME, set the CRS_HOME and LD_LIBRARY_PATH variables properly and execute the following command:\n\n$CRS_HOME/bin/skgxpinfo\n\nThe output should be:\n\nrds\n\nIf the RDS protocol is not being used, the appropriate binaries must be relinked.\n\n    NOTE: In all cases, do not use the \"relink all\" command due to various issues. Use the make commands provided. \n\nTo relink an ORACLE_HOME:\nAs the owner userid of the ORACLE_HOME execute the following steps with all necessary variables properly set:\n\n    Shutdown any processes using the ORACLE_HOME\n    \"cd $ORACLE_HOME/rdbms/lib\"\n    \"make -f ins_rdbms.mk ipc_rds ioracle\"\n    Restart any processes using the ORACLE_HOME \n\nTo relink a CRS_HOME:\n\n    NOTE: The following instructions are for Oracle stack versions 12.2 or higher:\n\nAs the owner userid of the CRS_HOME (and the \"root\" userid for some steps) execute the following steps with all necessary variables properly set:\n\n    As the \"root\" userid, stop the clusterware runnning out of the CRS_HOME\n    As the \"root\" userid, execute \"$CRS_HOME/crs/install/rootcrs.sh -unlock\"\n    \"cd $CRS_HOME/rdbms/lib\"\n    \"make -f ins_rdbms.mk ipc_rds ioracle\"\n    As the \"root\" userid, execute \"$CRS_HOME/crs/install/rootcrs.sh -lock\"\n    As the \"root\" userid, start the clusterware runnning out of the CRS_HOME\n    After a few minutes, as the \"root\" userid verify all expected resources are executing with \"$CRS_HOME/bin/crsctl stat res -t\" \n\n    NOTE: The following instructions are for Oracle stack versions 12.1 or lower (including 11.2.x):\n\nAs the owner userid of the CRS_HOME (and the \"root\" userid for some steps) execute the following steps with all necessary variables properly set:\n\n    As the \"root\" userid, stop the clusterware runnning out of the CRS_HOME\n    As the \"root\" userid, execute \"$CRS_HOME/crs/install/rootcrs.pl -unlock\"\n    \"cd $CRS_HOME/rdbms/lib\"\n    \"make -f ins_rdbms.mk ipc_rds ioracle\"\n    As the \"root\" userid, \"$CRS_HOME/crs/install/rootcrs.pl -patch\"\n    After a few minutes, as the \"root\" userid verify all expected resources are executing with \"$CRS_HOME/bin/crsctl stat res -t\""}]}, {"id": "cc0f27ca-2c51-4909-aebd-1048b65fdb1d", "checkCategory": "RDBMS", "checkID": "A3367839CF958605E053D498EB0AF7A4", "checkType": "SQL", "checkName": "Verify AUD$ and FGA_LOG$ tables use Automatic Segment Space Management", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "success", "statusLabel": "PASS", "output": "Table AUD$[FGA_LOG$] uses Automatic Segment Space Management"}, "children": [{"attr": {"consoleOutput": "\nPDB NAME = PDB11|Table Name = AUD$|Space Management Type = AUTO\n\nPDB NAME = PDB11|Table Name = FGA_LOG$|Space Management Type = AUTO\n\nPDB NAME = ROOT|Table Name = AUD$|Space Management Type = AUTO\n\nPDB NAME = ROOT|Table Name = FGA_LOG$|Space Management Type = AUTO"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nWith AUDIT_TRAIL set for database (AUDIT_TRAIL=db), and the AUD$ and FGA_LOG$ tables located in a dictionary segment space managed SYSTEM tablespace, \"gc\" wait events are sometimes observed during heavy periods of database logon activity. Testing has shown that under such conditions, placing the AUD$ and FGA_LOG$ tables in the SYSAUX tablespace, which uses automatic segment space management, reduces the space related wait events.\n\nThe impact of verifying that the AUD$ and FGA_LOG$ tables are in the SYSAUX table space is low. Moving them if they are not located in the SYSAUX does not require an outage, but should be done during a scheduled maintenance period or slow audit record generation window.\n\nIf Unified Auditing feature is enabled, unified audit records doesn't get inserted into the AUD$ and FGA_LOG$ tables, and instead uses AUDSYS.AUD$UNIFIED which by default gets created in SYSAUX tablespace. SYSAUX tablespace uses ASSM by default. So if Unified Audit feature is enabled, then it's ok to leave AUD$ and FGA_LOG$ tables in the SYSTEM as it will be empty.\n\nRisk:\n\nIf Unified Audit feature is not used, and if AUD$ and FGA_LOG$ tables are not verified to use automatic segment space management, there is a risk of a performance slowdown during periods of high database login activity.\n\nAction / Repair:\n\nTo verify the segment space management policy currently in use by the AUD$ and FGA_LOG$ tables, use the following Sqlplus command:\n\nNone Container Database : \n\nselect t.table_name,ts.segment_space_management \nfrom dba_tables t, dba_tablespaces ts \nwhere ts.tablespace_name = t.tablespace_name \nand t.table_name in ('AUD$','FGA_LOG$');\n\nThe output should be:\n\nTABLE_NAME                     SEGMEN\n------------------------------ ------\nFGA_LOG$                       AUTO\nAUD$                           AUTO \n\nContainer Datanase : \n\ncol pdb_name format a25\ncol table_name format a25\ncol space_management format a25\nselect pdb_name, t.table_name table_name,ts.segment_space_management space_management\nfrom cdb_tables t, cdb_tablespaces ts, cdb_pdbs p\nwhere ts.tablespace_name = t.tablespace_name\nand t.table_name in ('AUD$','FGA_LOG$')\nand t.con_id = ts.con_id\nand p.con_id=ts.con_id\nunion\nselect 'ROOT', t.table_name,ts.segment_space_management\nfrom dba_tables t, dba_tablespaces ts\nwhere ts.tablespace_name = t.tablespace_name\nand t.table_name in ('AUD$','FGA_LOG$')\norder by 1,2;\n\noutput should be \n\nPDB_NAME   TABLE_NAME SPACE_MANAGEMENT\n---------- ---------- ------\nROOT       AUD$       AUTO\nROOT       FGA_LOG$   AUTO\nV1C1P1     AUD$       AUTO\nV1C1P1     FGA_LOG$   AUTO\n\nIf one or both of the AUD$ or FGA_LOG$ tables return \"MANUAL\", use the DBMS_AUDIT_MGMT package to move them to the SYSAUX tablespace:\n\nBEGIN\nDBMS_AUDIT_MGMT.set_audit_trail_location(audit_trail_type =&gt; DBMS_AUDIT_MGMT.AUDIT_TRAIL_AUD_STD,--this moves table AUD$ \naudit_trail_location_value =&gt; 'SYSAUX');  \nEND;  \n/\n\nBEGIN\nDBMS_AUDIT_MGMT.set_audit_trail_location(audit_trail_type =&gt; DBMS_AUDIT_MGMT.AUDIT_TRAIL_FGA_STD,--this moves table FGA_LOG$ \naudit_trail_location_value =&gt; 'SYSAUX');\nEND;\n/   \n\nThe output should be similar to:\n\nPL/SQL procedure successfully completed. \n\nIf the output is not as above, investigate and correct the condition.\n\n    NOTE: This \"DBMS_AUDIT_MGMT.set_audit_trail\" command should be executed as part of the dbca template post processing scripts, but for existing databases, the command can be executed, but since it moves the AUD$ & FGA_LOG$ tables using \"alter table ... move\" command, it should be executed at a \"quiet\" time\n\n\nAlso this misconfiguration can be repaired with repair functionality in AHF using \"ahfctl compliance -repair -check A3367839CF958605E053D498EB0AF7A4\".\nTo see the repair command, run \"ahfctl compliance -showrepair A3367839CF958605E053D498EB0AF7A4\"."}, {"id": "d3c14956-583a-4226-a575-a6fed10397d1", "title": "Links", "links": [{"hyperlink": "http://docs.oracle.com/cd/E11882_01/server.112/e10803/config_db.htm#HABPT4845", "text": "Use Automatic Segment Space Management"}]}]}, {"id": "0b202a95-6116-4faa-962c-32bf3a50c97b", "checkCategory": "RDBMS", "checkID": "A98A14A7D1CB386DE040E50A1EC01EBD", "checkType": "SQL_PARAM", "checkName": "Check for parameter parallel_threads_per_cpu", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Database parameter PARALLEL_THREADS_PER_CPU is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Database parameter PARALLEL_THREADS_PER_CPU is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nExperience and testing has shown that certain database initialization parameters should be set at specific values. These are the best practice values set at deployment time. By setting these database initialization parameters as recommended, known problems may be avoided and performance maximized.\nThe parameters are common to all database instances. The impact of setting these parameters is minimal.\nThe performance related settings provide guidance to maintain highest stability without sacrificing performance. Changing the default performance settings can be done after careful performance evaluation and clear understanding of the performance impact.\n\n\n\nRisk:\n\nIf the database initialization parameters are not set as recommended, a variety of issues may be encountered, depending upon which initialization parameter is not set as recommended, and the actual set value.\n\n\n\nAction / Repair:\n\nPARALLEL_THREADS_PER_CPU = 1 properly accounts for hyper threading\n\nAlso this misconfiguration can be repaired with repair functionality in AHF using \"ahfctl compliance -repair -check A98A14A7D1CB386DE040E50A1EC01EBD\".\nTo see the repair command, run \"ahfctl compliance -showrepair A98A14A7D1CB386DE040E50A1EC01EBD\"."}, {"id": "cbe97853-459e-4e3d-9d36-e9d26c9c52e1", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1274318.1", "text": "Note: 1274318.1 - Oracle Sun Database Machine X2-2 Setup/Configuration Best Practices (Doc ID 1274318.1)"}]}]}, {"id": "621829f4-fca8-4b59-8980-cd7a5809252d", "checkCategory": "RDBMS", "checkID": "A98AC77CA837A489E040E50A1EC014A6", "checkType": "SQL_PARAM", "checkName": "Check for parameter os_authent_prefix", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Database parameter OS_AUTHENT_PREFIX is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Database parameter OS_AUTHENT_PREFIX is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nExperience and testing has shown that certain database initialization parameters should be set at specific values. These are the best practice values set at deployment time. By setting these database initialization parameters as recommended, known problems may be avoided and performance maximized.\nThe parameters are common to all database instances. The impact of setting these parameters is minimal.\nThe performance related settings provide guidance to maintain highest stability without sacrificing performance. Changing the default performance settings can be done after careful performance evaluation and clear understanding of the performance impact.\n\n\n\nRisk:\n\nIf the database initialization parameters are not set as recommended, a variety of issues may be encountered, depending upon which initialization parameter is not set as recommended, and the actual set value.\n\n\n\nAction / Repair:\n\nOS_AUTHENT_PREFIX =  is a security optimization (ie., null string)\n\nAlso this misconfiguration can be repaired with repair functionality in AHF using \"ahfctl compliance -repair -check A98AC77CA837A489E040E50A1EC014A6\".\nTo see the repair command, run \"ahfctl compliance -showrepair A98AC77CA837A489E040E50A1EC014A6\"."}, {"id": "ba4c8749-f5d6-45e7-a858-c95b9ea8a0ef", "title": "Links", "links": [{"hyperlink": "https://docs.oracle.com/search/?q=OS_AUTHENT_PREFIX&category=database&product=en%2Fdatabase%2Foracle%2Foracle-database", "text": "Setting OS_AUTHENT_PREFIX to a Null Value"}]}]}, {"id": "db1a511a-477b-4770-83de-51b826610526", "checkCategory": "RDBMS", "checkID": "A98AD732FD50F308E040E50A1EC01B2C", "checkType": "SQL_PARAM", "checkName": "Check for parameter use_large_pages", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Database parameter USE_LARGE_PAGES is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Database parameter USE_LARGE_PAGES is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nBenefits: Memory savings and reduce paging and swapping\n\nRisk:\n\nIf the database initialization parameters are not set as recommended, a variety of issues may be encountered, depending upon which initialization parameter is not set as recommended, and the actual set value.\n\n\n\nAction / Repair:\n\nUSE_LARGE_PAGES = ONLY ensures the entire SGA is stored in hugepages for Linux based systems only.\n\nNOTE: Please refer to My Oracle Support notes MOS 401749.1, 361323.1, and 1392497.1  in links section for additional details on configuring hugepages\n\nNOTE: If you have not reviewed notes 401749.1, 361323.1, and 1392497.1 and followed their guidance BEFORE using the database parameter \"use_large_pages=only\", this check will pass the environment but you will still not be able to start instances once the configured pool of operating system hugepages have been consumed by instance startups. If that should happen, you will need to change the \"use_large_pages\" initialization parameter to one of the other values, restart the instance, and follow the instructions in notes 401749.1 and 361323.1. The brute force alternative is to increase the huge page count until the newest instance will start, and then adjust the huge page count after you can see the estimated requirements for all currently active SGAs.\n\nNOTE: While it is possible to modify the number of hugepages in active memory in the running kernel, it is not recommended for two reasons:\n1) The hugepages pool must be contiguous, and it may not be possible to find enough contiguous pages to meet a request in the running kernel active memory.\n2) Setting the value in the kernel configuration files and rebooting ensures the expected number of hugepages is properly configured and available. Misconfigurations in this area can impact server availability so following this operational best practice prevents an unexpected outage caused by user error.\nNOTE: With the fix for bug 32498459, the Oracle database will enforce the use of large pages regardless of the setting of this parameter when the SGA is 32GB or higher. Release 19.12 and 21.3 include this fix."}, {"id": "cb121721-a943-40dc-af4d-6c879a08202e", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1392497.1", "text": "Note: 1392497.1 - USE_LARGE_PAGES To Enable HugePages (Doc ID 1392497.1)"}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=361323.1", "text": "Note: 361323.1 - HugePages on Linux: What It Is... and What It Is Not..."}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=401749.1", "text": "Note: 401749.1 - Shell Script to Calculate Values Recommended Linux HugePages / HugeTLB"}]}]}, {"id": "6719db2f-406f-4f86-a69e-6e1ca1ece9ee", "checkCategory": "RDBMS", "checkID": "A98B0EBCBD6D9EADE040E50A1EC02600", "checkType": "SQL_PARAM", "checkName": "Check for parameter sql92_security", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Database parameter sql92_security is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Database parameter sql92_security is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nExperience and testing has shown that certain database initialization parameters should be set at specific values. These are the best practice values set at deployment time. By setting these database initialization parameters as recommended, known problems may be avoided and performance maximized.\nThe parameters are common to all database instances. The impact of setting these parameters is minimal.\nThe performance related settings provide guidance to maintain highest stability without sacrificing performance. Changing the default performance settings can be done after careful performance evaluation and clear understanding of the performance impact.\n\n\n\nRisk:\n\nIf the database initialization parameters are not set as recommended, a variety of issues may be encountered, depending upon which initialization parameter is not set as recommended, and the actual set value.\n\n\n\nAction / Repair:\n\nSQL92_SECURITY = TRUE is a security optimization"}]}, {"id": "fafced83-5f9a-4d7d-a9b5-10bb24e4ab0f", "checkCategory": "ASM", "checkID": "AA53138B0B7D3B86E040E50A1EC07003", "checkType": "OS", "checkName": "Verify Oracle ASM instances communication uses the Private Network", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "ASM parameter CLUSTER_INTERCONNECTS is set to the recommended value"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY ORACLE ASM INSTANCES COMMUNICATION USES THE PRIVATE NETWORK\n\n\n\n1) Cluster Interconnect Value from instance:\n192.168.11.128 192.168.11.129\n\n3) Network card name and IP address from oifcfg:\nre0 = 192.168.11.128\nre1 = 192.168.11.129"}}]}, {"attr": {"target": "scaqal03adm06vm01:+ASM2", "status": "success", "statusLabel": "PASS", "output": "ASM parameter CLUSTER_INTERCONNECTS is set to the recommended value"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - VERIFY ORACLE ASM INSTANCES COMMUNICATION USES THE PRIVATE NETWORK\n\n\n\n1) Cluster Interconnect Value from instance:\n192.168.11.132 192.168.11.133\n\n3) Network card name and IP address from oifcfg:\nre0 = 192.168.11.132\nre1 = 192.168.11.133"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThe private network (either InfiniBand or RoCE) in an Oracle Exadata Database Machine provides superior performance and throughput characteristics that allow Oracle Clusterware, ASM, and databases to operate at optimal efficiency. \nThe private interconnect used by ASM instances, available in the v$cluster_interconnects view, should match both the ip addresses configured on the private network interfaces.\n\nNOTE: Properly configuring the Exadata environment to use the private network avoids using the Clusterware HAIP address which is not supported on Exadata. HAIP was disabled during deployment time in OEDA version 12.1.2.4 for all versions (bug 23627471) and is disabled automatically on Exadata by CRS scripts in GI version 12.2 (bug 24420871).\n\nRisk:\n\nIf an ASM instance does not use the private network for communication between cluster nodes, performance will be sub-optimal and service blackouts may occur, especially during internal network failures or planned maintenance.\n\nAction / Repair:\n\nIf the v$cluster_interconnects IP_ADDRESS column contains IP addresses different than the Exadata private network interfaces (returned by \"/sbin/ip show address\" command), check for misconfiguration in the following two areas:\n1) CLUSTER_INTERCONNECTS database initialization parameter and \n2) oifcfg getif for cluster interconnect. \nIdeally the CLUSTER_INTERCONNECTS initialization parameter should not be set and automatically uses the private network interfaces identified by the Clusterware. If the CLUSTER_INTERCONNECTS initialization parameter is set, the check ensures the parameter is set to the correct value.\n\nOnce the issue has been resolved, this audit check can be invoked individually as root user as follows:\n\n    # exachk -check AA53138B0B7D3B86E040E50A1EC07003\n\n"}, {"id": "5e7bfd5d-f835-45f2-ba77-47b3fc21eb35", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=2353240.1", "text": "Note: 2353240.1 - Exachk - Database parameter CLUSTER_INTERCONNECTS is not set to the recommended value (Doc ID 2353240.1)"}]}]}, {"id": "b3939f13-20f8-47d1-ba1a-d93e696630c5", "checkCategory": "RDBMS", "checkID": "AA53138B0B7E3B86E040E50A1EC07003", "checkType": "OS", "checkName": "Verify Oracle Database instances communication uses the Private Network", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Database parameter CLUSTER_INTERCONNECTS is set to the recommended value"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Verify Oracle Database instances communication uses the Private Network\n\n\n\n1) Cluster Interconnect Value from instance:\n192.168.11.128 192.168.11.129\n\n3) Network card name and IP address from oifcfg:\nre0 = 192.168.11.128\nre1 = 192.168.11.129"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Database parameter CLUSTER_INTERCONNECTS is set to the recommended value"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Verify Oracle Database instances communication uses the Private Network\n\n\n\n1) Cluster Interconnect Value from instance:\n192.168.11.132 192.168.11.133\n\n3) Network card name and IP address from oifcfg:\nre0 = 192.168.11.132\nre1 = 192.168.11.133"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThe private network (either InfiniBand or RoCE) in an Oracle Exadata Database Machine provides superior performance and throughput characteristics that allow Oracle Clusterware, ASM, and databases to operate at optimal efficiency. \nThe private interconnect used by database instances, available in the v$cluster_interconnects view, should match both the IP addresses configured on the private network interfaces.\n\nNOTE: Properly configuring the Exadata environment to use the private network avoids using the Clusterware HAIP address which is not supported on Exadata. HAIP was disabled during deployment time in OEDA version 12.1.2.4 for all versions (bug 23627471) and is disabled automatically on Exadata by CRS scripts in GI version 12.2 (bug 24420871).\n\nRisk:\n\nIf a database instance does not use the private network for communication between cluster nodes, performance will be sub-optimal and service blackouts may occur, especially during internal network failures or planned maintenance.\n\nAction / Repair:\n\nIf the v$cluster_interconnects IP_ADDRESS column contains IP addresses different than the Exadata private network interfaces (returned by \"/sbin/ip show address\" command), check for misconfiguration in the following two areas:\n1) CLUSTER_INTERCONNECTS database initialization parameter and \n2) oifcfg getif for cluster interconnect. \nIdeally the CLUSTER_INTERCONNECTS initialization parameter should not be set and automatically uses the private network interfaces identified by the Clusterware. If the CLUSTER_INTERCONNECTS initialization parameter is set, the check ensures the parameter is set to the correct value.\n\nOnce the issue has been resolved, this audit check can be invoked individually as root user as follows:\n\n    # exachk -check AA53138B0B7E3B86E040E50A1EC07003\n\n"}, {"id": "2ee07eac-51bf-4807-933d-b6e011fd6652", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=2353240.1", "text": "Note: 2353240.1 - Exachk - Database parameter CLUSTER_INTERCONNECTS is not set to the recommended value (Doc ID 2353240.1)"}]}]}, {"id": "a46d8bd5-9f5d-402c-80d9-c0113c510df9", "checkCategory": "ASM", "checkID": "AA53E911694E2C18E040E50A1EC03614", "checkType": "OS", "checkName": "Processes parameter for ASM instance", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "ASM processes parameter is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - PROCESSES PARAMETER FOR ASM INSTANCE\n\n\n\nProcesses parameter set on +ASM1 = 1024\nNumber of RDBMS instances running = 1\nRecommended value for Processes parameter for +ASM1 = 1024"}}]}, {"attr": {"target": "scaqal03adm06vm01:+ASM2", "status": "success", "statusLabel": "PASS", "output": "ASM processes parameter is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - PROCESSES PARAMETER FOR ASM INSTANCE\n\n\n\nProcesses parameter set on +ASM2 = 1024\nNumber of RDBMS instances running = 1\nRecommended value for Processes parameter for +ASM2 = 1024"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nExperience and testing has shown that certain ASM initialization parameters should be set at specific values. These are the best practice values set at deployment time. By setting these ASM initialization parameters as recommended, known problems may be avoided and performance maximized. The parameters are specific to the ASM instances. Unless otherwise specified, the value is for both X2-2 and X2-8 Database Machines. The impact of setting these parameters is minimal. \n\n\n\nRisk:\n\nIf the ASM initialization parameters are not set as recommended, a variety of issues may be encountered, depending upon which initialization parameter is not set as recommended, and the actual set value. \n\n\n\nAction / Repair:\n\nThis avoids issues observed when ASM hits max # of processes.\nFor &lt; 10 instances per node, set processes=1024\n\nFor &gt;= 10 instances per node,set processes using the following formula\n\nMAX((50*MIN(db_instances_per_node+1,11))+(10*MAX(db_instances_per_node-10,0)),1024)\n\nThis new formula accommodates the consolidation case where there are a lot of instances per node."}, {"id": "f62c6232-c68f-4f58-8b51-25bc4e073767", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1274318.1", "text": "Note: 1274318.1 - Oracle Sun Database Machine X2-2 Setup/Configuration Best Practices (Doc ID 1274318.1)"}]}]}, {"id": "c106e04e-20e4-4158-ab2b-871bfcb8e70e", "checkCategory": "RDBMS", "checkID": "AA9125A029E40EAFE040E50A1EC0620D", "checkType": "OS", "checkName": "db_recovery_file_dest_size", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Database parameter db_recovery_file_dest_size is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - db_recovery_file_dest_size\n\n\n\n90% of RECOC1 Total Space = \t\t       248281GB\ndb_recovery_file_dest_size= \t\t\t74483GB"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Database parameter db_recovery_file_dest_size is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - db_recovery_file_dest_size\n\n\n\n90% of RECOC1 Total Space = \t\t       248281GB\ndb_recovery_file_dest_size= \t\t\t74483GB"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nExperience and testing has shown that certain database initialization parameters should be set at specific values. These are the best practice values set at deployment time. By setting these database initialization parameters as recommended, known problems may be avoided and performance maximized. The parameters are common to all database instances. The impact of setting these parameters is minimal. The performance related settings provide guidance to maintain highest stability without sacrificing performance. Changing the default performance settings can be done after careful performance evaluation and clear understanding of the performance impact. \n\n\n\nRisk:\n\nIf the database initialization parameters are not set as recommended, a variety of issues may be encountered, depending upon which initialization parameter is not set as recommended, and the actual set value. \n\n\n\nAction / Repair:\n\nEnsure db_recovery_file_dest_size &lt;= 90% of the Recovery Area diskgroup TOTAL_MB size\n"}]}, {"id": "b30dd092-03cf-4669-bea8-a2103bf62d8b", "checkCategory": "RDBMS", "checkID": "AAA18D72CD2CABDFE040E50A1EC05848", "checkType": "OS", "checkName": "Check for COMPATIBLE", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Database parameter COMPATIBLE is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Check for COMPATIBLE\n\n\n\ninstance_version = 21.0.0.0.0 and compatible = 21.0.0"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Database parameter COMPATIBLE is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Check for COMPATIBLE\n\n\n\ninstance_version = 21.0.0.0.0 and compatible = 21.0.0"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nExperience and testing has shown that certain database initialization parameters should be set at specific values. These are the best practice values set at deployment time. By setting these database initialization parameters as recommended, known problems may be avoided and performance maximized. The parameters are common to all database instances. The impact of setting these parameters is minimal. The performance related settings provide guidance to maintain highest stability without sacrificing performance. Changing the default performance settings can be done after careful performance evaluation and clear understanding of the performance impact. \n\n\n\nRisk:\n\nIf the database initialization parameters are not set as recommended, a variety of issues may be encountered, depending upon which initialization parameter is not set as recommended, and the actual set value. \n\n\n\nAction / Repair:\n\nSet database parameter COMPATIBLE to current RDBMS version in use out to the fourth digit (ex: 11.2.0.2)."}]}, {"id": "67f25ff4-b8e0-4e1e-8a63-5c237fc72971", "checkCategory": "RDBMS", "checkID": "AAA80656B22DB08BE040E50A1EC02222", "checkType": "OS", "checkName": "High Redundancy Redolog files", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Database parameter Db_create_online_log_dest_n is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - High Redundancy Redolog files\n\n\n\nHigh redundancy disk groups =           2\nNumber of redo log groups with more than 1 member =              0\nNumber of diskgroup where redo log members are multiplexed =                        1"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Database parameter Db_create_online_log_dest_n is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - High Redundancy Redolog files\n\n\n\nHigh redundancy disk groups =           2\nNumber of redo log groups with more than 1 member =              0\nNumber of diskgroup where redo log members are multiplexed =                        1"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nExperience and testing has shown that certain database initialization parameters should be set at specific values. These are the best practice values set at deployment time. By setting these database initialization parameters as recommended, known problems may be avoided and performance maximized. The parameters are common to all database instances. The impact of setting these parameters is minimal. The performance related settings provide guidance to maintain highest stability without sacrificing performance. Changing the default performance settings can be done after careful performance evaluation and clear understanding of the performance impact. \n\n\n\nRisk:\n\nIf the database initialization parameters are not set as recommended, a variety of issues may be encountered, depending upon which initialization parameter is not set as recommended, and the actual set value. \n\n\n\nAction / Repair:\n\nEnsure the db_create_online_log_dest_n is configured for a high redundancy diskgroup\n\nA high redundancy diskgroup optimizes availability.\n\nIf a high redundancy disk group is available, use the first high ASM redundancy disk group for all your Online Redo Logs or Standby Redo Logs. Use only one log member to minimize performance impact.\n\nIf a high redundancy disk group is not available, multiplex redo log members across DATA and RECO ASM disk groups for additional protection."}]}, {"id": "771d6cc4-9304-4ea8-a11e-d8b7112ea022", "checkCategory": "HOST", "checkID": "B0019E089CAEC025E053D398EB0A3E83", "checkType": "OS_OUT_CHECK", "checkName": "Verify RoCE Interfaces Status [Database Server]", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "All RoCE interfaces have a status of \"UP\""}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR VERIFY ROCE INTERFACES STATUS [DATABASE SERVER]\n\n\n\nSUCCESS:2 RoCE interfaces had a state of \"UP\""}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "All RoCE interfaces have a status of \"UP\""}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR VERIFY ROCE INTERFACES STATUS [DATABASE SERVER]\n\n\n\nSUCCESS:2 RoCE interfaces had a state of \"UP\""}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nFor maximum throughput and protection, all available RoCE interfaces on the database and storage servers should have a state of \"UP\".\n\nRisk:\n\nNot having all RoCE interfaces \"UP\" may lead to reduced performance and introduce single points of failure.\n\nAction / Repair:\n\nTo verify RoCE Interfaces Status, as the \"root\" userid, execute the following on each database and storage server:\n\n#gather data\nRAW_DATA=$(ip addr | egrep \"re[[:digit:]]:|re[[:digit:]]pf\" | egrep -v \"inet\")\nUP_INTERFACES=$(echo \"$RAW_DATA\" | egrep \"[[:space:]]UP[[:space:]]\")\nUP_INTRFCE_CNT=$(echo \"$RAW_DATA\" | egrep -c \"[[:space:]]UP[[:space:]]\")\nBAD_INTERFACES=$(echo \"$RAW_DATA\" | egrep -v \"[[:space:]]UP[[:space:]]\")\nBAD_INTRFCE_CNT=$(echo \"$RAW_DATA\" | egrep -cv \"[[:space:]]UP[[:space:]]\")\n#analyze data\nif [[ $BAD_INTRFCE_CNT -gt 0 ]]\nthen\n  echo -e \"FAILURE:  one or more RoCE interfaces had a state other than \"UP\".  Details:\\n$BAD_INTERFACES\"\nelse\n  echo -e \"SUCCESS: $UP_INTRFCE_CNT RoCE interfaces had a state of \"UP\"\"\nfi\n\nThe expected output should be similar to the following:\n\nSUCCESS: 4 RoCE interfaces had a state of \"UP\"\n\nExample of a \"FAILURE\" result:\n\nFAILURE:  one or more RoCE interfaces had a state other than \"UP\".  Details:\n19: re1: &lt;BROADCAST,MULTICAST&gt; mtu 2300 qdisc mq state DOWN group default qlen 1000\n24: re6: &lt;BROADCAST,MULTICAST&gt; mtu 2300 qdisc mq state DOWN group default qlen 1000\n\nIf a \"FAILURE\" result is returned, investigate for root cause and take corrective action. "}]}, {"id": "c6c5aca9-9cd2-47c9-921d-3f3fa3f923b2", "checkCategory": "CRS HOME", "checkID": "B01200FAD7E0711CE053D498EB0AD42C", "checkType": "OS", "checkName": "Verify diskgroup attributes are set to enable Hardware Assisted Resilient Data (HARD) capability", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "All diskgroup attributes are set to enable Hardware Assisted Resilient Data (HARD) capability"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY DISKGROUP ATTRIBUTES ARE SET TO ENABLE HARDWARE ASSISTED RESILIENT DATA (HARD) CAPABILITY\n\n\n\nSUCCESS:Diskgroups have the expected values for HARD check attributes"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThere are specific diskgroup attributes that allow the detection of a extent mismatch between the partners during a rebalance operation. When a valid copy is found on any of the mirrors, it is used to repair the invalid copy, keeping the consistency of the data.\n\nRisk:\n\nAn incorrect setting of diskgroup attributes will disable HARD check detection during rebalance operations. When a corrupted block is found it could be moved to any of the mirrors, potentially replacing a valid copy. The higher the number of rebalance operations, the higher the chance to loose all the valid block copies.\n\nAction / Repair:\n\nThe correct diskgroup attribute values vary by software version level. Exachk runs the appropriate checks based upon the discovered environment configuration. To verify diskgroup attributes are set to enable Hardware Assisted Resilient Data (HARD) capability, run Exachk and review the provided report.\n\nNOTE: This best practice will only succeed if all the following are true:\nFor grid version series 12 or 18:\nAttribute Name \tValue\ncontent.check \tFALSE\nhard_check.enabled \tTRUE\n\nFor grid version 19 or higher:\nAttribute Name \tValue\ncontent.check \tTRUE\nhard_check.enabled \tTRUE \n\nThe expected output in the Exachk report should be as follows:\n\nIn the \"Findings Passed\" summary section of the report, the overall result should be \"PASS\":\n\nPASS   OS Check   All diskgroup attributes are set to enable Hardware Assisted Resilient Data (HARD) capability   All Database Servers   View\n\nIn the \"View\" detail section of the report for each individual database server:\n\nStatus on randomadm01:\nPASS =&gt; All diskgroup attributes are set to enable Hardware Assisted Resilient Data (HARD) capability\n\nDATA FROM RANDOMADM01 FOR VERIFY DISKGROUP ATTRIBUTES ARE SET TO ENABLE HARDWARE ASSISTED RESILIENT DATA (HARD) CAPABILITY\n\nSUCCESS: Diskgroups have the correct values for HARD check attributes\n\nA \"FAIL\" result view detail example:\n\nStatus on randomadm01:\nCRITICAL =&gt; One or more diskgroup attributes are not set to enable Hardware Assisted Resilient Data (HARD) capability\n\nDATA FROM RANDOMADM01 FOR VERIFY DISKGROUP ATTRIBUTES ARE SET TO ENABLE HARDWARE ASSISTED RESILIENT DATA (HARD) CAPABILITY\n\nFor Grid Infrastructure version 19 or higher, the expected values are:\ncontent.check TRUE ; hidden attribute hard_check.enabled TRUE\n\nFAILURE: Diskgroup DATAC1 have incorrect attributes. Please review the list: content.check: FALSE hard_check.enable: TRUE\nFAILURE: Diskgroup RECOC1 have incorrect attributes. Please review the list: content.check: FALSE hard_check.enable: TRUE\nIMPORTANT: Incorrect set of attributes could cause ASM rebalance not detecting HARD check violations (corrupted blocks)\n           This will spread corruption through the mirrored cells, leading to complete data corruption\n\nIf a \"FAILURE:\" result is returned, refer to the appropriate version specific documentation to set the attributes as recommended.\n\n    NOTE: If after corrective actions are completed you wish to run just this check without a full Exachk run, execute the following as the root userid:\n\n    exachk -check B01200FAD7E0711CE053D498EB0AD42C"}]}, {"id": "275d2408-88f8-47fb-a8cf-7206aa3f159e", "checkCategory": "RDBMS", "checkID": "B24A4497B2F5C871E053D298EB0A047D", "checkType": "SQL", "checkName": "Verify Local Undo Enabled in 12cR2 and later CDBs", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "success", "statusLabel": "PASS", "output": "Local undo is enabled"}, "children": [{"attr": {"consoleOutput": "\n\n'LOCAL_UNDO_ENABLED='||PROPERTY_VALUE\n-------------------------------------\nLOCAL_UNDO_ENABLED = TRUE"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nIn Oracle RDBMS 12cR2, the ability to create undo tablespaces in each pluggable database (PDB), also known as local undo, was added. Oracle recommends that local undo be enabled in all container databases (CDBs) for the following reasons:\n\n    Enables all of the PDB \"hot\" technologies like PDB relocate, PDB hot clone, refresh PDB. All of the data for the PDB is self contained in the PDBs datafiles, including UNDO, so these type of operations have no impact on other PDBs.\n    Improves flashback PDB functionality. There are additional steps required to ensure getting a clean restore point when local undo is not used.\n    Improves PDB point in time recovery. When using shared undo, PITR of a PDB requires creation of an auxiliary instance as we need to get the shared UNDO datafiles to the same point in time in order to perform rollforward/rollback phases. With local undo, we can restore the undo tablespaces for that PDB in place, again not impacting other PDBs. This uses less resources (no auxiliary instance) and is potentially faster (less files to restore as no auxiliary set datafiles need to be restored). \n\nNote that undo tablespaces will be created for each instance that PDB is opened, thus consuming more space than in a shared undo configuration.\n\nFor 12cR2 and 18c databases the default setting is shared undo. For 19c and later, the default setting is local undo. \n\nRisk:\n\nIf local undo is not enabled, the functionality mentioned in the Benefit/Impact section is not available.\n\nAction / Repair:\n\nTo verify the current local undo state in a CDB, connect to the target database with sqlplus as SYSDBA and execute the following sql command:\n\nSELECT property_value FROM database_properties WHERE property_name='LOCAL_UNDO_ENABLED';\n\nThe expected output is:\n\nPROPERTY_VALUE\n--------------------------------------------------------------------------------\nTRUE\n\nIf the value of LOCAL_UNDO_ENABLED is not \"TRUE\" or no rows are returned, enable local undo by performing the following:\n\n    NOTE: Changing this setting requires database downtime. \n\n    For Real Application Cluster (RAC) databases, connect as sysdba to one instance via SQLPLUS and put the database in EXCLUSIVE mode\n\n    SQL&gt; alter system set cluster_database=false scope=spfile;\n\n    Stop the database\n\n    $ srvctl stop database -d &lt;db_unique_name&gt;;\n\n    Connect as sysdba to one instance via SQLPLUS and startup the instance in UPGRADE mode\n\n    SQL&gt; startup upgrade;\n\n    Enable local undo\n\n    SQL&gt; alter database local undo on;\n\n    For RAC databases, take the database out of EXCLUSIVE mode\n\n    SQL&gt; alter system set cluster_database=true scope=spfile; \n\n    Shutdown the instance\n\n    SQL&gt; shutdown immediate;\n\n    Restart the database\n\n    $srvctl start database -d &lt;db_unique_name&gt;;\n\nEach PDB will automatically create it's own undo tablespace for each RAC instance when it is started for the first time with the new setting. To gain more control over sizing and setting of undo for each PDB, please see Document 2169828.1. "}, {"id": "e03919ad-0066-472b-b4e9-52e163d8f797", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=2169828.1", "text": "Note: 2169828.1 - Undo Modes in 12.2 Multitenant Databases - Local and Shared Modes"}]}]}, {"id": "9c854b74-6f46-429f-b0d6-5a8f2f011c1f", "checkCategory": "HOST", "checkID": "B363A5985C07C6E3E053D598EB0AA548", "checkType": "OS_OUT_CHECK", "checkName": "Verify TCP Selective Acknowledgement is enabled", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "TCP Selective Acknowledgment is enabled"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR VERIFY TCP SELECTIVE ACKNOWLEDGEMENT IS ENABLED\n\n\n\nSUCCESS:TCP Selective Acknowledgment is enabled.  Details:\nnet.ipv4.tcp_dsack = 1\nnet.ipv4.tcp_sack = 1"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "TCP Selective Acknowledgment is enabled"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR VERIFY TCP SELECTIVE ACKNOWLEDGEMENT IS ENABLED\n\n\n\nSUCCESS:TCP Selective Acknowledgment is enabled.  Details:\nnet.ipv4.tcp_dsack = 1\nnet.ipv4.tcp_sack = 1"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nFor maximum performance with large data transfers, TCP Selective Acknowledgement should be enabled. \n\nRisk:\n\nIf TCP Selective Acknowledgement is not enabled, there may be severe network throughput degradation for large data transfers during operations such as RMAN backup or restore, database migrations, cloning, instantiation, or Data Guard transport. Network throughput has been observed to reduce by a factor of 10 in some cases. \n\nAction / Repair:\n\nNOTE: Even if a database server has TCP Selective Acknowledgement enabled (e.g: Exadata default), end to end network throughput can still degrade if any participating client or sender database server does not have it enabled.\n\nTo verify TCP Selective Acknowledgement is enabled, as the root userid on each database server execute the following code:\n\nRAW_DSACK_DATA=$(sysctl net.ipv4.tcp_dsack)\nDSACK_VALUE=$(echo \"$RAW_DSACK_DATA\" | cut -d\"=\" -f2 | tr -dc [[:digit:]])\nRAW_SACK_DATA=$(sysctl net.ipv4.tcp_sack)\nSACK_VALUE=$(echo \"$RAW_SACK_DATA\" | cut -d\"=\" -f2 | tr -dc [[:digit:]])\nif [[ $DSACK_VALUE = \"1\" && $SACK_VALUE = \"1\" ]]\nthen\n  echo -e \"SUCCESS: TCP Selective Acknowledgment is enabled.  Details:\\n$RAW_DSACK_DATA\\n$RAW_SACK_DATA\"\nelse\n  echo -e \"FAILURE: TCP Selective Acknowledgment is not enabled.  Details:\\n$RAW_DSACK_DATA\\n$RAW_SACK_DATA\"\nfi\n\nThe expected output is:\n\nSUCCESS: TCP Selective Acknowledgment is enabled.  Details:\nnet.ipv4.tcp_dsack = 1\nnet.ipv4.tcp_sack = 1\n\nA \"FAILURE\" example:\n\nFAILURE: TCP Selective Acknowledgment is not enabled.  Details:\nnet.ipv4.tcp_dsack = 1\nnet.ipv4.tcp_sack = 0\n\nIf TCP Selective acknowlegement is not enabled, execute the following code as the root userid:\n\nsysctl -w net.ipv4.tcp_dsack=1\nsysctl -w net.ipv4.tcp_sack=1"}]}, {"id": "28240d8c-2047-44b9-91a1-619320277a12", "checkCategory": "HOST", "checkID": "B4453385F891B374E053D298EB0AAFAB", "checkType": "OS_OUT_CHECK", "checkName": "Verify RDMA Network Fabric kernel parameters on database servers", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "All RDMA Network Fabric kernel parameters on database servers are as expected"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR VERIFY RDMA NETWORK FABRIC KERNEL PARAMETERS ON DATABASE SERVERS\n\n\n\nSUCCESS: All RDMA Network Fabric kernel parameter settings are as recommended for an active/active interface:running kernel parameters\nnet.ipv4.conf.re0.accept_local=1\nnet.ipv4.conf.re1.accept_local=1\nnet.ipv4.conf.re0.rp_filter=0\nnet.ipv4.conf.re1.rp_filter=0\nnet.ipv4.conf.re0.arp_announce=2\nnet.ipv4.conf.re1.arp_announce=2\nnet.ipv4.conf.all.rp_filter=0\nnet.ipv4.conf.default.rp_filter=0\nnet.ipv4.conf.all.accept_local=1\nSUCCESS: All RDMA Network Fabric kernel parameter settings are as recommended for an active/active interface:kernel parameters at boot\nnet.ipv4.conf.re0.accept_local=1\nnet.ipv4.conf.re1.accept_local=1\nnet.ipv4.conf.re0.rp_filter=0\nnet.ipv4.conf.re1.rp_filter=0\nnet.ipv4.conf.re0.arp_announce=2\nnet.ipv4.conf.re1.arp_announce=2\nnet.ipv4.conf.all.rp_filter=0\nnet.ipv4.conf.default.rp_filter=0\nnet.ipv4.conf.all.accept_local=1"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "All RDMA Network Fabric kernel parameters on database servers are as expected"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR VERIFY RDMA NETWORK FABRIC KERNEL PARAMETERS ON DATABASE SERVERS\n\n\n\nSUCCESS: All RDMA Network Fabric kernel parameter settings are as recommended for an active/active interface:running kernel parameters\nnet.ipv4.conf.re0.accept_local=1\nnet.ipv4.conf.re1.accept_local=1\nnet.ipv4.conf.re0.rp_filter=0\nnet.ipv4.conf.re1.rp_filter=0\nnet.ipv4.conf.re0.arp_announce=2\nnet.ipv4.conf.re1.arp_announce=2\nnet.ipv4.conf.all.rp_filter=0\nnet.ipv4.conf.default.rp_filter=0\nnet.ipv4.conf.all.accept_local=1\nSUCCESS: All RDMA Network Fabric kernel parameter settings are as recommended for an active/active interface:kernel parameters at boot\nnet.ipv4.conf.re0.accept_local=1\nnet.ipv4.conf.re1.accept_local=1\nnet.ipv4.conf.re0.rp_filter=0\nnet.ipv4.conf.re1.rp_filter=0\nnet.ipv4.conf.re0.arp_announce=2\nnet.ipv4.conf.re1.arp_announce=2\nnet.ipv4.conf.all.rp_filter=0\nnet.ipv4.conf.default.rp_filter=0\nnet.ipv4.conf.all.accept_local=1"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThere are RDMA Network Fabric kernel parameter settings required for Exadata to work correctly that vary depending upon if a specific interface (RoCE or InfiniBand) is configured as active/passive or active/active.\n\nFor an active/passive configuration, the network kernel parameter settings for all RDMA Fabric interfaces (only InfiniBand on older Exadata systems) should be:\nNetwork Kernel Parameter\tValue\naccept_local\t1\nrp_filter\t0\n\nFor an active/active configuration, the network kernel parameter settings for all RDMA Fabric interfaces should be:\nNetwork Kernel Parameter\tValue\naccept_local\t1\nrp_filter\t0\narp_announce\t2\n- AND the three single kernel parameters\nNetwork Kernel Parameter\tValue\nnet.ipv4.conf.all.rp_filter\t0\nnet.ipv4.conf.default.rp_filter\t0\nnet.ipv4.conf.all.accept_local\t1\n\nThe impact of verifying the RDMA Network Fabric kernel parameters is minimal. Correcting a network kernel parameter requires updating the boot configuration file and restarting the interface(s). \n\nNOTE: These recommendations are for the RDMA Fabric interfaces on database servers only! They do not apply to the Ethernet interfaces on the database servers. No changes are permitted on the storage servers.\n\nRisk:\n\nIncorrect RDMA Network Fabric kernel parameter settings may prevent RAC from starting, or result in dropped packets and inconsistent RAC operation.  For the Ethernet RoCE network it could cause all systems connected to freeze.\n\nAction / Repair:\n\nThe expected output should be similar to (2 socket active/active example).  The first section are the values of the running configuration.  The second section are how they are configured at boot.\n\nSUCCESS:  All RDMA Fabric kernel parameter settings are as recommended for an active/active interface: running kernel parameters\nnet.ipv4.conf.re0.accept_local=1\nnet.ipv4.conf.re1.accept_local=1\nnet.ipv4.conf.re0.rp_filter=0\nnet.ipv4.conf.re1.rp_filter=0\nnet.ipv4.conf.re0.arp_announce=2\nnet.ipv4.conf.re1.arp_announce=2\nnet.ipv4.conf.all.rp_filter=0\nnet.ipv4.conf.default.rp_filter=0\nnet.ipv4.conf.all.accept_local=1\nSUCCESS:  All RDMA Fabric kernel parameter settings are as recommended for an active/active interface: kernel parameters at boot\nnet.ipv4.conf.re0.accept_local=1\nnet.ipv4.conf.re1.accept_local=1\nnet.ipv4.conf.re0.rp_filter=0\nnet.ipv4.conf.re1.rp_filter=0\nnet.ipv4.conf.re0.arp_announce=2\nnet.ipv4.conf.re1.arp_announce=2\nnet.ipv4.conf.all.rp_filter=0\nnet.ipv4.conf.default.rp_filter=0\nnet.ipv4.conf.all.accept_local=1\n\n- OR - (8 socket active/active example)\n\nSUCCESS:  All RDMA Fabric kernel parameter settings are as recommended for an active/active interface: running kernel parameters\nnet.ipv4.conf.ib0.accept_local=1\n&lt;outpout truncated&gt;\nnet.ipv4.conf.ib7.accept_local=1\nnet.ipv4.conf.ib0.rp_filter=0\n&lt;outpout truncated&gt;\nnet.ipv4.conf.ib7.rp_filter=0\nnet.ipv4.conf.ib0.arp_announce=2\n&lt;outpout truncated&gt;\nnet.ipv4.conf.ib7.arp_announce=2\nnet.ipv4.conf.all.rp_filter=0\nnet.ipv4.conf.default.rp_filter=0\nnet.ipv4.conf.all.accept_local=1\nSUCCESS:  All RDMA Fabric kernel parameter settings are as recommended for an active/active interface: kernel parameters at boot\nnet.ipv4.conf.ib0.accept_local=1\n&lt;outpout truncated&gt;\nnet.ipv4.conf.ib7.accept_local=1\nnet.ipv4.conf.ib0.rp_filter=0\n&lt;outpout truncated&gt;\nnet.ipv4.conf.ib7.rp_filter=0\nnet.ipv4.conf.ib0.arp_announce=2\n&lt;outpout truncated&gt;\nnet.ipv4.conf.all.rp_filter=0\nnet.ipv4.conf.default.rp_filter=0\nnet.ipv4.conf.all.accept_local=1  \n\nIf a \"FAILURE: ...\" message appears, investigate for root cause, make the necessary edits to the boot configuration file, and restart the interface(s).  A failure example:\n\nFAILURE:  One or more RDMA Fabric kernel parameter settings are not as recommended for an active/passive interface: running kernel parameters\nnet.ipv4.conf.bondib0.accept_local=0\nnet.ipv4.conf.ib0.accept_local=0\nnet.ipv4.conf.ib1.accept_local=0\nnet.ipv4.conf.bondib0.rp_filter=1\nnet.ipv4.conf.ib0.rp_filter=1\nnet.ipv4.conf.ib1.rp_filter=1\nnet.ipv4.conf.bondib0.arp_announce=0\nnet.ipv4.conf.ib0.arp_announce=0\nnet.ipv4.conf.ib1.arp_announce=0\nnet.ipv4.conf.all.rp_filter=1\nnet.ipv4.conf.default.rp_filter=1\nnet.ipv4.conf.all.accept_local=0\nFAILURE:  One or more RDMA Fabric kernel parameter settings are not as recommended for an active/passive interface: kernel parameters at boot\naccept_local not found\nrp_filter not found\narp_announce not found\nnet.ipv4.conf.all.rp_filter not found\nnet.ipv4.conf.default.rp_filter=1\nnet.ipv4.conf.all.accept_local not found\n\nIf the kernel parameters were not configured in the boot configuration file, this is noted as \"not found\".\n\n\nNOTE: These recommendations are for the RDMA Fabric interfaces on database servers only! They do not apply to the Ethernet interfaces on the database servers. No changes are permitted on the storage servers."}]}, {"id": "847867b9-8693-4c1e-b9c5-8753a4e1ecba", "checkCategory": "ASM", "checkID": "B5D069540D986319E0431EC0E50A82B1", "checkType": "SQL_PARAM", "checkName": "Check for parameter memory_target", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "ASM parameter MEMORY_TARGET is set according to recommended value"}, "children": [{"attr": {"consoleOutput": "\n+ASM1.allow_group_access_to_sga = FALSE\n+ASM2.allow_group_access_to_sga = FALSE\n+ASM1.asm_diskgroups = RECOC1\n+ASM2.asm_diskgroups = RECOC1\n+ASM1.asm_diskstring = o/*/DATAC1_*, o/*/RECOC1_*, /dev/exadata_quorum/*\n+ASM2.asm_diskstring = o/*/DATAC1_*, o/*/RECOC1_*, /dev/exadata_quorum/*\n+ASM1.asm_power_limit = 4\n+ASM2.asm_power_limit = 4\n+ASM1.asm_preferred_read_failure_groups =\n+ASM2.asm_preferred_read_failure_groups =\n+ASM1.audit_file_dest = /u01/app/21.0.0.0/grid/rdbms/audit\n+ASM2.audit_file_dest = /u01/app/21.0.0.0/grid/rdbms/audit\n+ASM1.audit_sys_operations = TRUE\n+ASM2.audit_sys_operations = TRUE\n+ASM1.audit_syslog_level = LOCAL0.INFO\n+ASM2.audit_syslog_level = LOCAL0.INFO\n+ASM1.audit_trail = NONE\n+ASM2.audit_trail = NONE\n+ASM1.background_core_dump = partial\n+ASM2.background_core_dump = partial\n+ASM1.background_dump_dest = /u01/app/21.0.0.0/grid/rdbms/log\n+ASM2.background_dump_dest = /u01/app/21.0.0.0/grid/rdbms/log\n+ASM1.cdb_cluster = FALSE\n+ASM2.cdb_cluster = FALSE\n+ASM1.cluster_database = TRUE\n+ASM2.cluster_database = TRUE\n+ASM1.cluster_interconnects = 192.168.11.128:192.168.11.129\n+ASM2.cluster_interconnects = 192.168.11.132:192.168.11.133\n+ASM1.connection_brokers = ((TYPE=DEDICATED)(BROKERS=1)), ((TYPE=EMON)(BROKERS=1))\n+ASM2.connection_brokers = ((TYPE=DEDICATED)(BROKERS=1)), ((TYPE=EMON)(BROKERS=1))\n+ASM1.core_dump_dest = /u01/app/oracle/diag/asm/+asm/+ASM1/cdump\n+ASM2.core_dump_dest = /u01/app/oracle/diag/asm/+asm/+ASM2/cdump\n+ASM1.cpu_count = 4\n+ASM2.cpu_count = 4\n+ASM1.db_cache_size = 0\n+ASM2.db_cache_size = 0\n+ASM1.db_ultra_safe = OFF\n+ASM2.db_ultra_safe = OFF\n+ASM1.db_unique_name = +ASM\n+ASM2.db_unique_name = +ASM\n+ASM1.diagnostic_dest = /u01/app/oracle\n+ASM2.diagnostic_dest = /u01/app/oracle\n+ASM1.diagnostics_control = IGNORE\n+ASM2.diagnostics_control = IGNORE\n+ASM1.event =\n+ASM2.event =\n+ASM1.file_mapping = FALSE\n+ASM2.file_mapping = FALSE\n+ASM1.filesystemio_options = none\n+ASM2.filesystemio_options = none\n+ASM1.forward_listener =\n+ASM2.forward_listener =\n+ASM1.heartbeat_batch_size = 5\n+ASM2.heartbeat_batch_size = 5\n+ASM1.ifile =\n+ASM2.ifile =\n+ASM1.instance_abort_delay_time = 0\n+ASM2.instance_abort_delay_time = 0\n+ASM1.instance_name = +ASM1\n+ASM2.instance_name = +ASM2\n+ASM1.instance_number = 1\n+ASM2.instance_number = 2\n+ASM1.instance_type = ASM\n+ASM2.instance_type = ASM\n+ASM1.large_pool_size = 16777216\n+ASM2.large_pool_size = 16777216\n+ASM1.ldap_directory_sysauth = no\n+ASM2.ldap_directory_sysauth = no\n+ASM1.listener_networks = ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (LOCAL_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr)(REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\"))\n+ASM2.listener_networks = ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (LOCAL_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr)(REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\"))\n+ASM1.local_listener =  (ADDRESS=(PROTOCOL=TCP)(HOST=10.214.209.68)(PORT=1521))\n+ASM2.local_listener =  (ADDRESS=(PROTOCOL=TCP)(HOST=10.214.209.69)(PORT=1521))\n+ASM1.lock_name_space =\n+ASM2.lock_name_space =\n+ASM1.lock_sga = FALSE\n+ASM2.lock_sga = FALSE\n+ASM1.max_dump_file_size = unlimited\n+ASM2.max_dump_file_size = unlimited\n+ASM1.memoptimize_pool_size = 0\n+ASM2.memoptimize_pool_size = 0\n+ASM1.memory_max_target = 0\n+ASM2.memory_max_target = 0\n+ASM1.memory_target = 0\n+ASM2.memory_target = 0\n+ASM1.nls_calendar =\n+ASM2.nls_calendar =\n+ASM1.nls_comp = BINARY\n+ASM2.nls_comp = BINARY\n+ASM1.nls_currency =\n+ASM2.nls_currency =\n+ASM1.nls_date_format =\n+ASM2.nls_date_format =\n+ASM1.nls_date_language =\n+ASM2.nls_date_language =\n+ASM1.nls_dual_currency =\n+ASM2.nls_dual_currency =\n+ASM1.nls_iso_currency =\n+ASM2.nls_iso_currency =\n+ASM1.nls_language = AMERICAN\n+ASM2.nls_language = AMERICAN"}}]}, {"attr": {"target": "scaqal03adm06vm01:+ASM2", "status": "success", "statusLabel": "PASS", "output": "ASM parameter MEMORY_TARGET is set according to recommended value"}, "children": [{"attr": {"consoleOutput": "\n+ASM1.allow_group_access_to_sga = FALSE\n+ASM2.allow_group_access_to_sga = FALSE\n+ASM1.asm_diskgroups = RECOC1\n+ASM2.asm_diskgroups = RECOC1\n+ASM1.asm_diskstring = o/*/DATAC1_*, o/*/RECOC1_*, /dev/exadata_quorum/*\n+ASM2.asm_diskstring = o/*/DATAC1_*, o/*/RECOC1_*, /dev/exadata_quorum/*\n+ASM1.asm_power_limit = 4\n+ASM2.asm_power_limit = 4\n+ASM1.asm_preferred_read_failure_groups =\n+ASM2.asm_preferred_read_failure_groups =\n+ASM1.audit_file_dest = /u01/app/21.0.0.0/grid/rdbms/audit\n+ASM2.audit_file_dest = /u01/app/21.0.0.0/grid/rdbms/audit\n+ASM1.audit_sys_operations = TRUE\n+ASM2.audit_sys_operations = TRUE\n+ASM1.audit_syslog_level = LOCAL0.INFO\n+ASM2.audit_syslog_level = LOCAL0.INFO\n+ASM1.audit_trail = NONE\n+ASM2.audit_trail = NONE\n+ASM1.background_core_dump = partial\n+ASM2.background_core_dump = partial\n+ASM1.background_dump_dest = /u01/app/21.0.0.0/grid/rdbms/log\n+ASM2.background_dump_dest = /u01/app/21.0.0.0/grid/rdbms/log\n+ASM1.cdb_cluster = FALSE\n+ASM2.cdb_cluster = FALSE\n+ASM1.cluster_database = TRUE\n+ASM2.cluster_database = TRUE\n+ASM1.cluster_interconnects = 192.168.11.128:192.168.11.129\n+ASM2.cluster_interconnects = 192.168.11.132:192.168.11.133\n+ASM1.connection_brokers = ((TYPE=DEDICATED)(BROKERS=1)), ((TYPE=EMON)(BROKERS=1))\n+ASM2.connection_brokers = ((TYPE=DEDICATED)(BROKERS=1)), ((TYPE=EMON)(BROKERS=1))\n+ASM1.core_dump_dest = /u01/app/oracle/diag/asm/+asm/+ASM1/cdump\n+ASM2.core_dump_dest = /u01/app/oracle/diag/asm/+asm/+ASM2/cdump\n+ASM1.cpu_count = 4\n+ASM2.cpu_count = 4\n+ASM1.db_cache_size = 0\n+ASM2.db_cache_size = 0\n+ASM1.db_ultra_safe = OFF\n+ASM2.db_ultra_safe = OFF\n+ASM1.db_unique_name = +ASM\n+ASM2.db_unique_name = +ASM\n+ASM1.diagnostic_dest = /u01/app/oracle\n+ASM2.diagnostic_dest = /u01/app/oracle\n+ASM1.diagnostics_control = IGNORE\n+ASM2.diagnostics_control = IGNORE\n+ASM1.event =\n+ASM2.event =\n+ASM1.file_mapping = FALSE\n+ASM2.file_mapping = FALSE\n+ASM1.filesystemio_options = none\n+ASM2.filesystemio_options = none\n+ASM1.forward_listener =\n+ASM2.forward_listener =\n+ASM1.heartbeat_batch_size = 5\n+ASM2.heartbeat_batch_size = 5\n+ASM1.ifile =\n+ASM2.ifile =\n+ASM1.instance_abort_delay_time = 0\n+ASM2.instance_abort_delay_time = 0\n+ASM1.instance_name = +ASM1\n+ASM2.instance_name = +ASM2\n+ASM1.instance_number = 1\n+ASM2.instance_number = 2\n+ASM1.instance_type = ASM\n+ASM2.instance_type = ASM\n+ASM1.large_pool_size = 16777216\n+ASM2.large_pool_size = 16777216\n+ASM1.ldap_directory_sysauth = no\n+ASM2.ldap_directory_sysauth = no\n+ASM1.listener_networks = ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (LOCAL_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr)(REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\"))\n+ASM2.listener_networks = ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (LOCAL_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr)(REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\"))\n+ASM1.local_listener =  (ADDRESS=(PROTOCOL=TCP)(HOST=10.214.209.68)(PORT=1521))\n+ASM2.local_listener =  (ADDRESS=(PROTOCOL=TCP)(HOST=10.214.209.69)(PORT=1521))\n+ASM1.lock_name_space =\n+ASM2.lock_name_space =\n+ASM1.lock_sga = FALSE\n+ASM2.lock_sga = FALSE\n+ASM1.max_dump_file_size = unlimited\n+ASM2.max_dump_file_size = unlimited\n+ASM1.memoptimize_pool_size = 0\n+ASM2.memoptimize_pool_size = 0\n+ASM1.memory_max_target = 0\n+ASM2.memory_max_target = 0\n+ASM1.memory_target = 0\n+ASM2.memory_target = 0\n+ASM1.nls_calendar =\n+ASM2.nls_calendar =\n+ASM1.nls_comp = BINARY\n+ASM2.nls_comp = BINARY\n+ASM1.nls_currency =\n+ASM2.nls_currency =\n+ASM1.nls_date_format =\n+ASM2.nls_date_format =\n+ASM1.nls_date_language =\n+ASM2.nls_date_language =\n+ASM1.nls_dual_currency =\n+ASM2.nls_dual_currency =\n+ASM1.nls_iso_currency =\n+ASM2.nls_iso_currency =\n+ASM1.nls_language = AMERICAN\n+ASM2.nls_language = AMERICAN"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nExperience and testing has shown that certain ASM initialization parameters \nshould be set at specific values. These are the best practice values set at \ndeployment time. By setting these ASM initialization parameters as \nrecommended, known problems may be avoided and performance maximized. The \nparameters are specific to the ASM instances. Unless otherwise specified, the \nvalue is for both X2-2 and X2-8 Database Machines. The impact of setting \nthese parameters is minimal. \n \n\n\nRisk:\n\nIf the ASM initialization parameters are not set as recommended, a variety of \nissues may be encountered, depending upon which initialization parameter is \nnot set as recommended, and the actual set value. \n \n\n\nAction / Repair:\n\nThis disables memory_target for the ASM instance. \n \nNOTE: The proper way to implement the memory related parameters is as \nfollows. This is important as it works around an issue where memory_target \nremains set despite setting it to 0. \n\n    * alter system set pga_aggregate_target=400M sid='*' scope=spfile; \n    * alter system set memory_target=0 sid='*' scope=spfile; \n    * alter system set memory_max_target=0 sid='*' scope=spfile; \n    * alter system reset memory_max_target sid='*' scope=spfile; "}, {"id": "b00923c7-96ac-4a97-8960-68882e448d9a", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1373255.1", "text": "Note: 1373255.1 - \t11.2.0.1/11.2.0.2 to 11.2.0.3 Database Upgrade on Exadata Database Machine"}]}]}, {"id": "b705a00c-5ccd-4544-88ba-ff95691dee83", "checkCategory": "ASM", "checkID": "B5D069540D996319E0431EC0E50A82B1", "checkType": "SQL_PARAM", "checkName": "Check for parameter pga_aggregate_target", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "ASM parameter PGA_AGGREGATE_TARGET is set according to recommended value"}, "children": [{"attr": {"consoleOutput": "\n+ASM1.allow_group_access_to_sga = FALSE\n+ASM2.allow_group_access_to_sga = FALSE\n+ASM1.asm_diskgroups = RECOC1\n+ASM2.asm_diskgroups = RECOC1\n+ASM1.asm_diskstring = o/*/DATAC1_*, o/*/RECOC1_*, /dev/exadata_quorum/*\n+ASM2.asm_diskstring = o/*/DATAC1_*, o/*/RECOC1_*, /dev/exadata_quorum/*\n+ASM1.asm_power_limit = 4\n+ASM2.asm_power_limit = 4\n+ASM1.asm_preferred_read_failure_groups =\n+ASM2.asm_preferred_read_failure_groups =\n+ASM1.audit_file_dest = /u01/app/21.0.0.0/grid/rdbms/audit\n+ASM2.audit_file_dest = /u01/app/21.0.0.0/grid/rdbms/audit\n+ASM1.audit_sys_operations = TRUE\n+ASM2.audit_sys_operations = TRUE\n+ASM1.audit_syslog_level = LOCAL0.INFO\n+ASM2.audit_syslog_level = LOCAL0.INFO\n+ASM1.audit_trail = NONE\n+ASM2.audit_trail = NONE\n+ASM1.background_core_dump = partial\n+ASM2.background_core_dump = partial\n+ASM1.background_dump_dest = /u01/app/21.0.0.0/grid/rdbms/log\n+ASM2.background_dump_dest = /u01/app/21.0.0.0/grid/rdbms/log\n+ASM1.cdb_cluster = FALSE\n+ASM2.cdb_cluster = FALSE\n+ASM1.cluster_database = TRUE\n+ASM2.cluster_database = TRUE\n+ASM1.cluster_interconnects = 192.168.11.128:192.168.11.129\n+ASM2.cluster_interconnects = 192.168.11.132:192.168.11.133\n+ASM1.connection_brokers = ((TYPE=DEDICATED)(BROKERS=1)), ((TYPE=EMON)(BROKERS=1))\n+ASM2.connection_brokers = ((TYPE=DEDICATED)(BROKERS=1)), ((TYPE=EMON)(BROKERS=1))\n+ASM1.core_dump_dest = /u01/app/oracle/diag/asm/+asm/+ASM1/cdump\n+ASM2.core_dump_dest = /u01/app/oracle/diag/asm/+asm/+ASM2/cdump\n+ASM1.cpu_count = 4\n+ASM2.cpu_count = 4\n+ASM1.db_cache_size = 0\n+ASM2.db_cache_size = 0\n+ASM1.db_ultra_safe = OFF\n+ASM2.db_ultra_safe = OFF\n+ASM1.db_unique_name = +ASM\n+ASM2.db_unique_name = +ASM\n+ASM1.diagnostic_dest = /u01/app/oracle\n+ASM2.diagnostic_dest = /u01/app/oracle\n+ASM1.diagnostics_control = IGNORE\n+ASM2.diagnostics_control = IGNORE\n+ASM1.event =\n+ASM2.event =\n+ASM1.file_mapping = FALSE\n+ASM2.file_mapping = FALSE\n+ASM1.filesystemio_options = none\n+ASM2.filesystemio_options = none\n+ASM1.forward_listener =\n+ASM2.forward_listener =\n+ASM1.heartbeat_batch_size = 5\n+ASM2.heartbeat_batch_size = 5\n+ASM1.ifile =\n+ASM2.ifile =\n+ASM1.instance_abort_delay_time = 0\n+ASM2.instance_abort_delay_time = 0\n+ASM1.instance_name = +ASM1\n+ASM2.instance_name = +ASM2\n+ASM1.instance_number = 1\n+ASM2.instance_number = 2\n+ASM1.instance_type = ASM\n+ASM2.instance_type = ASM\n+ASM1.large_pool_size = 16777216\n+ASM2.large_pool_size = 16777216\n+ASM1.ldap_directory_sysauth = no\n+ASM2.ldap_directory_sysauth = no\n+ASM1.listener_networks = ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (LOCAL_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr)(REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\"))\n+ASM2.listener_networks = ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (LOCAL_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr)(REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\"))\n+ASM1.local_listener =  (ADDRESS=(PROTOCOL=TCP)(HOST=10.214.209.68)(PORT=1521))\n+ASM2.local_listener =  (ADDRESS=(PROTOCOL=TCP)(HOST=10.214.209.69)(PORT=1521))\n+ASM1.lock_name_space =\n+ASM2.lock_name_space =\n+ASM1.lock_sga = FALSE\n+ASM2.lock_sga = FALSE\n+ASM1.max_dump_file_size = unlimited\n+ASM2.max_dump_file_size = unlimited\n+ASM1.memoptimize_pool_size = 0\n+ASM2.memoptimize_pool_size = 0\n+ASM1.memory_max_target = 0\n+ASM2.memory_max_target = 0\n+ASM1.memory_target = 0\n+ASM2.memory_target = 0\n+ASM1.nls_calendar =\n+ASM2.nls_calendar =\n+ASM1.nls_comp = BINARY\n+ASM2.nls_comp = BINARY\n+ASM1.nls_currency =\n+ASM2.nls_currency =\n+ASM1.nls_date_format =\n+ASM2.nls_date_format =\n+ASM1.nls_date_language =\n+ASM2.nls_date_language =\n+ASM1.nls_dual_currency =\n+ASM2.nls_dual_currency =\n+ASM1.nls_iso_currency =\n+ASM2.nls_iso_currency =\n+ASM1.nls_language = AMERICAN\n+ASM2.nls_language = AMERICAN"}}]}, {"attr": {"target": "scaqal03adm06vm01:+ASM2", "status": "success", "statusLabel": "PASS", "output": "ASM parameter PGA_AGGREGATE_TARGET is set according to recommended value"}, "children": [{"attr": {"consoleOutput": "\n+ASM1.allow_group_access_to_sga = FALSE\n+ASM2.allow_group_access_to_sga = FALSE\n+ASM1.asm_diskgroups = RECOC1\n+ASM2.asm_diskgroups = RECOC1\n+ASM1.asm_diskstring = o/*/DATAC1_*, o/*/RECOC1_*, /dev/exadata_quorum/*\n+ASM2.asm_diskstring = o/*/DATAC1_*, o/*/RECOC1_*, /dev/exadata_quorum/*\n+ASM1.asm_power_limit = 4\n+ASM2.asm_power_limit = 4\n+ASM1.asm_preferred_read_failure_groups =\n+ASM2.asm_preferred_read_failure_groups =\n+ASM1.audit_file_dest = /u01/app/21.0.0.0/grid/rdbms/audit\n+ASM2.audit_file_dest = /u01/app/21.0.0.0/grid/rdbms/audit\n+ASM1.audit_sys_operations = TRUE\n+ASM2.audit_sys_operations = TRUE\n+ASM1.audit_syslog_level = LOCAL0.INFO\n+ASM2.audit_syslog_level = LOCAL0.INFO\n+ASM1.audit_trail = NONE\n+ASM2.audit_trail = NONE\n+ASM1.background_core_dump = partial\n+ASM2.background_core_dump = partial\n+ASM1.background_dump_dest = /u01/app/21.0.0.0/grid/rdbms/log\n+ASM2.background_dump_dest = /u01/app/21.0.0.0/grid/rdbms/log\n+ASM1.cdb_cluster = FALSE\n+ASM2.cdb_cluster = FALSE\n+ASM1.cluster_database = TRUE\n+ASM2.cluster_database = TRUE\n+ASM1.cluster_interconnects = 192.168.11.128:192.168.11.129\n+ASM2.cluster_interconnects = 192.168.11.132:192.168.11.133\n+ASM1.connection_brokers = ((TYPE=DEDICATED)(BROKERS=1)), ((TYPE=EMON)(BROKERS=1))\n+ASM2.connection_brokers = ((TYPE=DEDICATED)(BROKERS=1)), ((TYPE=EMON)(BROKERS=1))\n+ASM1.core_dump_dest = /u01/app/oracle/diag/asm/+asm/+ASM1/cdump\n+ASM2.core_dump_dest = /u01/app/oracle/diag/asm/+asm/+ASM2/cdump\n+ASM1.cpu_count = 4\n+ASM2.cpu_count = 4\n+ASM1.db_cache_size = 0\n+ASM2.db_cache_size = 0\n+ASM1.db_ultra_safe = OFF\n+ASM2.db_ultra_safe = OFF\n+ASM1.db_unique_name = +ASM\n+ASM2.db_unique_name = +ASM\n+ASM1.diagnostic_dest = /u01/app/oracle\n+ASM2.diagnostic_dest = /u01/app/oracle\n+ASM1.diagnostics_control = IGNORE\n+ASM2.diagnostics_control = IGNORE\n+ASM1.event =\n+ASM2.event =\n+ASM1.file_mapping = FALSE\n+ASM2.file_mapping = FALSE\n+ASM1.filesystemio_options = none\n+ASM2.filesystemio_options = none\n+ASM1.forward_listener =\n+ASM2.forward_listener =\n+ASM1.heartbeat_batch_size = 5\n+ASM2.heartbeat_batch_size = 5\n+ASM1.ifile =\n+ASM2.ifile =\n+ASM1.instance_abort_delay_time = 0\n+ASM2.instance_abort_delay_time = 0\n+ASM1.instance_name = +ASM1\n+ASM2.instance_name = +ASM2\n+ASM1.instance_number = 1\n+ASM2.instance_number = 2\n+ASM1.instance_type = ASM\n+ASM2.instance_type = ASM\n+ASM1.large_pool_size = 16777216\n+ASM2.large_pool_size = 16777216\n+ASM1.ldap_directory_sysauth = no\n+ASM2.ldap_directory_sysauth = no\n+ASM1.listener_networks = ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (LOCAL_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr)(REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\"))\n+ASM2.listener_networks = ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (LOCAL_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr)(REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\"))\n+ASM1.local_listener =  (ADDRESS=(PROTOCOL=TCP)(HOST=10.214.209.68)(PORT=1521))\n+ASM2.local_listener =  (ADDRESS=(PROTOCOL=TCP)(HOST=10.214.209.69)(PORT=1521))\n+ASM1.lock_name_space =\n+ASM2.lock_name_space =\n+ASM1.lock_sga = FALSE\n+ASM2.lock_sga = FALSE\n+ASM1.max_dump_file_size = unlimited\n+ASM2.max_dump_file_size = unlimited\n+ASM1.memoptimize_pool_size = 0\n+ASM2.memoptimize_pool_size = 0\n+ASM1.memory_max_target = 0\n+ASM2.memory_max_target = 0\n+ASM1.memory_target = 0\n+ASM2.memory_target = 0\n+ASM1.nls_calendar =\n+ASM2.nls_calendar =\n+ASM1.nls_comp = BINARY\n+ASM2.nls_comp = BINARY\n+ASM1.nls_currency =\n+ASM2.nls_currency =\n+ASM1.nls_date_format =\n+ASM2.nls_date_format =\n+ASM1.nls_date_language =\n+ASM2.nls_date_language =\n+ASM1.nls_dual_currency =\n+ASM2.nls_dual_currency =\n+ASM1.nls_iso_currency =\n+ASM2.nls_iso_currency =\n+ASM1.nls_language = AMERICAN\n+ASM2.nls_language = AMERICAN"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nExperience and testing has shown that certain ASM initialization parameters \nshould be set at specific values. These are the best practice values set at \ndeployment time. By setting these ASM initialization parameters as \nrecommended, known problems may be avoided and performance maximized. The \nparameters are specific to the ASM instances. The impact of setting \nthese parameters is minimal. \n \n\n\nRisk:\n\nIf the ASM initialization parameters are not set as recommended, a variety of \nissues may be encountered, depending upon which initialization parameter is \nnot set as recommended, and the actual set value. \n \n\n\nAction / Repair:\n\nThis disables memory_target for the ASM instance and setting PGA_AGGREGATE_TARGET to 400M provides the ASM instance sufficient PGA memory\n \nNOTE: The proper way to implement the memory related parameters is as \nfollows. This is important as it works around an issue where memory_target \nremains set despite setting it to 0. \n \n    * alter system set pga_aggregate_target=400M sid='*' scope=spfile; \n    * alter system set memory_target=0 sid='*' scope=spfile; \n    * alter system set memory_max_target=0 sid='*' scope=spfile; \n    * alter system reset memory_max_target sid='*' scope=spfile; "}]}, {"id": "4e93338a-b2d2-4703-b677-a0b8c4edd11e", "checkCategory": "ASM", "checkID": "B5D11DE2AEA63C17E0431EC0E50AFC06", "checkType": "SQL_PARAM", "checkName": "Check for parameter memory_max_target", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "ASM parameter MEMORY_MAX_TARGET is set according to recommended value"}, "children": [{"attr": {"consoleOutput": "\n+ASM1.allow_group_access_to_sga = FALSE\n+ASM2.allow_group_access_to_sga = FALSE\n+ASM1.asm_diskgroups = RECOC1\n+ASM2.asm_diskgroups = RECOC1\n+ASM1.asm_diskstring = o/*/DATAC1_*, o/*/RECOC1_*, /dev/exadata_quorum/*\n+ASM2.asm_diskstring = o/*/DATAC1_*, o/*/RECOC1_*, /dev/exadata_quorum/*\n+ASM1.asm_power_limit = 4\n+ASM2.asm_power_limit = 4\n+ASM1.asm_preferred_read_failure_groups =\n+ASM2.asm_preferred_read_failure_groups =\n+ASM1.audit_file_dest = /u01/app/21.0.0.0/grid/rdbms/audit\n+ASM2.audit_file_dest = /u01/app/21.0.0.0/grid/rdbms/audit\n+ASM1.audit_sys_operations = TRUE\n+ASM2.audit_sys_operations = TRUE\n+ASM1.audit_syslog_level = LOCAL0.INFO\n+ASM2.audit_syslog_level = LOCAL0.INFO\n+ASM1.audit_trail = NONE\n+ASM2.audit_trail = NONE\n+ASM1.background_core_dump = partial\n+ASM2.background_core_dump = partial\n+ASM1.background_dump_dest = /u01/app/21.0.0.0/grid/rdbms/log\n+ASM2.background_dump_dest = /u01/app/21.0.0.0/grid/rdbms/log\n+ASM1.cdb_cluster = FALSE\n+ASM2.cdb_cluster = FALSE\n+ASM1.cluster_database = TRUE\n+ASM2.cluster_database = TRUE\n+ASM1.cluster_interconnects = 192.168.11.128:192.168.11.129\n+ASM2.cluster_interconnects = 192.168.11.132:192.168.11.133\n+ASM1.connection_brokers = ((TYPE=DEDICATED)(BROKERS=1)), ((TYPE=EMON)(BROKERS=1))\n+ASM2.connection_brokers = ((TYPE=DEDICATED)(BROKERS=1)), ((TYPE=EMON)(BROKERS=1))\n+ASM1.core_dump_dest = /u01/app/oracle/diag/asm/+asm/+ASM1/cdump\n+ASM2.core_dump_dest = /u01/app/oracle/diag/asm/+asm/+ASM2/cdump\n+ASM1.cpu_count = 4\n+ASM2.cpu_count = 4\n+ASM1.db_cache_size = 0\n+ASM2.db_cache_size = 0\n+ASM1.db_ultra_safe = OFF\n+ASM2.db_ultra_safe = OFF\n+ASM1.db_unique_name = +ASM\n+ASM2.db_unique_name = +ASM\n+ASM1.diagnostic_dest = /u01/app/oracle\n+ASM2.diagnostic_dest = /u01/app/oracle\n+ASM1.diagnostics_control = IGNORE\n+ASM2.diagnostics_control = IGNORE\n+ASM1.event =\n+ASM2.event =\n+ASM1.file_mapping = FALSE\n+ASM2.file_mapping = FALSE\n+ASM1.filesystemio_options = none\n+ASM2.filesystemio_options = none\n+ASM1.forward_listener =\n+ASM2.forward_listener =\n+ASM1.heartbeat_batch_size = 5\n+ASM2.heartbeat_batch_size = 5\n+ASM1.ifile =\n+ASM2.ifile =\n+ASM1.instance_abort_delay_time = 0\n+ASM2.instance_abort_delay_time = 0\n+ASM1.instance_name = +ASM1\n+ASM2.instance_name = +ASM2\n+ASM1.instance_number = 1\n+ASM2.instance_number = 2\n+ASM1.instance_type = ASM\n+ASM2.instance_type = ASM\n+ASM1.large_pool_size = 16777216\n+ASM2.large_pool_size = 16777216\n+ASM1.ldap_directory_sysauth = no\n+ASM2.ldap_directory_sysauth = no\n+ASM1.listener_networks = ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (LOCAL_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr)(REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\"))\n+ASM2.listener_networks = ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (LOCAL_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr)(REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\"))\n+ASM1.local_listener =  (ADDRESS=(PROTOCOL=TCP)(HOST=10.214.209.68)(PORT=1521))\n+ASM2.local_listener =  (ADDRESS=(PROTOCOL=TCP)(HOST=10.214.209.69)(PORT=1521))\n+ASM1.lock_name_space =\n+ASM2.lock_name_space =\n+ASM1.lock_sga = FALSE\n+ASM2.lock_sga = FALSE\n+ASM1.max_dump_file_size = unlimited\n+ASM2.max_dump_file_size = unlimited\n+ASM1.memoptimize_pool_size = 0\n+ASM2.memoptimize_pool_size = 0\n+ASM1.memory_max_target = 0\n+ASM2.memory_max_target = 0\n+ASM1.memory_target = 0\n+ASM2.memory_target = 0\n+ASM1.nls_calendar =\n+ASM2.nls_calendar =\n+ASM1.nls_comp = BINARY\n+ASM2.nls_comp = BINARY\n+ASM1.nls_currency =\n+ASM2.nls_currency =\n+ASM1.nls_date_format =\n+ASM2.nls_date_format =\n+ASM1.nls_date_language =\n+ASM2.nls_date_language =\n+ASM1.nls_dual_currency =\n+ASM2.nls_dual_currency =\n+ASM1.nls_iso_currency =\n+ASM2.nls_iso_currency =\n+ASM1.nls_language = AMERICAN\n+ASM2.nls_language = AMERICAN"}}]}, {"attr": {"target": "scaqal03adm06vm01:+ASM2", "status": "success", "statusLabel": "PASS", "output": "ASM parameter MEMORY_MAX_TARGET is set according to recommended value"}, "children": [{"attr": {"consoleOutput": "\n+ASM1.allow_group_access_to_sga = FALSE\n+ASM2.allow_group_access_to_sga = FALSE\n+ASM1.asm_diskgroups = RECOC1\n+ASM2.asm_diskgroups = RECOC1\n+ASM1.asm_diskstring = o/*/DATAC1_*, o/*/RECOC1_*, /dev/exadata_quorum/*\n+ASM2.asm_diskstring = o/*/DATAC1_*, o/*/RECOC1_*, /dev/exadata_quorum/*\n+ASM1.asm_power_limit = 4\n+ASM2.asm_power_limit = 4\n+ASM1.asm_preferred_read_failure_groups =\n+ASM2.asm_preferred_read_failure_groups =\n+ASM1.audit_file_dest = /u01/app/21.0.0.0/grid/rdbms/audit\n+ASM2.audit_file_dest = /u01/app/21.0.0.0/grid/rdbms/audit\n+ASM1.audit_sys_operations = TRUE\n+ASM2.audit_sys_operations = TRUE\n+ASM1.audit_syslog_level = LOCAL0.INFO\n+ASM2.audit_syslog_level = LOCAL0.INFO\n+ASM1.audit_trail = NONE\n+ASM2.audit_trail = NONE\n+ASM1.background_core_dump = partial\n+ASM2.background_core_dump = partial\n+ASM1.background_dump_dest = /u01/app/21.0.0.0/grid/rdbms/log\n+ASM2.background_dump_dest = /u01/app/21.0.0.0/grid/rdbms/log\n+ASM1.cdb_cluster = FALSE\n+ASM2.cdb_cluster = FALSE\n+ASM1.cluster_database = TRUE\n+ASM2.cluster_database = TRUE\n+ASM1.cluster_interconnects = 192.168.11.128:192.168.11.129\n+ASM2.cluster_interconnects = 192.168.11.132:192.168.11.133\n+ASM1.connection_brokers = ((TYPE=DEDICATED)(BROKERS=1)), ((TYPE=EMON)(BROKERS=1))\n+ASM2.connection_brokers = ((TYPE=DEDICATED)(BROKERS=1)), ((TYPE=EMON)(BROKERS=1))\n+ASM1.core_dump_dest = /u01/app/oracle/diag/asm/+asm/+ASM1/cdump\n+ASM2.core_dump_dest = /u01/app/oracle/diag/asm/+asm/+ASM2/cdump\n+ASM1.cpu_count = 4\n+ASM2.cpu_count = 4\n+ASM1.db_cache_size = 0\n+ASM2.db_cache_size = 0\n+ASM1.db_ultra_safe = OFF\n+ASM2.db_ultra_safe = OFF\n+ASM1.db_unique_name = +ASM\n+ASM2.db_unique_name = +ASM\n+ASM1.diagnostic_dest = /u01/app/oracle\n+ASM2.diagnostic_dest = /u01/app/oracle\n+ASM1.diagnostics_control = IGNORE\n+ASM2.diagnostics_control = IGNORE\n+ASM1.event =\n+ASM2.event =\n+ASM1.file_mapping = FALSE\n+ASM2.file_mapping = FALSE\n+ASM1.filesystemio_options = none\n+ASM2.filesystemio_options = none\n+ASM1.forward_listener =\n+ASM2.forward_listener =\n+ASM1.heartbeat_batch_size = 5\n+ASM2.heartbeat_batch_size = 5\n+ASM1.ifile =\n+ASM2.ifile =\n+ASM1.instance_abort_delay_time = 0\n+ASM2.instance_abort_delay_time = 0\n+ASM1.instance_name = +ASM1\n+ASM2.instance_name = +ASM2\n+ASM1.instance_number = 1\n+ASM2.instance_number = 2\n+ASM1.instance_type = ASM\n+ASM2.instance_type = ASM\n+ASM1.large_pool_size = 16777216\n+ASM2.large_pool_size = 16777216\n+ASM1.ldap_directory_sysauth = no\n+ASM2.ldap_directory_sysauth = no\n+ASM1.listener_networks = ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (LOCAL_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr)(REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\"))\n+ASM2.listener_networks = ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (LOCAL_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr)(REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.128)(PORT=1525)))\")), ((NAME=ora.ASMNET1LSNR_ASM.lsnr) (REMOTE_LISTENER=\"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.11.132)(PORT=1525)))\"))\n+ASM1.local_listener =  (ADDRESS=(PROTOCOL=TCP)(HOST=10.214.209.68)(PORT=1521))\n+ASM2.local_listener =  (ADDRESS=(PROTOCOL=TCP)(HOST=10.214.209.69)(PORT=1521))\n+ASM1.lock_name_space =\n+ASM2.lock_name_space =\n+ASM1.lock_sga = FALSE\n+ASM2.lock_sga = FALSE\n+ASM1.max_dump_file_size = unlimited\n+ASM2.max_dump_file_size = unlimited\n+ASM1.memoptimize_pool_size = 0\n+ASM2.memoptimize_pool_size = 0\n+ASM1.memory_max_target = 0\n+ASM2.memory_max_target = 0\n+ASM1.memory_target = 0\n+ASM2.memory_target = 0\n+ASM1.nls_calendar =\n+ASM2.nls_calendar =\n+ASM1.nls_comp = BINARY\n+ASM2.nls_comp = BINARY\n+ASM1.nls_currency =\n+ASM2.nls_currency =\n+ASM1.nls_date_format =\n+ASM2.nls_date_format =\n+ASM1.nls_date_language =\n+ASM2.nls_date_language =\n+ASM1.nls_dual_currency =\n+ASM2.nls_dual_currency =\n+ASM1.nls_iso_currency =\n+ASM2.nls_iso_currency =\n+ASM1.nls_language = AMERICAN\n+ASM2.nls_language = AMERICAN"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nExperience and testing has shown that certain ASM initialization parameters should be set at specific values. These are the best practice values set at deployment time. \n\nBy setting these ASM initialization parameters as recommended, known problems may be avoided and performance maximized. \n\nThe parameters are specific to the ASM instances. Unless otherwise specified, the \nvalue is for both X2-2 and X2-8 Database Machines. The impact of setting these parameters is minimal. \n\n\n\nRisk:\n\nIf the ASM initialization parameters are not set as recommended, a variety of issues may be encountered, depending upon which initialization parameter is not set as recommended, and the actual set value. \n \n\n\nAction / Repair:\n\nSetting MEMORY_MAX_TARGET to 0 disables MEMORY_MAX_TARGET for the ASM instance\n \nNOTE: The proper way to implement the memory related parameters is as follows. This is important as it works around an issue where memory_target remains set despite setting it to 0. \n \n    * alter system set pga_aggregate_target=400M sid='*' scope=spfile; \n    * alter system set memory_target=0 sid='*' scope=spfile; \n    * alter system set memory_max_target=0 sid='*' scope=spfile; \n    * alter system reset memory_max_target sid='*' scope=spfile; "}, {"id": "331872e7-6540-45db-b83a-f7639808a247", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1373255.1", "text": "Note: 1373255.1 - \t11.2.0.1/11.2.0.2 to 11.2.0.3 Database Upgrade on Exadata Database Machine"}]}]}, {"id": "95564aeb-d661-4b70-8da4-98aac478e3d0", "checkCategory": "RDBMS", "checkID": "BCE22AC1A8B1190DE0431EC0E50A453A", "checkType": "SQL", "checkName": "Invalid application objects", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "success", "statusLabel": "PASS", "output": "No application objects were found to be invalid"}, "children": [{"attr": {"consoleOutput": "\n\nQuery returned no rows which is expected when the SQL check passes."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nVerifying application code is properly compiled can prevent potential impacts to performance and to ensure that users do not encounter application errors.\n\nRisk:\n\nAlthough invalid objects are recompiled automatically on use, compiling objects prior to operation will either eliminate or minimize subsequent latencies due to on-demand automatic recompilation at runtime. Objects which are invalid due to coding errors may cause the calling applications to fail. The recommended approach to recompile objects using the utlrp.sql script will only compile invalid objects. There is no impact to valid objects which may be in use. \n\nAction / Repair:\n\nThe following script can be run to recompile invalid objects:\n\n$ORACLE_HOME/perl/bin/perl catcon.pl --n 1 --echo --log_file_base utlrp --script_dir . utlrp.sql\n\n\nReview the log file for \"OBJECTS WITH ERRORS\" and \"ERRORS DURING RECOMPILATION\". Further documentation can be found here:\n\nhttps://docs.oracle.com/en/database/oracle/oracle-database/19/ladbi/recompiling-all-invalid-objects.html\n\n\nInvalid objects can also be listed using the following SQL:\n\nSELECT owner, object_name, object_type \n  FROM dba_objects \n WHERE status != 'VALID' \n   AND owner not in ('SYS','SYSTEM') \n   AND object_name NOT LIKE 'BIN$%';\n\n\nNote: Once the issue has been resolved, if you wish to validate this Exachk check individually, run the following command as \"root\" user:\n\n    exachk -showpass -check BCE22AC1A8B1190DE0431EC0E50A453A"}, {"id": "6f63e1b2-0806-429c-b05a-9a6059d2d668", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=837570.1", "text": "Note: 837570.1 - Complete Checklist for Manual Upgrades to 11gR2"}]}]}, {"id": "6a6c5170-4be5-410c-8661-91f264db06a8", "checkCategory": "ASM HOME", "checkID": "BEEC289AF1841071E053D498EB0A498D", "checkType": "OS", "checkName": "Verify v$asm_disk os_mb and total_mb values are the same", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "v$asm_disk os_mb and total_mb values are the same"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY V$ASM_DISK OS_MB AND TOTAL_MB VALUES ARE THE SAME\n\n\n\nSUCCESS:os_mb and total_mb values matched for all disks.  Details:\nno rows selected"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nBy default on Exadata, ASM disk groups will be created with disks that are the same size as the Exadata grid disks. This simplifies overall administration and management. It also enables Exadata auto disk management to work properly.\n\nRisk:\n\nWhen the ASM disk size differs from the Exadata grid disk size, commands that add a disk to the disk group, such as those run by Exadata auto disk management, will fail. This can typically occur after a failed disk is replaced.\n\nThe most common reason for this condition to occur is when incorrect ASM disk sizes are specified on the ASM create disk group command, or if a wrong size is specified using the ASM RESIZE DISK command.\n\nAction / Repair:\n\nTo verify that all diskgroups have the same OS_MB and TOTAL_MB values, as the grid home owner userid, and with the environment set to access the ASM instance on one database server, execute the following code:\n\nUNSET DISK_SIZE_DATA\nDISK_SIZE_DATA=$($ORACLE_HOME/bin/sqlplus -s \"/ as sysdba\" &lt;&lt;EOF\nset newpage none head on lines 80 pagesize 32000 feedback on timing off serveroutput on\ncolumn group_number heading 'Group|Number'\ncolumn name heading 'Name'\ncolumn os_mb heading 'Operating|System MB'\ncolumn total_mb heading \"Total MB\"\nselect group_number,name,os_mb,total_mb\nfrom v$asm_disk_stat\nwhere os_mb != total_mb and failgroup_type='REGULAR'\norder by group_number,failgroup,name;\nexit\nEOF\n)\nif [[ $(echo $DISK_SIZE_DATA | egrep -i \"no rows selected\" | wc -l) -eq 1 ]]\nthen\n  echo -e \"SUCCESS: os_mb and total_mb values matched for all disks.  Details:\\n$DISK_SIZE_DATA\"\nelse\n  echo -e \"FAILURE: os_mb and total_mb values did not match for one or more disks.  Details:\\n$DISK_SIZE_DATA\"\nfi\n\nThe expected output should be similar to:\n\nSUCCESS: os_mb and total_mb values matched for all disks.  Details:\n\nno rows selected\n\nExample of a \"FAILURE\" result:\n\nFAILURE: os_mb and total_mb values did not match for one or more disks.  Details:\n     Group                                 Operating\n    Number Name                            System MB   Total MB\n---------- ------------------------------ ---------- ----------\n         2 RECOC1_FD_00_RANDOM05CELADM10     1161664    1160656\n         2 RECOC1_FD_01_RANDOM05CELADM10     1161664    1160656\n         2 RECOC1_FD_02_RANDOM05CELADM10     1161664    1160656\n&lt;example data truncated for brevity&gt;\n         2 RECOC1_FD_04_RANDOM05CELADM14     1161664    1160656\n         2 RECOC1_FD_05_RANDOM05CELADM14     1161664    1160656\n         2 RECOC1_FD_06_RANDOM05CELADM14     1161664    1160656\n         2 RECOC1_FD_07_RANDOM05CELADM14     1161664    1160656\n\n40 rows selected.\n\nIf a result other than \"SUCCESS:\" is returned, identify the reason for having a different value and take corrective action."}]}, {"id": "6ebab4a0-7a4f-4b83-90dc-38237b2e3b53", "checkCategory": "RDBMS", "checkID": "BEF432FA40EC35BDE053D198EB0A82C0", "checkType": "OS", "checkName": "Identify CON$.CON# reaching maximum limit", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "CON$.CON# is within maximum limit"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Identify CON$.CON# reaching maximum limit\n\n\n\n\n\nPDB 1 :PASS:con# max value:6933 is within threshold value:4284967293.\n\nPDB 3 :PASS:con# max value:6867 is within threshold value:4284967293.\nNote:Top gaps in con#:\n\nPDB_ID\tCON_PRV#\tCON_NXT#"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nIf con$.con# reaches the maximum limit of 4294967293 then ORA-600 [12807] would be encountered.\n\nRisk:\n\nPotential Database Outage.\n\nAction / Repair:\n\nFor the con$.con# reaching maximum limit of 4294967293, patch 25343563 would need to be applied which provides a mechanism to reuse the con# which are unused in the system due to fragmentation.\n\nIf 25343563 is already applied, please ensure that you have enough gaps in con$ for con#."}, {"id": "a1326d45-ad37-4eb4-a527-309d18dc8969", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=13781691.8", "text": "Note: 13781691.8 - Bug 13781691 - ORA-600 [12807] if CON$.CON# very high due to bug 13784384 (Doc ID 13781691.8)"}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=2660231.1", "text": "Note: 2660231.1 -  Internal Database Limits on Number of Objects, Constraints, and Users (Doc ID 2660231.1)"}]}]}, {"id": "0007be97-932a-4fec-9274-4924023cb0f3", "checkCategory": "RDBMS", "checkID": "BEF432FA40F135BDE053D198EB0A82C0", "checkType": "OS", "checkName": "Identify OBJ$.OBJ# reaching maximum limit", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "OBJ$.OBJ# is within maximum limit"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Identify OBJ$.OBJ# reaching maximum limit\n\n\n\n\n\nPDB 1 :PASS:obj# max value:368634 is within threshold value:4284967293.\n\nPDB 3 :PASS:obj# max value:75097 is within threshold value:4284967293.\nNote:Top gaps in obj#:\n\nPDB_ID\tOBJ_PRV#\tOBJ_NXT#\n\n1     132563\t  133646\n3\t26470\t   27647"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nIf obj$.obj# reaches the maximum limit of 4294967293 then ORA-600 [kkdlron-max-objid] would be encountered.\n\n\nRisk:\n\nPotential Database Outage.\n\nAction / Repair:\n\nWhen OBJ$.OBJ# reaches maximum limit of 4294967293, Database will no longer be usable. The only available solution would be to rebuild the database before reaching the limit. If limit has already reached, customer need to apply patch for bug 20529650 and rebuild the database immediately.\n\nNote: Bug 20529650 is not a fix. It only provides an extra headroom for rebuilding the database by providing additional 39 million object numbers. Customers will need to use this window to rebuild their database immediately. \n\nCustomer is also advised to change the application to prevent consuming the object numbers at a high rate. "}, {"id": "734b9c78-c25b-4557-8769-938b74fa50e9", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=20529650.8", "text": "Note: 20529650.8 - Bug 20529650 - ORA-600 [kkdlron-max-objid], [4254950911] (Doc ID 20529650.8)"}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=2660231.1", "text": "Note: 2660231.1 -  Internal Database Limits on Number of Objects, Constraints, and Users (Doc ID 2660231.1)"}]}]}, {"id": "8d59e71a-a4a3-4e3b-987b-ce57ad55b994", "checkCategory": "RDBMS", "checkID": "BF7AE780E1252F69E0431EC0E50AE447", "checkType": "OS", "checkName": "High Redundancy Controlfile", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Database control files are configured as recommended"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - High Redundancy Controlfile\n\n\n\nControl files = +DATAC1/CDB1/CONTROLFILE/current.259.1123543513\n\nHigh redundancy diskgroups = 2\n\nHigh redundancy diskgroups where control files are multiplexed = 1\n\nNormal redundancy diskgroups where control files are multiplexed = 0\n\nFlash Recovery Area disk group Name = +RECOC1\n\nData Guard in-use = 0\n\nRMAN control file auto backup = 1"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Database control files are configured as recommended"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - High Redundancy Controlfile\n\n\n\nControl files = +DATAC1/CDB1/CONTROLFILE/current.259.1123543513\n\nHigh redundancy diskgroups = 2\n\nHigh redundancy diskgroups where control files are multiplexed = 1\n\nNormal redundancy diskgroups where control files are multiplexed = 0\n\nFlash Recovery Area disk group Name = +RECOC1\n\nData Guard in-use = 0\n\nRMAN control file auto backup = 1"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThe control file is a critical database file that stores metadata for a given database.  When a control file becomes unavailable, the database instance fails.  Control files are also essential for database and instance recovery.\nProper control file configuration helps to reduce database outages, improve performance, and shorten database or instance recovery time.\n\nThe impact of verifying the database control file configuration is minimal.  The impact of changing the control file configuration varies based on specific circumstances and cannot be estimated here.\n\nRisk:\n\nIf the database initialization parameters are not set as recommended, a variety of issues may be encountered, depending upon which initialization parameter is not set as recommended, and the actual set value. \n\n\nAction / Repair:\n\nOracle recommends that the control files be configured (via the control_files database initialization parameter) as shown:\n\nEither DATA or RECO alone are high redundancy:\n\n    one controlfile in DATA - PASS\n    one controlfile in RECO - PASS\n\n    NOTE: Following the above recommendation maintains High Availability while reducing the overall number of control file writes.\n\nboth DATA and RECO are high redundancy:\n\n    one controlfile in DATA - PASS\n    one controlfile in RECO - WARN\n\n    NOTE: It is preferred the control file be in DATA with all of the other database files.\n\n    one controlfile in both DATA and RECO - WARN\n    both controlfile in both DATA - WARN\n    both controlfile in both RECO - WARN\n\n    NOTE: The above recommendation results in more control file writes than are necessary.\n\nonly normal redundancy disk groups exist, both DATA and RECO:\n\n    one controlfile in DATA with Data Guard in use - WARN\n\n    NOTE: The above recommendation is high impact because if the control file is lost, a complete fail over to the standby is required!\n\n    one controlfile in DATA with current backup controlfile in RECO diskgroup - WARN\n\n    NOTE: Regardless of the specific control file configuration, it is recommended that rman contolfile autobackup always be on. For additional information and specific evaluation see the \"Verify rman controlfile autobackup is set to ON\" section in the MAA Scorecard.\n\nANY OTHER CONTROLFILE CONFIGURATION - FAIL"}]}, {"id": "3185a7ad-dde0-41bd-b0ef-430b3b55c4c2", "checkCategory": "HOST", "checkID": "CE59464AC43480C4E053D198EB0AC2C0", "checkType": "OS", "checkName": "Verify filesystems housing Grid Infrastructure home does not have \"nosuid\" mount option set", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Filesystem housing Grid Infrastructure home is not mounted with 'nosuid' option."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY FILESYSTEMS HOUSING GRID INFRASTRUCTURE HOME DOES NOT HAVE \"NOSUID\" MOUNT OPTION SET\n\n\n\nSUCCESS:Filesystem housing oracle home /u01/app/21.0.0.0/grid is not mounted with 'nosuid' option.\n/etc/mtab entry:/dev/mapper/VGExaDbDisk.grid21.7.0.0.220719.img-LVDBDisk /u01/app/21.0.0.0/grid xfs rw,relatime,attr2,inode64,noquota 0 0"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Filesystem housing Grid Infrastructure home is not mounted with 'nosuid' option."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - VERIFY FILESYSTEMS HOUSING GRID INFRASTRUCTURE HOME DOES NOT HAVE \"NOSUID\" MOUNT OPTION SET\n\n\n\nSUCCESS:Filesystem housing oracle home /u01/app/21.0.0.0/grid is not mounted with 'nosuid' option.\n/etc/mtab entry:/dev/mapper/VGExaDbDisk.grid21.7.0.0.220719.img-LVDBDisk /u01/app/21.0.0.0/grid xfs rw,relatime,attr2,inode64,noquota 0 0"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nAll filesystems housing oracle homes will be checked to make sure 'nosuid' mount option is not present. If filesystems containing DB oracle homes are mounted with the 'nosuid' option then 'oradism' executable is unable to elevate the priority of critical processes like LMS and VKTM. If the LMS process is not running at the proper scheduling priority it can lead to instance evictions due to IPC send timeouts at times of high CPU utilization. Using Oracle 19c and higher, if 'oradism' is unable to elevate the priority of critical background processes there could be ORA-00800 [SET PRIORITY FAILED] error.\n\nThe 'oradism' executable is invoked after database startup and must be allowed to change the scheduling priority of LMS and other database background processes to the realtime scheduling class in order to maximize the ability of these key processes to be scheduled on the CPU in a timely way at times of high CPU utilization.\n\nIf GI oracle home is mounted with 'nosuid' option there could be errors in mounting ACFS filesystem and other unexpected issues.\n\nRisk:\n\nSoftware instability and unexpected behavior.\n\nAction / Repair:\n\nExample output returned by the check for success scenario:\n\nSUCCESS: Filesystem housing oracle home ($ORACLE_HOME) is not mounted with 'nosuid' option.\n\nExample output returned by the check for failure scenario:\n\nFAILURE: Following filesystem housing oracle home $(ORACLE_HOME) is mounted with 'nosuid' option. Remove the 'nosuid' option (ex: from /etc/fstab) and remount: Filesystem /dev/mapper/VGExaDb-LVDbOra1 mounted on /u01\nIf any FAILURE is reported, then investigate and remove the 'nosuid' mount option from the filesystems and remount.\n\n\nNote: Error ORA-00800 [SET PRIORITY FAILED] can occur for other reasons. Please review MOS documents in links section for more information."}, {"id": "62884514-3898-4a1b-9123-a4d026df84e3", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=2551359.1", "text": "Note: 2551359.1 - ORA-00800: Soft External Error, Arguments: [Set Priority Failed], [VKTM] [Check traces and OS configuration]"}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=2718971.1", "text": "Note: 2718971.1 - ORA-00800: soft external error, arguments: [Set Priority Failed], [VKTM], for Oracle Linux (Doc ID 2718971.1)"}]}]}, {"id": "c01d8e9b-63b0-45e3-b92f-9f6e0bd2f804", "checkCategory": "HOST", "checkID": "CE5B9D2D186D95AEE053D298EB0A1820", "checkType": "OS", "checkName": "Verify filesystems housing oracle homes do not have \"nosuid\" mount option set", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:/u01/app/oracle/product/21.0.0.0/dbhome_1", "status": "success", "statusLabel": "PASS", "output": "Filesystem housing oracle home is not mounted with 'nosuid' option."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - /u01/app/oracle/product/21.0.0.0/dbhome_1 DATABASE_HOME - Verify filesystems housing oracle homes do not have \"nosuid\" mount option set\n\n\n\nSUCCESS:Filesystem housing oracle home /u01/app/oracle/product/21.0.0.0/dbhome_1 is not mounted with 'nosuid' option.\n/etc/mtab entry:/dev/mapper/VGExaDbDisk.db21.7.0.0.220719_3.img-LVDBDisk /u01/app/oracle/product/21.0.0.0/dbhome_1 xfs rw,relatime,attr2,inode64,noquota 0 0"}}]}, {"attr": {"target": "scaqal03adm06vm01:/u01/app/oracle/product/21.0.0.0/dbhome_1", "status": "success", "statusLabel": "PASS", "output": "Filesystem housing oracle home is not mounted with 'nosuid' option."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - /u01/app/oracle/product/21.0.0.0/dbhome_1 DATABASE_HOME - Verify filesystems housing oracle homes do not have \"nosuid\" mount option set\n\n\n\nSUCCESS:Filesystem housing oracle home /u01/app/oracle/product/21.0.0.0/dbhome_1 is not mounted with 'nosuid' option.\n/etc/mtab entry:/dev/mapper/VGExaDbDisk.db21.7.0.0.220719_3.img-LVDBDisk /u01/app/oracle/product/21.0.0.0/dbhome_1 xfs rw,relatime,attr2,inode64,noquota 0 0"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nAll filesystems housing oracle homes will be checked to make sure 'nosuid' mount option is not present. If filesystems containing DB oracle homes are mounted with the 'nosuid' option then 'oradism' executable is unable to elevate the priority of critical processes like LMS and VKTM. If the LMS process is not running at the proper scheduling priority it can lead to instance evictions due to IPC send timeouts at times of high CPU utilization. Using Oracle 19c and higher, if 'oradism' is unable to elevate the priority of critical background processes there could be ORA-00800 [SET PRIORITY FAILED] error.\n\nThe 'oradism' executable is invoked after database startup and must be allowed to change the scheduling priority of LMS and other database background processes to the realtime scheduling class in order to maximize the ability of these key processes to be scheduled on the CPU in a timely way at times of high CPU utilization.\n\nIf GI oracle home is mounted with 'nosuid' option there could be errors in mounting ACFS filesystem and other unexpected issues.\n\nRisk:\n\nSoftware instability and unexpected behavior.\n\nAction / Repair:\n\nExample output returned by the check for success scenario:\n\nSUCCESS: Filesystem housing oracle home ($ORACLE_HOME) is not mounted with 'nosuid' option.\n\nExample output returned by the check for failure scenario:\n\nFAILURE: Following filesystem housing oracle home $(ORACLE_HOME) is mounted with 'nosuid' option. Remove the 'nosuid' option (ex: from /etc/fstab) and remount: Filesystem /dev/mapper/VGExaDb-LVDbOra1 mounted on /u01\nIf any FAILURE is reported, then investigate and remove the 'nosuid' mount option from the filesystems and remount.\n\nNote: Error ORA-00800 [SET PRIORITY FAILED] can occur for other reasons. Please review MOS documents in links section for more information."}, {"id": "10402179-c134-4903-91a4-20022c6e0dd4", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=2551359.1", "text": "Note: 2551359.1 - ORA-00800: Soft External Error, Arguments: [Set Priority Failed], [VKTM] [Check traces and OS configuration]"}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=2718971.1", "text": "Note: 2718971.1 - ORA-00800: soft external error, arguments: [Set Priority Failed], [VKTM], for Oracle Linux (Doc ID 2718971.1)"}]}]}, {"id": "930ebfad-0bef-4546-87b4-3a9ce19c2c38", "checkCategory": "RDBMS", "checkID": "D32050FDBDF41815E053D398EB0A6DFC", "checkType": "SQL", "checkName": "Verify no PDB plugin violations are reported", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "success", "statusLabel": "PASS", "output": "There are no incompatibilities between PDB(s) and the CDB"}, "children": [{"attr": {"consoleOutput": "\n\nQuery returned no rows which is expected when the SQL check passes."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nPDBs that are plugged into CDB will run optimally if there are no incompatibilities.\n\nRisk:\n\nAny incompatibilities need to be reviewed and resolved for optimal runtime of tenants.\n\nAction / Repair:\n\nPlease review the check's output. If you see query returned no rows then its a PASS. Otherwise, please review the violations reported and their date/time. Refer to the MOS notes listed in this audit check and take necessary action. If you notice a different issue than what's in these notes, please engage Oracle Support for assistance.\n\nPlease note, this audit check may also be invoked individually as root user:\n\n# exachk -check D32050FDBDF41815E053D398EB0A6DFC\n"}, {"id": "f128696f-9b84-4d2f-83f6-364c5139f324", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=1935365.1", "text": "Note: 1935365.1 - Multitenant Unplug/Plug Best Practices (Doc ID 1935365.1)"}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=2288129.1", "text": "Note: 2288129.1 - Known Issues With PDB_PLUG_IN_VIOLATIONS (Doc ID 2288129.1)"}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=31387426.8", "text": "Note: 31387426.8 - Bug 31387426 - DBMS_PDB.CLEAR_PLUGIN_VIOLATIONS() should allow clearing of pending violations for named PDB"}]}]}, {"id": "a63b4e49-d98e-4288-8f60-f6ccd3dfeb7d", "checkCategory": "ASM", "checkID": "D45FD167691E265FE0431EC0E50A4C68", "checkType": "OS", "checkName": "Verify no ASM external redundancy diskgroups exist", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "There are no ASM external redundancy diskgroups."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY NO ASM EXTERNAL REDUNDANCY DISKGROUPS EXIST\n\n\n\nThere were no ASM diskgroups with redundancy other than HIGH or NORMAL"}}]}, {"attr": {"target": "scaqal03adm06vm01:+ASM2", "status": "success", "statusLabel": "PASS", "output": "There are no ASM external redundancy diskgroups."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - VERIFY NO ASM EXTERNAL REDUNDANCY DISKGROUPS EXIST\n\n\n\nThere were no ASM diskgroups with redundancy other than HIGH or NORMAL"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nASM redundancy prevents data loss.\n\n\n\nRisk:\n\nUnprotected ASM templates and/or external redundancy diskgroups can cause\ndata loss.\n\n\n\nAction / Repair:\n\nTo check the redundancy of mounted ASM diskgroups, use the following SQL\nstatement in the ASM instance. The result should be HIGH or NORMAL.\nSQL&gt; select distinct type from v$asm_diskgroup_stat;\nTYPE\n------\nHIGH\nIf ASM external redundancy diskgroups exist, investigate and correct the\ncondition."}]}, {"id": "88452a6a-b060-48a3-96c7-e45e491b61b7", "checkCategory": "ASM", "checkID": "D461326889EE4A3DE0431EC0E50ABE4A", "checkType": "OS", "checkName": "Verify no ASM unprotected templates exist", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "There are no ASM unprotected templates."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY NO ASM UNPROTECTED TEMPLATES EXIST\n\n\n\nThere were no ASM templates with redundancy other than HIGH or MIRROR"}}]}, {"attr": {"target": "scaqal03adm06vm01:+ASM2", "status": "success", "statusLabel": "PASS", "output": "There are no ASM unprotected templates."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - VERIFY NO ASM UNPROTECTED TEMPLATES EXIST\n\n\n\nThere were no ASM templates with redundancy other than HIGH or MIRROR"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nASM redundancy prevents data loss\n\n\nRisk:\n\nUnprotected ASM templates and/or external redundancy diskgroups can cause data loss.\n\n\n\nAction / Repair:\n\nTo check the types of ASM templates in use, use the following SQL statement in the ASM instance. The result should be HIGH or MIRROR.\n\nSQL&gt; select distinct redundancy from v$asm_template;\n\nREDUND\n------\nHIGH\n\nTo check the redundancy of mounted ASM diskgroups, use the following SQL statement in the ASM instance. The result should be HIGH or NORMAL\n\nSQL&gt; select distinct type from v$asm_diskgroup_stat;\n\nTYPE\n------\nHIGH\n\nIf either ASM unprotected templates or external redundancy diskgroups exist, investigate and correct the condition. "}]}, {"id": "3fc4ac9f-b0cc-4dba-8fa5-dd0f18ccf7ac", "checkCategory": "HOST", "checkID": "D812D32D8AF28D71E053D298EB0A2451", "checkType": "OS_OUT_CHECK", "checkName": "Verify config parameter vm.nr_hugepages value is same or less in initramfs [Database Server]", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "vm.nr_hugepages parameter value in initramfs config file matches or is less than value in system config file"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR VERIFY SYSCTL.CONF PARAMETER VM.NR_HUGEPAGES VALUE IS SAME OR LESS IN INITRAMFS [DATABASE SERVER]\n\n\n\nSUCCESS:vm.nr_hugepages parameter does not exist in initramfs image file. Comparison not needed.\n\nDETAILS:\nsystem sysctl config vm.nr_hugepages    :60959\ninitramfs sysctl config vm.nr_hugepages :hugepages not configured in initramfs config file"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "vm.nr_hugepages parameter value in initramfs config file matches or is less than value in system config file"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR VERIFY SYSCTL.CONF PARAMETER VM.NR_HUGEPAGES VALUE IS SAME OR LESS IN INITRAMFS [DATABASE SERVER]\n\n\n\nSUCCESS:vm.nr_hugepages parameter does not exist in initramfs image file. Comparison not needed.\n\nDETAILS:\nsystem sysctl config vm.nr_hugepages    :60959\ninitramfs sysctl config vm.nr_hugepages :hugepages not configured in initramfs config file"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nIf a database server memory is reduced, then you must first review and adjust the SGA size of the existing databases and operating system hugepages configuration accordingly. Hugepages configuration is controlled by the parameter \"vm.nr_hugepages\" in sysctl configuration file. This parameter could also be set in configuration file inside the /boot/initramfs-$(uname -r).img file which is used during the initial boot process. If the \"vm.nr_hugepages\" parameter exists in the config file inside initramfs image file then it is important that this parameter value is same or less than the value in the system config file.\n\nRisk:\n\nIf the hugepages parameter exists in the initramfs config file and its value is set to a stale or incorrect higher value, then the database server may fail to restart and display OOM kill errors.\n\nAction / Repair:\n\nThe expected output if parameter value is equal or lower is below:\n\nSUCCESS: vm.nr_hugepages parameter exists inside initramfs config file and value [nnnn] matches with /etc/sysctl.conf.\nor\nSUCCESS: vm.nr_hugepages parameter exists inside initramfs config file and its value [nnn] is less than the value [nnnn] in the system config file.\nor\nSUCCESS: vm.nr_hugepages parameter does not exist in initramfs image file. Comparison not needed.\n\nIf parameter value is higher in initramfs then the output from the script would be:\n\nCRITICAL: vm.nr_hugepages parameter value [nnnnn] in initramfs config file is higher than the value [nnnn] in the system config file.\n\n\nIf the initramfs parameter value is found to be higher, then use the below \"dracut\" command as \"root\" user to sync the initramfs image file. \n\n# cp /boot/initramfs-$(uname -r).img &lt;backup_directory&gt;/initramfs-$(uname -r).img.bak\n# dracut --force \n\nNote: Force option will overwrite the existing initramfs image file. \n\nRun the check script again to validate the values.\n\n"}]}, {"id": "83479b71-a32c-43af-941f-1eec8e8edad4", "checkCategory": "ASM", "checkID": "D957C871B811597AE04312C0E50A91BF", "checkType": "OS", "checkName": "Disks without Disk Group", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "No disks found which are not part of any disk group"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - DISKS WITHOUT DISK GROUP\n\n\n\nno rows selected"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "The GROUP_NUMBER and DISK_NUMBER columns in GV$ASM_DISK will only be valid if the disk is part of a disk group which is currently mounted by the instance. Otherwise, GROUP_NUMBER will be 0, and DISK_NUMBER will be a unique value with respect to the other disks that also have a group number of 0. Run following query to find out the disks which are not part of any disk group.\n\nselect name,path,HEADER_STATUS,GROUP_NUMBER  from gv$asm_disk where group_number=0;"}]}, {"id": "e042687b-f696-40c4-b526-b18f1dff3931", "checkCategory": "SYSTEM", "checkID": "DCAC61E06536FEDAE053D298EB0A9812", "checkType": "OS", "checkName": "Verify that packages exadata-sun-computenode-minimum and exadata-sun-computenode are installed", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Packages exadata-sun-computenode-minimum and exadata-sun-computenode are installed"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY THAT PACKAGES EXADATA-SUN-COMPUTENODE-MINIMUM AND EXADATA-SUN-COMPUTENODE ARE INSTALLED\n\n\n\nPASS:Packages exadata-sun-computenode-minimum and exadata-sun-computenode are installed.\nDETAILS:\nOutput for command \"rpm -qa | grep -- '-sun-'\":\nexadata-sun-kvm-computenode-minimum-22.1.6.0.0.221207-1.noarch\nexadata-sun-kvm-computenode-exact-22.1.6.0.0.221207-1.noarch\nexadata-sun-kvm-computenode-22.1.6.0.0.221207-1.noarch"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Packages exadata-sun-computenode-minimum and exadata-sun-computenode are installed"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - VERIFY THAT PACKAGES EXADATA-SUN-COMPUTENODE-MINIMUM AND EXADATA-SUN-COMPUTENODE ARE INSTALLED\n\n\n\nPASS:Packages exadata-sun-computenode-minimum and exadata-sun-computenode are installed.\nDETAILS:\nOutput for command \"rpm -qa | grep -- '-sun-'\":\nexadata-sun-kvm-computenode-minimum-22.1.6.0.0.221207-1.noarch\nexadata-sun-kvm-computenode-exact-22.1.6.0.0.221207-1.noarch\nexadata-sun-kvm-computenode-22.1.6.0.0.221207-1.noarch"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nPackages exadata-sun-computenode-minimum and exadata-sun-computenode must be installed.\n\nNote:\nOn systems where the last update was an Exadata Live Update, it is expected that the exadata-sun-computenode* packages are not present. If a traditional software update is subsequently performed (not an Exadata Live Update), the exadata-sun-computenode* packages will be present again.\n\nRisk:\n\nUnpredicted behavior.\n\nAction / Repair:\n\nEnsure that packages exadata-sun-computenode-minimum and exadata-sun-computenode are installed on systems where the last update was not an Exadata Live Update.\n\nNote: If after corrective actions are completed, you wish to run just this review manually without a full Exachk run, as the \"root\" userid execute the following Exachk command:\n\n    exachk -showpass -check DCAC61E06536FEDAE053D298EB0A9812\n"}, {"id": "8b6699f8-f08a-40d8-8bb1-432dd16a931a", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=2676839.1", "text": "Note: 2676839.1 - Engineered Systems - Package exadata-sun-computenode-minimum Is Missing (Doc ID 2676839.1)"}]}]}, {"id": "8261759b-deda-4539-9564-dfbdf1a537c0", "checkCategory": "ASM", "checkID": "DCDAA687991C74C1E04312C0E50AB672", "checkType": "OS", "checkName": "Verify no ASM corruption is reported", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "There was no ASM corruption found."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY NO ASM CORRUPTION IS REPORTED\n\n"}}]}, {"attr": {"target": "scaqal03adm06vm01:+ASM2", "status": "success", "statusLabel": "PASS", "output": "There was no ASM corruption found."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - VERIFY NO ASM CORRUPTION IS REPORTED\n\n"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nVerifying that ASM is not reporting corruption helps to avoid outages. If corruption is found, this proactive notification enables customers to perform root cause analysis and repair the issue before the corruption is encountered in their application.\n\n\n\nRisk:\n\nApplication exposure to data corruption.\n\n\n\nAction / Repair:\n\nIf an ASM rebalance or resync encounters an I/O error on the last mirror copy, ASM writes a well known string to the least number of blocks to avoid a diskgroup dismount. ASM provides notification on this event via it's alert log, but sometimes this notification can be missed.\n\nTo verify that no ASM corruption has occurred, execute the following command as the \"grid infrastructure owner\" userid with the environment properly set for the target ASM instance, on each database server:\n\nalert_dest=$(echo -e \"set heading off feedback off timing off lines 180\\n select value from v$parameter where name='background_dump_dest';\"|$ORACLE_HOME/bin/sqlplus -s / as sysdba|grep -v ^$|tail -1);\nalert_name=$(find $alert_dest -name 'alert_*.log' 2&gt;/dev/null);\nif [ `grep -iw \"with BADFDATA\" $alert_name | wc -l` -ne \"0\" ]\nthen\necho -e \"The following ASM alert logs were found to contain the string \"with BADFDATA\":\\n\"\necho -e `grep -iw \"with BADFDATA\" $alert_name`\nelse\necho \"No ASM alert logs were found to contain the string \"with BADFDATA\".\"\nfi\n\nThe expected result is:\n\nNo ASM alert logs were found to contain the string \"with BADFDATA\".\n\nIf the output is similar to:\n\nThe following ASM alert logs were found to contain the string \"with BADFDATA\":\n\n/u01/app/grid/diag/asm/+asm/+ASM1/trace/alert_dummyfile.log:with BADFDATA\n\nThen a corruption has occurred. It is extremely important to identify the root cause and proactively deal with the corruption. For example, if it is an index block, the index can be recreated when convenient. \n\nNOTE: There is no automatic correction of this condition. RCA MUST be conducted and the issue manually addressed. \n\nNOTE: Exachk has no way to determine during an Exachk run if an issue uncovered in a sequence of alert logs has been corrected, because it has no way to determine what the root cause was, what the root cause specific correction should have been, whether or not the customer's application has accessed the involved blocks again, etc, etc.\n\nCustomers should not follow the published guidelines for skipping this check, because then a future occurrence would be missed.\n\nAfter you have cleared the condition, and you know the database is clean, if you do not want to fail this check again for previously detected and corrected occurrences, the following actions are recommended:\n\nFor alert log files that are not the current active alert log\n1) gzip the file in which the error was reported, after it has been confirmed that all the detected corruption has been corrected.  The detection command used will not search the gzip file.\n\nFor the current active alert log\n1) Correct all detected corruptions\n2) execute the manual commands to check for new detected corruption.  If reported, correct.\n3) repeat 2) until no new corruptions reported.\n4) gzip the current active log.  ASM will create a new one as soon as it needs to write to the alert log.  The detection command used will not search the gzip file."}]}, {"id": "3ff26bad-96cf-45a9-8bd8-1b6d43d05bf9", "checkCategory": "ASM", "checkID": "E0B03D017A2D4A2BE053D198EB0ADAE3", "checkType": "OS", "checkName": "Check the integrity of key GI startup files", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "The integrity check of key GI startup files succeeded"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - CHECK THE INTEGRITY OF KEY GI STARTUP FILES\n\n\n\nOCR & OLR backup and integrity check:\n\nSUCCESS:OCR backup is taken within the expected timeframe.\nSUCCESS:OLR backup is taken within the expected timeframe.\nSUCCESS:No OCR corruption detected.\nSUCCESS:No OLR corruption detected.\n\n\nDETAILS:\n1) Oracle Cluster Registry (OCR):CRS-40002:No activities match the query.\nLast OCR backups:\n\nscaqal03adm05vm01     2024/08/29 16:26:38     +RECOC1:/scaqal03050601/OCRBACKUP/backup00.ocr.259.1178295995     260588894\n\nscaqal03adm05vm01     2024/08/29 12:26:34     +RECOC1:/scaqal03050601/OCRBACKUP/backup01.ocr.280.1178281591     260588894\n\nscaqal03adm05vm01     2024/08/29 08:26:30     +RECOC1:/scaqal03050601/OCRBACKUP/backup02.ocr.267.1178267187     260588894\n\nscaqal03adm05vm01     2024/08/28 12:26:10     +RECOC1:/scaqal03050601/OCRBACKUP/day.ocr.268.1178195171     260588894\n\nscaqal03adm05vm01     2024/08/16 08:21:44     +RECOC1:/scaqal03050601/OCRBACKUP/week.ocr.270.1177143705     260588894\n\n\n2) Oracle Local Registry (OLR):CRS-40002:No activities match the query.\nLast OLR backups:\n\nscaqal03adm05vm01     2024/08/29 01:27:14     /u01/app/oracle/crsdata/scaqal03adm05vm01/olr/autobackup_20240829_012714.olr     260588894\n\nscaqal03adm05vm01     2024/08/28 01:27:13     /u01/app/oracle/crsdata/scaqal03adm05vm01/olr/autobackup_20240828_012713.olr     260588894\n\n\n\nCredentials check:\n\nSUCCESS:ASM Credentials are set correctly.\n\n\nDETAILS:\ncredverify:Credentials created correctly on scaqal03adm05vm01.us.oracle.com."}}]}, {"attr": {"target": "scaqal03adm06vm01:+ASM2", "status": "success", "statusLabel": "PASS", "output": "The integrity check of key GI startup files succeeded"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - CHECK THE INTEGRITY OF KEY GI STARTUP FILES\n\n\n\nOCR & OLR backup and integrity check:\n\nSUCCESS:OCR backup is taken within the expected timeframe.\nSUCCESS:OLR backup is taken within the expected timeframe.\nSUCCESS:No OCR corruption detected.\nSUCCESS:No OLR corruption detected.\n\n\nDETAILS:\n1) Oracle Cluster Registry (OCR):CRS-40002:No activities match the query.\nLast OCR backups:\n\nscaqal03adm05vm01     2024/08/29 16:26:38     +RECOC1:/scaqal03050601/OCRBACKUP/backup00.ocr.259.1178295995     260588894\n\nscaqal03adm05vm01     2024/08/29 12:26:34     +RECOC1:/scaqal03050601/OCRBACKUP/backup01.ocr.280.1178281591     260588894\n\nscaqal03adm05vm01     2024/08/29 08:26:30     +RECOC1:/scaqal03050601/OCRBACKUP/backup02.ocr.267.1178267187     260588894\n\nscaqal03adm05vm01     2024/08/28 12:26:10     +RECOC1:/scaqal03050601/OCRBACKUP/day.ocr.268.1178195171     260588894\n\nscaqal03adm05vm01     2024/08/16 08:21:44     +RECOC1:/scaqal03050601/OCRBACKUP/week.ocr.270.1177143705     260588894\n\n\n2) Oracle Local Registry (OLR):CRS-40002:No activities match the query.\nLast OLR backups:\n\nscaqal03adm06vm01     2024/08/29 12:05:09     /u01/app/oracle/crsdata/scaqal03adm06vm01/olr/autobackup_20240829_120509.olr     260588894\n\nscaqal03adm06vm01     2024/08/28 12:05:08     /u01/app/oracle/crsdata/scaqal03adm06vm01/olr/autobackup_20240828_120508.olr     260588894\n\n\n\nCredentials check:\n\nSUCCESS:ASM Credentials are set correctly.\n\n\nDETAILS:\ncredverify:Credentials created correctly on scaqal03adm06vm01.us.oracle.com."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nIntegrity of key GI startup files is important for normal operations and for a clean startup of GI components. OCR and OLR are critical GI files and this check will validate that there are no corruption related errors for these files. This check will also validate that ASM credentials have been created properly across a multi-node cluster, and are consistent across the OCR, OLR, and password files.\n\nCRS takes a backup of OCR every 4 hours and a backup of OLR is performed once in 24 hours. Backup process checks the integrity of these files and makes sure that there are no corruptions and if there are any corruption related errors backup will not succeed. Existence of a current backup implies that there is no corruption in OCR and OLR at the time of the backup. We need to check if a successful backup was taken for these files in the specified timeframe and then check for any corruption related errors after the last backup to make sure the integrity of OCR and OLR is intact. OCR is global and if any corruption related errors are found, the errors will be displayed under each node in the report.\n\nThe asmcmd \"credverify\" checks to see if credentials have been created properly across a multinode cluster, and are consistent across the OCR, OLR, and password file. The asmcmd \"credfix\" also does the same, but the command additionally deletes inconsistent credentials and adds new ones across the OCR, OLR, and password file. It also enables flex ASM if the GPnP profile has not been changed yet.\n\nStarting with GI 19.8 RU, you can use \"asmcmd credverify\" and \"asmcmd credfix\" to verify and fix the asm credential issue.\n\nRisk:\n\nIf there is any corruption in the OCR and OLR files, normal GI operations would be impacted and a restart of GI stack will most likely fail.\n\nIf there are invalid or missing ASM credentials across key GI files, it would result in ORA-01017: invalid username/password; logon denied errors.\n\nAction / Repair:\n\nFollow the below steps to correct the OCR or OLR corruption:\nOption 1: Restore consistent backup of OCR. Backup must be from before the change that introduced the corruption.\nSee steps in note, How to Restore ASM Based OCR when OCR backup is located in ASM diskgroup? (Doc ID 2569847.1)\nOption 2: If OCR backup is not available, then rebuild OCR.\nSee steps in  How to Deconfigure/Reconfigure(Rebuild OCR) or Deinstall Grid Infrastructure (Doc ID 1377349.1)\n\nIf the following message is reported\n    Oracle Cluster Registry (OCR): CRS-40021: The cluster activity log operation failed. Detailed error: 'ORA-28002: the password will expire within 1 days'\nand the GIMR (MGNTDB) is running on that system please run this command to fix the issue:\n    mgmtca configRepos setpasswd -user calog\nor\n    mgmtca configRepos setpasswd -allusers\n\n\nFor credential related errors follow below MOS document: \nUser Guide for ASMCMDs \"credverify\" and \"credfix\" for ASM Credential Management (Doc ID 2717290.1)\nThe credential resolution is typically done using $ORACLE_HOME/bin/asmcmd --nocp credfix. However depending upon the type of issue additional steps will be required. Hence please reach out to Oracle Support for assistance.\n\nNote: If after corrective actions are completed, you wish to run just this review manually without a full Exachk run, as the \"root\" userid execute the following Exachk command:\n\n    exachk -check E0B03D017A2D4A2BE053D198EB0ADAE3 -showpass"}]}, {"id": "6514662a-9c00-4983-9606-01abedd8a7f4", "checkCategory": "RDBMS", "checkID": "E13461CE4E9717FAE04312C0E50AB0C0", "checkType": "OS", "checkName": "Local listener set to node VIP", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Local listener init parameter is set to local node VIP"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Local listener set to node VIP\n\n\n\nLocal Listener =\n(ADDRESS=(PROTOCOL=TCP)(HOST=10.214.209.68)(PORT=1521))\n\nLocal VIP Config =\nVIP exists:network number 1, hosting node scaqal03adm05vm01\nVIP Name:scaqal03client05vm01-vip.us.oracle.com\nVIP IPv4 Address:10.214.209.68\nVIP IPv6 Address:\nVIP is enabled.\nVIP is individually enabled on nodes:\nVIP is individually disabled on nodes:"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Local listener init parameter is set to local node VIP"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Local listener set to node VIP\n\n\n\nLocal Listener =\n(ADDRESS=(PROTOCOL=TCP)(HOST=10.214.209.69)(PORT=1521))\n\nLocal VIP Config =\nVIP exists:network number 1, hosting node scaqal03adm06vm01\nVIP Name:scaqal03client06vm01-vip.us.oracle.com\nVIP IPv4 Address:10.214.209.69\nVIP IPv6 Address:\nVIP is enabled.\nVIP is individually enabled on nodes:\nVIP is individually disabled on nodes:"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "The LOCAL_LISTENER parameter should be set to the node VIP. If you need fully qualified domain names, ensure that LOCAL_LISTENER is set to the fully qualified domain name (node-vip.mycompany.com). By default a local listener is created during cluster configuration that runs out of the grid infrastructure home and listens on the specified port(default is 1521) of the node VIP."}]}, {"id": "7fe5cefd-1d21-4c51-a7e5-63893930f28d", "checkCategory": "HOST", "checkID": "E59ABF53EAF06F0BE04312C0E50A7C2A", "checkType": "OS", "checkName": "Verify ExaWatcher is executing [Database Server]", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "ExaWatcher is running"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY EXAWATCHER IS EXECUTING [DATABASE SERVER]\n\n\n\n21"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "ExaWatcher is running"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - VERIFY EXAWATCHER IS EXECUTING [DATABASE SERVER]\n\n\n\n24"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nExaWatcher collects data on key metrics for both database and storage servers, which can be used for both troubleshooting and performance analysis.\n\nThere is minimal impact to verify that ExaWatcher is executing, or from starting ExaWatcher if it is not executing.\n\nRisk:\n\nIf ExaWatcher is not executing, valuable data for analysis is not collected.\n\nAction / Repair:\n\nTo verify that ExaWatcher is executing, as the \"root\" userid execute the following command set on each database and storage server in the cluster:\n\nNUM_OF_EXAWATCHERS=$(ps -ef | grep -i exawatcher | grep -v grep | wc -l)\nif [[ $NUM_OF_EXAWATCHERS -gt 0 ]]\nthen\n  echo -e \"SUCCESS: ExaWatcher is executing.  Number of processes: $NUM_OF_EXAWATCHERS\"\nelse\n  echo -e \"FAILURE: ExaWatcher is not executing.  Number of processes: $NUM_OF_EXAWATCHERS\"\nfi\n\nThe output should be similar to:\n\nSUCCESS: ExaWatcher is executing.  Number of processes: 15\n\nNOTE: The number of processes may vary depending upon the site-specific configuration. \n\nIf ExaWatcher is not executing, please refer to the \"System Diagnostics Data Gathering with sosreports and Oracle ExaWatcher\" section of the \"Oracle Exadata Storage Server Software User's Guide\" that is for your specific installed version of Oracle Exadata Storage Server software."}, {"id": "016bfb69-efda-4a54-9eee-4c00de197d7b", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=301137.1", "text": "Note: 301137.1 - OS Watcher User Guide"}]}]}, {"id": "6dea05a8-27f1-4317-b1ec-3348eec615bb", "checkCategory": "RDBMS", "checkID": "E94589BC1AC24CFBE04312C0E50A3849", "checkType": "OS", "checkName": "Verify online (hot) patches are not applied on ORACLE_HOME", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Online (hot) patches are not applied to ORACLE_HOME"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Verify online (hot) patches are not applied on ORACLE_HOME\n\n\n\n\nPatch File Name  \t\t\t\t  State\n================ \t\t\t\t=========\nNo patches currently installed"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Online (hot) patches are not applied to ORACLE_HOME"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Verify online (hot) patches are not applied on ORACLE_HOME\n\n\n\n\nPatch File Name  \t\t\t\t  State\n================ \t\t\t\t=========\nNo patches currently installed"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nOnline patches are recommended when a downtime cannot be scheduled and the patch needs to be applied urgently.\n\nRisk:\n\nOnline patches consume additional memory and if kept permanently the memory consumption increases as the number of processes in the system increases.  Recycling the database with an online (hot) patch not replaced by the regular (offline) patch can severely degrade database performance.\n\nAction / Repair:\n\nIt is strongly recommended to rollback all Online patches and replace them with regular (offline) patches on next instance shutdown or the earliest maintenance window."}, {"id": "d2ad1922-488b-40e8-bb1d-2c9ce2978d96", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=761111.1", "text": "Note: 761111.1 - RDBMS Online Patching Aka Hot Patching"}, {"hyperlink": "http://docs.oracle.com/cd/E11882_01/server.112/e10803/schedule_outage.htm#BABCAGCJ", "text": "Online patching"}]}]}, {"id": "0ab734f4-db84-4bc0-bd1b-d184f784de62", "checkCategory": "CRS HOME", "checkID": "E96A3ED23AC91994E04312C0E50ABD03", "checkType": "OS", "checkName": "Verify online (hot) patches are not applied on CRS_HOME", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Online (hot) patches are not applied to CRS_HOME."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY ONLINE (HOT) PATCHES ARE NOT APPLIED ON CRS_HOME\n\n\n\nls:cannot access /u01/app/21.0.0.0/grid/hpatch/:No such file or directory"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Online (hot) patches are not applied to CRS_HOME."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - VERIFY ONLINE (HOT) PATCHES ARE NOT APPLIED ON CRS_HOME\n\n\n\nls:cannot access /u01/app/21.0.0.0/grid/hpatch/:No such file or directory"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nOnline patches are recommended when a downtime cannot be scheduled and the patch needs to be applied urgently\n\n\n\nRisk:\n\nOnline patches consume additional memory and if kept permanently the memory consumption increases as the number of processes in the system increases.  Recycling the ASM instance with an online (hot) patch not replaced by the regular (offline) patch can severely degrade ASM performance.\n\nAction / Repair:\n\nIt is strongly recommended to rollback all Online patches and replace them with regular (offline) patches on next instance shutdown or the earliest maintenance window."}, {"id": "86085a5c-8e78-44aa-b544-4c71e0ba72c6", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=761111.1", "text": "Note: 761111.1 - RDBMS Online Patching Aka Hot Patching"}, {"hyperlink": "http://docs.oracle.com/cd/E11882_01/server.112/e10803/schedule_outage.htm#BABCAGCJ", "text": "Online patching"}]}]}, {"id": "bfcbf82a-0242-407f-ab02-3622373aae70", "checkCategory": "RDBMS HOME", "checkID": "ED600DFC38714E72E04313C0E50AF4D9", "checkType": "OS", "checkName": "Exadata Storage Server rolling cell patching minimum RDBMS software requirement", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:/u01/app/oracle/product/21.0.0.0/dbhome_1", "status": "success", "statusLabel": "PASS", "output": "Exadata Storage Server RDBMS software version meets requirement for rolling cell patching"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - /u01/app/oracle/product/21.0.0.0/dbhome_1 DATABASE_HOME - Exadata Storage Server rolling cell patching minimum RDBMS software requirement\n\n\n\n34172231;OCW RELEASE UPDATE 21.7.0.0.0 (34172231)\n34160444;Database Release Update :21.7.0.0.220719 (34160444)\n\nOPatch succeeded."}}]}, {"attr": {"target": "scaqal03adm06vm01:/u01/app/oracle/product/21.0.0.0/dbhome_1", "status": "success", "statusLabel": "PASS", "output": "Exadata Storage Server RDBMS software version meets requirement for rolling cell patching"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - /u01/app/oracle/product/21.0.0.0/dbhome_1 DATABASE_HOME - Exadata Storage Server rolling cell patching minimum RDBMS software requirement\n\n\n\n34172231;OCW RELEASE UPDATE 21.7.0.0.0 (34172231)\n34160444;Database Release Update :21.7.0.0.220719 (34160444)\n\nOPatch succeeded."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Review MOS Note 888828.1 to identify the minimum software levels required to perform rolling cell patching"}, {"id": "c393efe1-a27b-48d6-b19e-69c57fa91605", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=888828.1", "text": "Note: 888828.1 - \tDatabase Machine and Exadata Storage Server 11g Release 2 (11.2) Supported Versions"}]}]}, {"id": "df225117-6250-4b43-ae8e-dadae020d8b4", "checkCategory": "HOST", "checkID": "FA04175CA0373385E04313C0E50A46C1", "checkType": "OS", "checkName": "TFA Collector status", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "TFA Collector is installed and running"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - TFA COLLECTOR STATUS\n\n\n\n\n-rwxr-xr-x 1 root root 36557 Aug 29 11:37 /etc/init.d/init.tfa\n\n-rwxr-xr-x 1 root root 7 Aug 29 11:37 /opt/oracle.ahf/data/scaqal03adm05vm01/tfa/internal/.pidfile"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "TFA Collector is installed and running"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - TFA COLLECTOR STATUS\n\n\n\n\n-rwxr-xr-x 1 root root 36557 Aug 29 11:39 /etc/init.d/init.tfa\n\n-rwxr-xr-x 1 root root 6 Aug 29 11:39 /opt/oracle.ahf/data/scaqal03adm06vm01/tfa/internal/.pidfile"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "TFA Collector (aka TFA) is a diagnostic collection utility to simplify  diagnostic data collection on Oracle Clusterware/Grid Infrastructure and RAC  systems.  TFA is similar to the diagcollection utility packaged with Oracle  Clusterware in the fact that it collects and packages diagnostic data however  TFA is MUCH more powerful than diagcollection with its ability to centralize  and automate the collection of diagnostic information. This helps speed up  the data collection and upload process with Oracle Support, minimizing delays  in data requests and analysis.\nTFA provides the following key benefits:- \n  - Encapsulates diagnostic data collection for all CRS/GI and RAC components  on all cluster nodes into a single command executed from a single node \n  - Ability to \"trim\" diagnostic files during data collection to reduce data  upload size \n  - Ability to isolate diagnostic data collection to a given time period \n  - Ability to centralize collected diagnostic output to a single server in  the cluster \n  - Ability to isolate diagnostic collection to a particular product  component, e.g. ASM, RDBMS, Clusterware \n  - Optional Real Time Scan Alert Logs for conditions indicating a problem (DB \n  - Alert Logs, ASM Alert Logs, Clusterware Alert Logs, etc) \n  - Optional Automatic Data Collection based off of Real Time Scan findings \n  - Optional On Demand Scan (user initialted) of all log and trace files for  conditions indicating a problem \n  - Optional Automatic Data Collection based off of On Demand Scan findings "}, {"id": "dd10ca13-2885-48cd-8617-7a703265db3e", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1513912.1", "text": "Note: 1513912.1 - TFA Collector- The Preferred Tool for Automatic or ADHOC Diagnostic Gathering Across All Cluster Nodes"}, {"hyperlink": "http://www.oracle.com/technetwork/products/clustering/overview/tracefileanalyzer-2008420.pdf", "text": "Trace File Analyzer Collector (TFA)"}]}]}, {"id": "710df876-9f88-4d46-b9fb-39efee5cb755", "checkCategory": "RDBMS", "checkID": "C7BC5051489C206DE053D298EB0AFA64", "checkType": "OS", "checkName": "Verify no duplicate parameter entries in database init.ora(spfile)", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "There are no duplicate parameter entries in the database init.ora(spfile) file"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Verify no duplicate parameter entries in database init.ora(spfile)\n\n\n\nNo Duplicate Database Parameters Found in spfile /opt/oracle.ahf/data/scaqal03adm05vm01/exachk/user_root/work/.exachk_082924_164512/.exachk_082924_164512/oracle/CDB11_pfile_from_spfile_345936.ora\nSee complete list of parameters in spfile /opt/oracle.ahf/data/scaqal03adm05vm01/exachk/user_root/work/.exachk_082924_164512/.exachk_082924_164512/oracle/CDB11_pfile_from_spfile_345936.ora:\nCDB12.__data_transfer_cache_size=0\nCDB11.__data_transfer_cache_size=0\nCDB11.__db_cache_size=102542344192\nCDB12.__db_cache_size=98784247808\nCDB12.__inmemory_ext_roarea=0\nCDB11.__inmemory_ext_roarea=0\nCDB12.__inmemory_ext_rwarea=0\nCDB11.__inmemory_ext_rwarea=0\nCDB12.__java_pool_size=0\nCDB11.__java_pool_size=0\nCDB12.__large_pool_size=268435456\nCDB11.__large_pool_size=268435456\nCDB11.__oracle_base='/u01/app/oracle'#ORACLE_BASE set from environment\nCDB12.__oracle_base='/u01/app/oracle'#ORACLE_BASE set from environment\nCDB12.__pga_aggregate_target=62545461248\nCDB11.__pga_aggregate_target=62545461248\nCDB12.__sga_target=124822487040\nCDB11.__sga_target=124822487040\nCDB12.__shared_io_pool_size=268435456\nCDB11.__shared_io_pool_size=268435456\nCDB11.__shared_pool_size=21206401024\nCDB12.__shared_pool_size=24964497408\nCDB12.__streams_pool_size=0\nCDB11.__streams_pool_size=0\nCDB12.__unified_pga_pool_size=0\nCDB11.__unified_pga_pool_size=0\n*._appqos_cdb_setting=3\n*._assm_segment_repair_bg=FALSE\n*._disable_oradebug_commands='NONE'\n*._parallel_adaptive_max_users=2\n*.audit_sys_operations=TRUE\n*.audit_trail='db'\n*.cluster_database=true\nCDB12.cluster_interconnects='192.168.11.132:192.168.11.133'\nCDB11.cluster_interconnects='192.168.11.128:192.168.11.129'\n*.compatible='21.0.0'\n*.control_files='+DATAC1/CDB1/CONTROLFILE/current.259.1123543513'\n*.db_block_checking='false'\n*.db_block_checksum='full'\n*.db_block_size=8192\n*.db_create_file_dest='+DATAC1'\n*.db_create_online_log_dest_1='+DATAC1'\n*.db_files=1024\n*.db_lost_write_protect='typical'\n*.db_name='CDB1'\n*.db_recovery_file_dest='+RECOC1'\n*.db_recovery_file_dest_size=79975940096000#90% of Total Space in FRA Disk Group\n*.db_unique_name='CDB1'#ENSURE THAT DB_UNIQUE_NAME IS UNIQUE ACROSS THE ENTERPRISE\n*.diagnostic_dest='/u01/app/oracle'\n*.dispatchers='(PROTOCOL=TCP) (SERVICE=CDB1XDB)'\n*.enable_pluggable_database=true\n*.fast_start_mttr_target=300\n*.filesystemio_options='setall'\n*.global_names=TRUE\nfamily:dw_helper.instance_mode='read-only'\nCDB12.instance_number=2\nCDB11.instance_number=1\n*.local_listener='-oraagent-dummy-'\n*.log_archive_dest_1='location=USE_DB_RECOVERY_FILE_DEST valid_for=(ALL_LOGFILES,ALL_ROLES) MAX_FAILURE=1 REOPEN=5 DB_UNIQUE_NAME=CDB1 ALTERNATE=LOG_ARCHIVE_DEST_2'\n*.log_archive_dest_2='location=+DATAC1 valid_for=(ALL_LOGFILES,ALL_ROLES) DB_UNIQUE_NAME=CDB1 ALTERNATE=LOG_ARCHIVE_DEST_1'\n*.log_archive_dest_state_1='ENABLE'\n*.log_archive_dest_state_2='ALTERNATE'\n*.log_archive_format='%t_%s_%r.dbf'\n*.nls_language='AMERICAN'\n*.nls_territory='AMERICA'\n*.open_cursors=1000\n*.os_authent_prefix=''\n*.parallel_execution_message_size=16384\n*.parallel_threads_per_cpu=1\n*.pga_aggregate_target=59411m\n*.processes=2048\n*.recyclebin='on'\n*.remote_login_passwordfile='exclusive'\n*.sga_target=118823m\n*.sql92_security=TRUE\nCDB12.thread=2\nCDB11.thread=1\n*.undo_tablespace='UNDOTBS1'\nCDB11.undo_tablespace='UNDOTBS1'\nCDB12.undo_tablespace='UNDOTBS2'\n*.use_large_pages='ONLY'"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "There are no duplicate parameter entries in the database init.ora(spfile) file"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Verify no duplicate parameter entries in database init.ora(spfile)\n\n\n\nNo Duplicate Database Parameters Found in spfile /opt/oracle.ahf/data/scaqal03adm06vm01/exachk/user_root/work/.exachk_082924_164512/.exachk_082924_164512/oracle/CDB12_pfile_from_spfile_269741.ora\nSee complete list of parameters in spfile /opt/oracle.ahf/data/scaqal03adm06vm01/exachk/user_root/work/.exachk_082924_164512/.exachk_082924_164512/oracle/CDB12_pfile_from_spfile_269741.ora:\nCDB12.__data_transfer_cache_size=0\nCDB11.__data_transfer_cache_size=0\nCDB11.__db_cache_size=102542344192\nCDB12.__db_cache_size=98784247808\nCDB12.__inmemory_ext_roarea=0\nCDB11.__inmemory_ext_roarea=0\nCDB12.__inmemory_ext_rwarea=0\nCDB11.__inmemory_ext_rwarea=0\nCDB12.__java_pool_size=0\nCDB11.__java_pool_size=0\nCDB12.__large_pool_size=268435456\nCDB11.__large_pool_size=268435456\nCDB11.__oracle_base='/u01/app/oracle'#ORACLE_BASE set from environment\nCDB12.__oracle_base='/u01/app/oracle'#ORACLE_BASE set from environment\nCDB12.__pga_aggregate_target=62545461248\nCDB11.__pga_aggregate_target=62545461248\nCDB12.__sga_target=124822487040\nCDB11.__sga_target=124822487040\nCDB12.__shared_io_pool_size=268435456\nCDB11.__shared_io_pool_size=268435456\nCDB11.__shared_pool_size=21206401024\nCDB12.__shared_pool_size=24964497408\nCDB12.__streams_pool_size=0\nCDB11.__streams_pool_size=0\nCDB12.__unified_pga_pool_size=0\nCDB11.__unified_pga_pool_size=0\n*._appqos_cdb_setting=3\n*._assm_segment_repair_bg=FALSE\n*._disable_oradebug_commands='NONE'\n*._parallel_adaptive_max_users=2\n*.audit_sys_operations=TRUE\n*.audit_trail='db'\n*.cluster_database=true\nCDB12.cluster_interconnects='192.168.11.132:192.168.11.133'\nCDB11.cluster_interconnects='192.168.11.128:192.168.11.129'\n*.compatible='21.0.0'\n*.control_files='+DATAC1/CDB1/CONTROLFILE/current.259.1123543513'\n*.db_block_checking='false'\n*.db_block_checksum='full'\n*.db_block_size=8192\n*.db_create_file_dest='+DATAC1'\n*.db_create_online_log_dest_1='+DATAC1'\n*.db_files=1024\n*.db_lost_write_protect='typical'\n*.db_name='CDB1'\n*.db_recovery_file_dest='+RECOC1'\n*.db_recovery_file_dest_size=79975940096000#90% of Total Space in FRA Disk Group\n*.db_unique_name='CDB1'#ENSURE THAT DB_UNIQUE_NAME IS UNIQUE ACROSS THE ENTERPRISE\n*.diagnostic_dest='/u01/app/oracle'\n*.dispatchers='(PROTOCOL=TCP) (SERVICE=CDB1XDB)'\n*.enable_pluggable_database=true\n*.fast_start_mttr_target=300\n*.filesystemio_options='setall'\n*.global_names=TRUE\nfamily:dw_helper.instance_mode='read-only'\nCDB12.instance_number=2\nCDB11.instance_number=1\n*.local_listener='-oraagent-dummy-'\n*.log_archive_dest_1='location=USE_DB_RECOVERY_FILE_DEST valid_for=(ALL_LOGFILES,ALL_ROLES) MAX_FAILURE=1 REOPEN=5 DB_UNIQUE_NAME=CDB1 ALTERNATE=LOG_ARCHIVE_DEST_2'\n*.log_archive_dest_2='location=+DATAC1 valid_for=(ALL_LOGFILES,ALL_ROLES) DB_UNIQUE_NAME=CDB1 ALTERNATE=LOG_ARCHIVE_DEST_1'\n*.log_archive_dest_state_1='ENABLE'\n*.log_archive_dest_state_2='ALTERNATE'\n*.log_archive_format='%t_%s_%r.dbf'\n*.nls_language='AMERICAN'\n*.nls_territory='AMERICA'\n*.open_cursors=1000\n*.os_authent_prefix=''\n*.parallel_execution_message_size=16384\n*.parallel_threads_per_cpu=1\n*.pga_aggregate_target=59411m\n*.processes=2048\n*.recyclebin='on'\n*.remote_login_passwordfile='exclusive'\n*.sga_target=118823m\n*.sql92_security=TRUE\nCDB12.thread=2\nCDB11.thread=1\n*.undo_tablespace='UNDOTBS1'\nCDB11.undo_tablespace='UNDOTBS1'\nCDB12.undo_tablespace='UNDOTBS2'\n*.use_large_pages='ONLY'"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": ""}]}, {"id": "226f9c4a-0a18-4951-89b3-791bb15a6978", "checkCategory": "RDBMS", "checkID": "FB7BBD8E8BC78623E0539812F50A0B81", "checkType": "OS", "checkName": "Validate controlfile_record_keep_time is set correctly", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "control_file_record_keep_time parameter is set correctly"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Validate controlfile_record_keep_time is set correctly\n\n\n\nSUCCESS:RMAN Catalog NOT used and control_file_record_keep_time between 1 and 99"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "control_file_record_keep_time parameter is set correctly"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Validate controlfile_record_keep_time is set correctly\n\n\n\nSUCCESS:RMAN Catalog NOT used and control_file_record_keep_time between 1 and 99"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nControl File sizes can impact database performance and stability. Controlfile (CF) Enqueue contention may occur when control file size gets very large and one of the key contributor of the size of the controlfile is controlfile_record_keep_time.  This check is to ensure that the spfile parameter controlfile_record_keep_time is set to 7 for databases that are using an RMAN catalog. Otherwise, the recommended value &lt;= database recovery window (e.g. backup retention window) + 7 days.\n\nRisk:\n\nFor databases with very large control files, CF Enqueue contention can occur and in rare circumstances can cause stalls or in the rare cases instance eviction.\n\nAction / Repair:\n\nRun the query below which reports the SUCCESS/FAILURE for the test\n\nWITH ro AS\n   ( SELECT COUNT(1) found\n       FROM DUAL\n      WHERE EXISTS ( SELECT 1 FROM V$RMAN_OUTPUT WHERE OUTPUT = 'connected to recovery catalog database' )\n   )\n   , init AS\n   ( SELECT TO_NUMBER(VALUE) value\n       FROM V$PARAMETER WHERE NAME = 'control_file_record_keep_time' AND VALUE = '7'\n   )\nSELECT CASE WHEN ro.found = 1 AND init.value = 7 THEN 'SUCCESS: RMAN Catalog used and control_file_record_keep_time = 7'\n            WHEN ro.found = 1 AND init.value &lt;&gt; 7 THEN 'FAILURE: RMAN Catalog used and control_file_record_keep_time &lt;&gt; 7'\n            WHEN ro.found = 0 AND init.value BETWEEN 1 AND 99 THEN 'SUCCESS: RMAN Catalog NOT used and control_file_record_keep_time between 1 and 99'\n            ELSE 'FAILURE: RMAN Catalog NOT used and control_file_record_keep_time NOT between 1 and 99' END RESULTS\n  FROM ro\n     , init\n/\n\nIf an RMAN Catalog is detected, but the control_file_record_keep_time &lt;&gt; 7 then change the parameter control_file_record_keep_time and restart the database\n\nALTER SYSTEM SET control_file_record_keep_time = 7 SCOPE=SPFILE SID='*'\n/\n\nIf an RMAN Catalog is NOT detected, and the control_file_record_keep_time is &lt; 1 or &gt; 99 then change the parameter control_file_record_keep_time and restart the database.  The value chosen should be &lt;= database recovery window (e.g. backup retention window) +  7 days.\n\nALTER SYSTEM SET control_file_record_keep_time = &lt;value&gt; SCOPE=SPFILE SID='*'\n\n/\n\nOnce the issue has been resolved, this audit check can be invoked individually as root user as follows:\n# exachk -check FB7BBD8E8BC78623E0539812F50A0B81"}]}, {"id": "2fda4f76-d5ca-43e1-b32a-b469575cb567", "checkCategory": "ASM", "checkID": "FE94289A829C6A2AE0539912F50AD188", "checkType": "OS", "checkName": "Check for CachedBy and CachingPolicy GridDisks attributes", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "Attribute cachingPolicy is correct for all grid disks"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - CHECK FOR CACHEDBY AND CACHINGPOLICY GRIDDISKS ATTRIBUTES\n\n\n\n[SUCCESS]:Attribute cachingPolicy is correct for all grid disks.\n\nDetails:\n1) Check for CachedBy attribute in grid disks\n[SUCCESS]:All grid disks have some flash defined in CachedBy attribute.\n\n2) Check for CachingPolicy attribute\n[SUCCESS]:All grid disks have CachingPolicy=default.\n\n3) Check for symetric CachedBy between grid disks\n[SUCCESS]:All grid disks have the same number of Flash Devices in cachedBy attribute."}}]}, {"attr": {"target": "scaqal03adm06vm01:+ASM2", "status": "success", "statusLabel": "PASS", "output": "Attribute cachingPolicy is correct for all grid disks"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - CHECK FOR CACHEDBY AND CACHINGPOLICY GRIDDISKS ATTRIBUTES\n\n\n\n[SUCCESS]:Attribute cachingPolicy is correct for all grid disks.\n\nDetails:\n1) Check for CachedBy attribute in grid disks\n[SUCCESS]:All grid disks have some flash defined in CachedBy attribute.\n\n2) Check for CachingPolicy attribute\n[SUCCESS]:All grid disks have CachingPolicy=default.\n\n3) Check for symetric CachedBy between grid disks\n[SUCCESS]:All grid disks have the same number of Flash Devices in cachedBy attribute."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nSystems can incur unpredictable performance degradation when the cachingPolicy attribute is not using flash or when the cachedBy attribute is not symmetrical across storage servers.\nSince March 2022 the cachingPolicy attribute is changed to default in Oracle Exadata System Software 22.1 or higher.\nFor systems with XT storage servers, those storgae servers are skipped from this check automatically.\n\nRisk:\n\nUnpredictable performance degradation.\n\nAction / Repair:\n\nMake sure that all grid disks with cachingPolicy=default and cachedBy=[SOMEFLASH] and same number of flash devices specified per grid disk.\n1. Check to make sure all DATA and RECO grid disks have a cachingPolicy of default.\n2. Check to make sure all DATA and RECO grid disks have at least one flash device in the cachedBy attribute.\n3. Check to see if the cachedBy configuration is identical across all storage servers.\n\n\nNote: Once the issue has been resolved, if you wish to validate this Exachk check individually, you may run the following command as \"root\" user:\n\n    exachk -showpass -check FE94289A829C6A2AE0539912F50AD188"}]}, {"id": "fb0f0d27-02ed-412a-8772-4f3accbbfcd4", "checkCategory": "HOST", "checkID": "FFBC5B8AEE398CADE0539812F50A0429", "checkType": "OS", "checkName": "Check for tainted kernel by non-Oracle modules and 3rd party security software installed from package", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "No tainted modules or 3rd party security software installed from package detected in this system"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - CHECK FOR TAINTED KERNEL BY NON-ORACLE MODULES AND 3RD PARTY SECURITY SOFTWARE INSTALLED FROM PACKAGE\n\n\n\nSUCCESS:No tainted modules or 3rd party security software installed from package detected in this system"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "No tainted modules or 3rd party security software installed from package detected in this system"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - CHECK FOR TAINTED KERNEL BY NON-ORACLE MODULES AND 3RD PARTY SECURITY SOFTWARE INSTALLED FROM PACKAGE\n\n\n\nSUCCESS:No tainted modules or 3rd party security software installed from package detected in this system"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nYou may load additional software on the database servers. However, to ensure best performance, Oracle discourages adding software except for agents, such as backup agents and security monitoring agents, on the database servers. \n\nRisk:\n\nLoading non-standard kernel modules on the operating system of the database servers is allowed but discouraged. Oracle will not support questions or issues with the non-standard modules. If a server crashes, and Oracle suspects the crash may have been caused by a non-standard module, then Oracle support may refer you to the vendor of the non-standard module or ask that the issue be reproduced without the non-standard module. Modifying the database server operating system other than by applying official patches and upgrades is not supported.\n\nAction / Repair:\n\nIn case of operational impact occurs, please refer to the vendor\u0019s documentation to disable this software and reproduce the issue. Contact the vendor and follow their guidelines for support of the security software."}]}, {"id": "ce085204-efa7-4e88-a2cb-261e441874e3", "checkCategory": "RDBMS", "checkID": "025C58C06C8C1B40E0639712F50ABF2C", "checkType": "OS", "checkName": "Dedicated Tablespace for Unified Audit Trail", "checkStatus": "WARN", "status": "warning", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "warning", "statusLabel": "WARN", "output": "AHF-10321: SYSTEM tablespace is being used by audit objects"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Dedicated Tablespace for Unified Audit Trail\n\n\n\nPARAMETER_NAME            PARAMETER_VALUE           AUDIT_TRAIL\n------------------------- ------------------------- -------------------\nDB AUDIT TABLESPACE       SYSAUX                    UNIFIED AUDIT TRAIL"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "warning", "statusLabel": "WARN", "output": "AHF-10321: SYSTEM tablespace is being used by audit objects"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Dedicated Tablespace for Unified Audit Trail\n\n\n\nPARAMETER_NAME            PARAMETER_VALUE           AUDIT_TRAIL\n------------------------- ------------------------- -------------------\nDB AUDIT TABLESPACE       SYSAUX                    UNIFIED AUDIT TRAIL"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nMoving the database audit trail objects out of the SYSAUX tablespace improves overall database performance by reducing the load on the SYSAUX tablespace.\n\nRisk:\n\nSYSAUX tablespace usage for auditing can lead to potential database performance problems.\n\n\nAction / Repair:\n\nIf the default tablespace for audit object is under SYSAUX tablespace, then it is recommended to create a new custom tablespace and move the existing audit objects/data to the new tablespace to avoid any Performance overhead. Always Maintain sufficient space to avoid database unplanned outages and configure tablespace monitoring also partition the auditing table. This is to avoid performance during data purging. Schedule audit data purging jobs as per your organization policies\nIt is applicable only for customers who are using unified audit by default. Database has both unified and traditional audit. This is not for audit if audit trail is set to OS\n\nThis can be done following the below commands as an example:\n\nCreate a new tablespace AUDIT_TBS and make sure that its size is large enough for the tables that will be moved.\n\nMove the audit trail tables using procedure DBMS_AUDIT_MGMT.SET_AUDIT_TRAIL_LOCATION.\n\nAlways Maintain sufficient space to avoid database unplanned outages and configure tablespace monitoring also partition the auditing table. This is to avoid performance during data purging. Schedule audit data purging jobs as per your organization policies\nFor Unified Audit Trail:\n\ncreate tablespace AUDIT_TBS datafile '&lt;PATH&gt;/auditts.dbf' size 100M autoextend on;\n\nBEGIN\nDBMS_AUDIT_MGMT.set_audit_trail_location(\naudit_trail_type =&gt; DBMS_AUDIT_MGMT.AUDIT_TRAIL_UNIFIED,--this moves table Unified Audit\naudit_trail_location_value =&gt; 'AUDIT_TBS');\nEND;\n/"}, {"id": "406a1332-9339-4b98-ba28-10a9dbb22355", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?_afrLoop=320467694180754&parent=EXTERNAL_SEARCH&sourceId=HOWTO&id=1328239.1&_afrWindowMode=0&_adf.ctrl-state=sdxtfmf3p_53", "text": "How To Move The DB Audit Trails To A New Tablespace Using DBMS_AUDIT_MGMT? (Doc ID 1328239.1)"}, {"hyperlink": "https://docs.oracle.com/en/database/oracle/oracle-database/19/arpls/DBMS_AUDIT_MGMT.html#GUID-C704D6B0-A6ED-4CFC-B364-CC008CFF76F1", "text": "PL/SQL Packages and Types Reference - DBMS_AUDIT_MGMT"}]}]}, {"id": "42979b7a-c8de-4aa6-b02f-1ac055590bb6", "checkCategory": "RDBMS", "checkID": "4A1584F49EDF8AD0E0530C98EB0A516E", "checkType": "OS", "checkName": "Verify service definition for Pluggable Databases", "checkStatus": "WARN", "status": "warning", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "warning", "statusLabel": "WARN", "output": "AHF-10063: One or more open PDBs have failed service verification checks"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Verify service definition for Pluggable Databases\n\n\n\nSUCCESS:all open PDBs have non-default services defined or there are no open PDBs\n\nSUCCESS:no PDBs have saved state information\n\nSUCCESS:no AFTER STARTUP DATABASE triggers were detected\n\nWARNING:One or more pluggable databases were found to have user defined services which are not being used. The following list may not show all PDBs/services.\nTotal unused user defined services count:1\n\nUnused user defined services\n---------------------------------------------------\nPDB_NAME\t     SERVICE_NAME\n-------------------- ----------------------------------------\nPDB11\t\t     CDB1_PDB11_svc"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "warning", "statusLabel": "WARN", "output": "AHF-10063: One or more open PDBs have failed service verification checks"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Verify service definition for Pluggable Databases\n\n\n\nSUCCESS:all open PDBs have non-default services defined or there are no open PDBs\n\nSUCCESS:no PDBs have saved state information\n\nSUCCESS:no AFTER STARTUP DATABASE triggers were detected\n\nWARNING:One or more pluggable databases were found to have user defined services which are not being used. The following list may not show all PDBs/services.\nTotal unused user defined services count:1\n\nUnused user defined services\n---------------------------------------------------\nPDB_NAME\t     SERVICE_NAME\n-------------------- ----------------------------------------\nPDB11\t\t     CDB1_PDB11_svc"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nWhen following MAA best practices for Pluggable database services on Exadata or RAC, you ensure that applications can connect to pluggable database\u0019s service in more predictable manner.  Here are the main recommendations for pluggable database services:\n\n    Never use PDB default services, nor SAVED STATE (except during relocate operations), nor database triggers to manage role based PDB services\n    Use clusterware managed distinct services per PDB for your application service and leverage that application service to connect to the database\n    When defining clusterware managed application service, you should define which PDB and services will be started and in which RAC instance and database role.\n    For Data Guard, always use role based services by assigning a role to each clusterware managed service.\n    Review the check output below for the usage of user defined services for each PDB and take action as appropriate.\n\nIf the above practices are applied, you will have predictable service management during PDB open within a RAC cluster and for Data Guard role transitions.  This will lead to higher application service availability and avoid application errors.\n\nSee My Oracle Support note Best Practices for Pluggable Database End User and Application Connection and Open on Database Startup (Doc ID 2833029.1) for more information.\n\nRisk:\n\nIf PDB connects to the default PDB services or use SAVED STATE or database triggers, the service management may be unpredictable resulting in application downtime or resulting in PDB services coming up in the wrong database or instances in an unpredictable manner after software updates, RAC instance, CDB database restarts or after Data Guard role transition resulting in application errors and unpredictable application results.\n\nAction / Repair:\n\nNote that only PDBs that are open and not in MIGRATE/UPGRADE mode will be checked for non-default services while all PDBs will be checked for saved state information. Since a PDB may not be open on all instances the following script should be executed on each instance of each CDB.\n\nIf there are PDBs found that do not have non-default services defined for them, a message similar to the following will be returned:\nWARNING: the following open PDBs do not have non-default services defined: TESTPDB4 TESTPDB2 TESTPDB3 TESTPDB5 TESTPDB1\nTo resolve the warning, create services for these PDBs using either:\n    1. srvctl in Grid Infrastructure or Oracle Restart based environments\n    2. The DBMS_SERVICE.create_service package in environments where srvctl is not available.\n\nIf there are PDBs found having saved state information, a message similar to the following will be returned:\nWARNING: the following PDBs have saved state information: TESTPDB4 TESTPDB2 TESTPDB3 TESTPDB5 TESTPDB1 PDBs in preparation for PDB relocate operations can be ignored \nTo resolve the warning, for each PDB in the list, connect to the CDB via sqlplus and run:\n    ALTER PLUGGABLE DATABASE &lt;pdbName&gt; DISCARD SAVED STATE INSTANCES=ALL;\n\nIf AFTER STARTUP DATABASE triggers were found, a message similar to the following will be returned:\nWARNING: The following AFTER STARTUP DATABASE triggers exist: \nOPEN_ALL_PLUGGABLES\nPlease review to ensure no triggers open PDBs.\nThis warning can occur for any AFTER STARTUP DATABASE trigger, please delete any listed trigger that performs open on PDBs:\n    DROP TRIGGER &lt;triggerName&gt;;\n\n\nOnce the issue has been resolved, this audit check can be invoked individually as root user as follows:\n\n    # exachk -check 4A1584F49EDF8AD0E0530C98EB0A516E"}, {"id": "20e0f7c0-4cf8-4285-b509-27f3efea4ae6", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=2833029.1", "text": "Note: 2833029.1 - Best Practices for Pluggable Database End User and Application Connection and Open on Database Startup"}]}]}, {"id": "87568d3f-674a-4470-a05f-1852dc410e6f", "checkCategory": "RDBMS", "checkID": "C796340C46300788E053D498EB0A33A7", "checkType": "SQL", "checkName": "Invalid sys/system objects", "checkStatus": "WARN", "status": "warning", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "warning", "statusLabel": "WARN", "output": "AHF-6983: SYS or SYSTEM objects were found to be INVALID"}, "children": [{"attr": {"consoleOutput": "\n\nOBJECT_NAME\n----------------------\nDBA_FGA_AUDIT_TRAIL\nCDB_FGA_AUDIT_TRAIL\nDBA_COMMON_AUDIT_TRAIL\nCDB_COMMON_AUDIT_TRAIL\nFGA_LOG$FOR_EXPORT\nDBMS_AUDIT_UTIL\nDBMS_AUDIT_UTIL"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "If the dbupgdiag.sql script reports any invalid objects, run $ORACLE_HOME/rdbms/admin/utlrp.sql (multiple times) to validate the invalid objects in the database until there is no change in the number of invalid objects.\n\n$ cd $ORACLE_HOME/rdbms/admin\n$ sqlplus \"/ as sysdba\"\nSQL&gt; @utlrp.sql\n\nAfter validating the invalid objects, re-run dbupgdiag.sql in the database once again and make sure that everything is fine."}, {"id": "3ef8ed23-19e6-4735-b6b0-920f10fa745d", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=837570.1", "text": "Note: 837570.1 - Complete Checklist for Manual Upgrades to 11gR2"}]}]}, {"id": "71d9cc6b-44b0-44a2-98c2-34cd683de09f", "checkCategory": "RDBMS", "checkID": "DD0C3EB098D2D3F0E053D598EB0A6318", "checkType": "OS", "checkName": "Check Auto Extensible datafiles are expanding by at least one stripe width", "checkStatus": "WARN", "status": "warning", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "warning", "statusLabel": "WARN", "output": "AHF-8168: Some Auto Extensible datafiles are not expanding by at least one stripe width"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Check Auto Extensible datafiles are expanding by at least one stripe width\n\n\n\nPDB11(3):Incremental size too small for file# 13, fname +DATAC1/CDB1/EFEE5BB385D0C905E05311C2D60AD565/DATAFILE/users.285.1123545623, incremental size 1280K, minimum recommended size 155648K"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "warning", "statusLabel": "WARN", "output": "AHF-8168: Some Auto Extensible datafiles are not expanding by at least one stripe width"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Check Auto Extensible datafiles are expanding by at least one stripe width\n\n\n\nPDB11(3):Incremental size too small for file# 13, fname +DATAC1/CDB1/EFEE5BB385D0C905E05311C2D60AD565/DATAFILE/users.285.1123545623, incremental size 1280K, minimum recommended size 155648K"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nWhen datafiles extend very frequently and using the default increment size, additional load can be put on the database engine which can lead to intermittent crashes.  By increasing the increment size to match the ASM disk group stripe width (1 x 4MB AU per ASM Disk) as a minimum, the chances of a database crash are reduced.\n\nRisk:\n\nThe default increment size is 64MB or 100MB depending on the size of the datafile in question.  Both of these defaults are extremely low in an engineered system.  The default for a quarter rack will be only 144MB and the default for a full rack will be 672MB.  The default for an ExaCS full rack will be 576MB.  All of these increments are relatively small and therefore should impose no risk of using the increased size.\n\nAction / Repair:\n\nTo see which datafiles are configured for auto extensible but using a small increment size, run the following query while connected as sysdba to the root container in multitenant container database or to the database in none multitenant:\n\nWITH data_dg AS\n   ( SELECT REPLACE(value,'+') dg_value\n       FROM v$parameter\n      WHERE name = 'db_create_file_dest' )\n   , au_size AS\n   ( SELECT allocation_unit_size\n       FROM v$asm_diskgroup_stat dg\n          , data_dg\n      WHERE name = data_dg.dg_value\n        AND data_dg.dg_value = dg.name )\n   , disk_cnt AS\n   ( SELECT COUNT(*) value\n       FROM v$asm_disk_stat d\n          , v$asm_diskgroup_stat dg\n          , data_dg\n      WHERE dg.name = data_dg.dg_value\n        AND dg.group_number = d.group_number)\n   , stripe_size AS\n   ( SELECT disk_cnt.value*au_size.allocation_unit_size value\n       FROM au_size\n          , disk_cnt )\nSELECT nvl(pdbs.name,'CDB$ROOT') ||\n       '(' ||\n       df.con_id ||\n       '):Incremental size to small for file# ' ||\n       df.file_id ||\n       ', fname ' ||\n       df.file_name ||\n       ', incremental size ' ||\n       (t.block_size * df.increment_by)/1024  ||\n       'K, minimum recommended size ' ||\n       stripe_size.value/1024 ||\n       'K' text\n  FROM cdb_data_files df\n     , cdb_tablespaces t\n     , stripe_size\n     , v$pdbs pdbs\n WHERE df.con_id = t.con_id\n   AND pdbs.con_id (+) = df.con_id\n   AND df.tablespace_name = t.tablespace_name\n   AND df.increment_by &lt;&gt; 0\n   AND ( t.block_size * df.increment_by ) &lt; stripe_size.value\n/\n\n\nAny rows returned means that those datafiles identified are configured for autoextend, but the increment size is smaller than the stripe width: \n\nSample output from a multi-tentant database is as follows\n\nPDB202149(4):Incremental size to small for file# 214, fname +DATAC1/CDB19RUA/D1E4416D853A72C0E053A50B200A2274/DATAFILE/aq_ts.5543.1089854819, incremental size 131072K, minimum recommended size 688128K\n\n\nRepair:\n\nFor any files that are reported as being in error, the increment size can be increased by executing the command similar to\n\nSQL&gt; alter session set container=PDB202149;\n\nSession altered.\n\nSQL&gt; alter database datafile 214 autoextend on next 688128K;\n\nDatabase altered."}]}, {"id": "594db205-9940-4a17-b90d-18ca94471a25", "checkCategory": "RDBMS", "checkID": "EB3693991E0AC815E053D298EB0AFB6B", "checkType": "OS", "checkName": "Check for Underscore Parameter Without a Comment", "checkStatus": "WARN", "status": "warning", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "warning", "statusLabel": "WARN", "output": "AHF-9082: There exists one or more underscore parameters without a comment"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Check for Underscore Parameter Without a Comment\n\n\n\nThere exists one or more underscore parameters without a comment\n\n_appqos_cdb_setting          3\n_disable_oradebug_commands   NONE\n_ipddb_enable                TRUE\n_assm_segment_repair_bg      FALSE\n_parallel_adaptive_max_users 2"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "warning", "statusLabel": "WARN", "output": "AHF-9082: There exists one or more underscore parameters without a comment"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Check for Underscore Parameter Without a Comment\n\n\n\nThere exists one or more underscore parameters without a comment\n\n_appqos_cdb_setting          3\n_disable_oradebug_commands   NONE\n_ipddb_enable                TRUE\n_assm_segment_repair_bg      FALSE\n_parallel_adaptive_max_users 2"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nUnderscore/Hidden parameters are typically set as a workaround to solve a known issue in a specific database version, but are usually set and forgotten even after upgrading to a future database version that contains the fix for the known issue. \nNot knowing when or why an underscore parameter was set for a database causes confusion during the life cycle of a database. This is important for patching events and particularly important during database upgrades. \nIt is recommended to review underscore parameters before major database version upgrades - adding a descriptive comment allows the administrator to more easily determine if an underscore parameter is still needed.\n\nRisk:\n\nNot understanding why a database parameter was set can lead to confusion and potentially performance or stability impacts through the life cycle of a database.\n\nAction / Repair:\n\nThe following SQL can be used to find underscore parameters which do not have comments\n\nselect name, value from v$parameter where name LIKE '!_%' ESCAPE '!' AND update_comment IS NULL;\n\n\nWhen setting underscore parameters, always include a comment to show user, date and reason it was set.\n\nThe following example shows a proper way of setting _gc_policy_minimum to 15000. Note that the example includes the MOS note number and its description as well as the date it was set and the user who set it:\nalter system set \"_gc_policy_minimum\"=15000 comment='user=Scott Tiger; Date=May 15, 2022; Reason=Best Practices and Recommendations for RAC databases with SGA size over 100GB (Doc ID 1619155.1)' scope=both sid='*';\n\nAnother example is setting the underscore parameter due to a request from Oracle Support in a Service Request:\nalter system set \"_gc_policy_minimum\"=15000 comment='user=Scott Tiger; Date=May 15, 2022; Reason=SR SR number' scope=both sid='*';\n\nAnother example are the few allowed underscore parameters for a specific database version, which are listed in check \"Verify Hidden Database Initialization Parameter Usage\" (Check Id 19DA5169713DA63BE0530A98EB0AAE45), e.g., for database version 19c:\n_assm_segment_repair_bg FALSE\n_parallel_adaptive_max_users 2\n_bct_public_dba_buffer_size 26214144\n_bct_buffer_allocation_max 1073741824\n_ipddb_enable TRUE\nFor these allowed underscore parameters set the comment as in the following example for parameter _assm_segment_repair_bg:\nalter system set \"_assm_segment_repair_bg\"=FALSE comment='user=oeda; Date=May 15, 2022; Reason=OEDA' scope=both sid='*';\n\n\nAfter setting the underscore parameters with a comment, verify the comment is included by issuing the following command:\nselect name, value, update_comment from v$parameter where name='&lt;underscore parameter name&gt;';\n\n\nOnce the issue has been resolved, this audit check can be invoked individually as root user as follows:\n\n    # exachk -check EB3693991E0AC815E053D298EB0AFB6B"}]}]}]}, {"sectionId": "fe3f7c5a-509d-461a-8575-65624e65441d", "sectionName": "Cluster Wide", "subsection": [{"subSectionName": "Cluster Wide", "checksList": [{"id": "acf349da-e493-4836-a01d-da32d8f5633a", "checkCategory": "HOST", "checkID": "09CB3C7131F1D975E0639A12F50A2A8A", "checkType": "CROSS_NODE_CHECK", "checkName": "Verify no orphaned files exist in ASM", "checkStatus": "CRITICAL", "status": "danger", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "danger", "statusLabel": "CRITICAL", "output": "AHF-10602: Verify no orphaned files exist in ASM"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY NO ORPHANED FILES EXIST IN ASM\n\n\n\nCRITICAL:Orphaned files were found; all DBs were opened and checked. The installed ASM version will not detect and handle orphan files properly.\n\nWithout the proper ASM software version and the presence of orphaned files, it is likely that ASM resync or rebalance operations may be slow or possibly stalled causing diskgroups to have fewer redundant copies of file extents, thereby compromising availability in the event of a disk failure. Please install the recommended ASM software updates (RU 19.22 or higher) and review the list of orphaned files to see if they should be removed.\n\nOrphan files:\n+DATAC1/AHFT/CONTROLFILE/CURRENT.296.1158487951\n+DATAC1/AHFT/DATAFILE/SYSAUX.293.1158487849\n+DATAC1/AHFT/DATAFILE/SYSTEM.292.1158487813\n+DATAC1/AHFT/DATAFILE/UNDOTBS1.294.1158487873\n+DATAC1/AHFT/DATAFILE/USERS.295.1158487875\n\n\nSpace taken by orphan files:4.0G"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\n\"Orphaned\" files are files that exist in ASM but are not in use by a database.  These files may have been initialized as part of a database / PDB creation or other operation that wasn't able to complete properly (usually due to lack of space). They are generally datafiles, but can be other types as well.  The headers of these files are not finalized and do not appear to be normal when Oracle performs integrity checks (such as H.A.R.D.). These malformed headers will fail the H.A.R.D check during ASM resync or rebalance leading to stalling and very slow resync/rebalance performance.\n\nThis check will look for orphaned files as well as ensure the ASM software version in use is capable of detecting and handling orphan files properly during rebalance. The following types of files are checked:\n\n- datafiles\n- datafile copies\n- controlfiles\n- block change tracking files\n- logfiles\n- tempfiles\n- archived logfiles\n\nRisk:\n\nOrphaned files can lead to errors, stalled resync/rebalance operations, and performance problems if the ASM software version is not capable of detecting them, in addtion to simply wasting space.\n\nAction / Repair:\n\n- Ensure the ASM software version in use is capable of detecting and handling orphan files properly\n- Search for any orphaned files in each diskgroup and list any candidate orphaned files.  In some cases, files may not be in use because the database or PDB is closed or the files happen to be in the process of being initialized.\n- Any candidate files listed should be verified that they are truly orphaned before removing them. The \"asmcmd rm \" command can be used to remove them once you have verified they are orphaned and should be removed."}]}, {"id": "3c1203a7-8bbe-4bc6-bbda-2f3fa62e364b", "checkCategory": "CLUSTER", "checkID": "03167059021F9CCAE0639812F50A4422", "checkType": "CLUSTERWIDE_CHECK", "checkName": "Verify resource limits across all nodes in the cluster", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "Resource limits match across cluster"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - Verify resource limits across all nodes in the cluster\n\n\n\nCRS_LIMIT_NPROC=400000\nCRS_LIMIT_OPENFILE=400000\nCRS_LIMIT_STACK=2048\n\nDATA FROM scaqal03adm06vm01 - Verify resource limits across all nodes in the cluster\n\n\n\nCRS_LIMIT_NPROC=400000\nCRS_LIMIT_OPENFILE=400000\nCRS_LIMIT_STACK=2048"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nHaving the same resource limits across all nodes in the cluster allows the same level of service for all database nodes.\n\n\n\nRisk:\n\nProcess startup failure due to maximum number of processes or open files limit reached.\n\nAction / Repair:\n\nManually update the $GI_HOME/crs/install/s_crsconfig_&lt;NODE&gt;_env.txt and bounce the cluster.\n\nNote: Once the issue has been resolved, if you wish to validate this Exachk check individually, you may run the following command as \"root\" user:\n\n    exachk -showpass -check 03167059021F9CCAE0639812F50A4422"}]}, {"id": "578120d0-064b-4825-928e-9209c3613746", "checkCategory": "CLUSTER", "checkID": "9EC5FC17F157DA56E040E50A1EC04678", "checkType": "CLUSTERWIDE_CHECK", "checkName": "Root  time zone", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "Time zone matches for root user across cluster"}, "children": [{"attr": {"consoleOutput": "\n\n\nDATA FROM SCAQAL03ADM05VM01 FOR ROOT TIME ZONE CHECK\n\n\n\nThu Aug 29 16:48:00 PDT 2024\n\n\nDATA FROM SCAQAL03ADM06VM01 FOR ROOT TIME ZONE CHECK\n\n\n\nThu Aug 29 16:47:56 PDT 2024"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": ""}]}, {"id": "78322e71-6ac1-491c-98f0-e35dd55ad402", "checkCategory": "CLUSTER", "checkID": "9EC5FC17F158DA56E040E50A1EC04678", "checkType": "CLUSTERWIDE_CHECK", "checkName": "Grid Infrastructure software owner time zone", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "Time zone matches for Grid Infrastructure software owner across cluster"}, "children": [{"attr": {"consoleOutput": "\n\n\nDATA FROM SCAQAL03ADM05VM01 FOR CRS USER TIME ZONE CHECK\n\n\n\nThu Aug 29 16:47:19 PDT 2024\n\n\nDATA FROM SCAQAL03ADM06VM01 FOR CRS USER TIME ZONE CHECK\n\n\n\nThu Aug 29 16:47:16 PDT 2024"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nClusterware deployment requirement\n\n\n\nRisk:\n\nPotential cluster instability\n\n\n\nAction / Repair:\n\nOracle Clusterware requires the same time zone setting on all cluster nodes. During installation, the installation process picks up the time zone setting of the Grid installation owner on the node where OUI runs, and uses that on all nodes as the default TZ setting for all processes managed by Oracle Clusterware. This default is used for databases, Oracle ASM, and any other managed processes.\n\nIf for whatever reason the time zones have gotten out of sync then the configuration should be corrected.\nConsult with Oracle Support about the proper method for correcting the time zones."}]}, {"id": "bc84ac5c-c0bf-4d51-b76a-b2e87dfe48c2", "checkCategory": "CLUSTER", "checkID": "9EC794D381B576B6E040E50A1EC004DC", "checkType": "CLUSTERWIDE_CHECK", "checkName": "Kernel version comparison across cluster", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "OS Kernel version (uname -r) matches across cluster."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - Kernel version comparison across cluster\n\n\n\n4.14.35-2047.516.2.4.el7uek.x86_64\n\nDATA FROM scaqal03adm06vm01 - Kernel version comparison across cluster\n\n\n\n4.14.35-2047.516.2.4.el7uek.x86_64"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nStability, Availability, Standardization\n\n\n\nRisk:\n\nPotential cluster instability due to kernel version mismatch on cluster nodes.\nIt is possible that if the kernel versions do not match that some incompatibility\ncould exist which would make diagnosing problems difficult or bugs fixed in the later kernel still being present on some nodes but not on others.\n\n\n\nAction / Repair:\n\nUnless in the process of a rolling upgrade of cluster node kernels it is assumed\nthat the kernel versions will match across the cluster.  If they do not then it is\nassumed that some mistake has been made and overlooked.  The purpose of\nthis check is to bring this situation to the attention of the customer for action and remedy."}]}, {"id": "08beb63f-3747-4406-bb81-39e2771ea2f3", "checkCategory": "CLUSTER", "checkID": "9EC85C05CBC08705E040E50A1EC029CF", "checkType": "CLUSTERWIDE_CHECK", "checkName": "Grid Infrastructure - Public interface name check (VIP)", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "Public network interface names are the same across cluster"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - Grid Infrastructure - Public interface name check (VIP)\n\n\n\nbondeth0  10.214.208.0  global  public\nre0  192.168.0.0  global  cluster_interconnect,asm\nre1  192.168.0.0  global  cluster_interconnect,asm\n\nDATA FROM scaqal03adm06vm01 - Grid Infrastructure - Public interface name check (VIP)\n\n\n\nbondeth0  10.214.208.0  global  public\nre0  192.168.0.0  global  cluster_interconnect,asm\nre1  192.168.0.0  global  cluster_interconnect,asm"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nStability, Availability, Standardization\n\n\n\nRisk:\n\nPotential application instability due to incorrectly named network interfaces used for node VIP.\n\n\n\nAction / Repair:\n\nThe Oracle clusterware expects and it is required that the network interfaces used for\nthe public interface used for the node VIP be named the same on all nodes of the cluster."}]}, {"id": "e2844d7b-2ee9-402a-9485-23b0ff929780", "checkCategory": "CLUSTER", "checkID": "9EC93390FB31FDD3E040E50A1EC04ADF", "checkType": "CLUSTERWIDE_CHECK", "checkName": "Grid Infrastructure - Private interconnect interface name check", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "Private interconnect interface names are the same across cluster"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - Grid Infrastructure - Private interconnect interface name check\n\n\n\nbondeth0  10.214.208.0  global  public\nre0  192.168.0.0  global  cluster_interconnect,asm\nre1  192.168.0.0  global  cluster_interconnect,asm\n\nDATA FROM scaqal03adm06vm01 - Grid Infrastructure - Private interconnect interface name check\n\n\n\nbondeth0  10.214.208.0  global  public\nre0  192.168.0.0  global  cluster_interconnect,asm\nre1  192.168.0.0  global  cluster_interconnect,asm"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nStability, Availability, Standardization\n\n\n\nRisk:\n\nPotential cluster or application instability due to incorrectly named network interfaces.\n\n\n\nAction / Repair:\n\nThe Oracle clusterware expects and it is required that the network interfaces used for\nthe cluster interconnect be named the same on all nodes of the cluster."}]}, {"id": "fabd7569-0571-4cfd-bd58-fc8bd39bf226", "checkCategory": "CLUSTER", "checkID": "9EC9684AE521FA71E040E50A1EC0441B", "checkType": "CLUSTERWIDE_CHECK", "checkName": "Timezone for current user", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "Timezone matches for current user across cluster."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - Timezone for current user\n\n\n\nThu Aug 29 16:49:45 PDT 2024\n\nDATA FROM scaqal03adm06vm01 - Timezone for current user\n\n\n\nThu Aug 29 16:49:23 PDT 2024"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nClusterware deployment requirement\n\n\n\nRisk:\n\nPotential cluster instability\n\n\n\nAction / Repair:\n\nOracle Clusterware requires the same time zone setting on all cluster nodes. During installation, the installation process picks up the time zone setting of the Grid installation owner on the node where OUI runs, and uses that on all nodes as the default TZ setting for all processes managed by Oracle Clusterware. This default is used for databases, Oracle ASM, and any other managed processes.\n\nIf for whatever reason the time zones have gotten out of sync then the configuration should be corrected.\nConsult with Oracle Support about the proper method for correcting the time zones."}, {"id": "34d08d04-db1d-4d87-85b3-b3e68db596e9", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1662018.1", "text": "Note: 1662018.1 - Oracle Sun Database Machine Cross Node Consistency Best Practice Checks"}]}]}, {"id": "8f8fcd9a-efb7-4291-93df-1901a464edfc", "checkCategory": "CLUSTER", "checkID": "DC28F0808B781B0EE04313C0E50A8416", "checkType": "CLUSTERWIDE_CHECK", "checkName": "Verify imageinfo on database server", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "Imageinfo matches across cluster on database servers"}, "children": [{"attr": {"consoleOutput": "\n\n\nDATA FROM SCAQAL03ADM05VM01 FOR VERIFY IMAGEINFO ON DATABASE SERVER\n\n\n\n22.1.6.0.0.221207\n\n\nDATA FROM SCAQAL03ADM06VM01 FOR VERIFY IMAGEINFO ON DATABASE SERVER\n\n\n\n22.1.6.0.0.221207"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Imageinfo output must match on all compute nodes across cluster."}, {"id": "2775b226-f8cd-4205-92e6-d20d37cb1e7d", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1662018.1", "text": "Note: 1662018.1 - Oracle Sun Database Machine Cross Node Consistency Best Practice Checks"}]}]}, {"id": "57f8b94d-3258-4c8a-a25f-6c3292e31dd1", "checkCategory": "CLUSTER", "checkID": "F0826F44876E588FE04312C0E50AD38A", "checkType": "CLUSTERWIDE_CHECK", "checkName": "Verify DNS config file consistency across database servers", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "DNS server config file matches across database servers"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - Verify DNS config file consistency across database servers\n\n\n\noptions timeout:4\noptions attempts:2\noptions rotate\nsearch us.oracle.com\nnameserver 10.31.138.25\nnameserver 206.223.27.1\nnameserver 206.223.27.2\n\nDATA FROM scaqal03adm06vm01 - Verify DNS config file consistency across database servers\n\n\n\noptions timeout:4\noptions attempts:2\noptions rotate\nsearch us.oracle.com\nnameserver 10.31.138.25\nnameserver 206.223.27.1\nnameserver 206.223.27.2"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "md5sum of /etc/resolv.conf must match on all database servers"}, {"id": "97c5e1e5-c492-45b9-9deb-bed38241757c", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1662018.1", "text": "Note: 1662018.1 - Oracle Sun Database Machine Cross Node Consistency Best Practice Checks"}]}]}, {"id": "e76449c7-0370-46d2-810a-2bfdd358db53", "checkCategory": "CLUSTER", "checkID": "F08405952A250A9DE04312C0E50AD4CC", "checkType": "CLUSTERWIDE_CHECK", "checkName": "Verify /etc/localtime file consistency across database servers", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "/etc/localtime matches across database servers"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - Verify /etc/localtime file consistency across database servers\n\n\n\ne82527606c69a9c53dc75063cc75b5af  /etc/localtime\n\nDATA FROM scaqal03adm06vm01 - Verify /etc/localtime file consistency across database servers\n\n\n\ne82527606c69a9c53dc75063cc75b5af  /etc/localtime"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "md5sum of /etc/localtime must match on all database servers"}, {"id": "56f41dd5-b875-4d76-8b04-48243a23a8bd", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1662018.1", "text": "Note: 1662018.1 - Oracle Sun Database Machine Cross Node Consistency Best Practice Checks"}]}]}, {"id": "f527a3e2-b5d0-48ab-aebf-a13a44b21ec4", "checkCategory": "CLUSTER", "checkID": "F08481DA1B2D3F72E04313C0E50A7B3E", "checkType": "CLUSTERWIDE_CHECK", "checkName": "Verify cellinit.ora config file consistency across database servers", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "cellinit.ora matches across database servers"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - Verify cellinit.ora config file consistency across database servers\n\n\n\nipaddress1=192.168.11.128/20\nipaddress2=192.168.11.129/20\n\nDATA FROM scaqal03adm06vm01 - Verify cellinit.ora config file consistency across database servers\n\n\n\nipaddress1=192.168.11.132/20\nipaddress2=192.168.11.133/20"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nmd5sum of cellinit.ora must match on all database servers.\n\n\nAction / Repair:\n\nUse following command on each database server and output must be same on all\n\nsed '/^(local_)*ipaddress/d;/^ *#/d' /etc/oracle/cell/network-config/cellinit.ora | tr -d ' \\t\\r\\f' | sort | awk 'NF' | md5sum"}, {"id": "a2df5069-2eb9-4aa3-bb5b-a598066442fb", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1662018.1", "text": "Note: 1662018.1 - Oracle Sun Database Machine Cross Node Consistency Best Practice Checks"}]}]}, {"id": "4a835c4b-c668-4258-b52f-93dbaff23d95", "checkCategory": "CLUSTER", "checkID": "F086120133332A4AE04313C0E50AF5F8", "checkType": "CLUSTERWIDE_CHECK", "checkName": "Clusterware software version comparison", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "Clusterware software version matches across cluster."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - Clusterware software version comparison\n\n\n\nOracle Clusterware version on node [scaqal03adm05vm01] is [21.0.0.0.0]\n\nDATA FROM scaqal03adm06vm01 - Clusterware software version comparison\n\n\n\nOracle Clusterware version on node [scaqal03adm06vm01] is [21.0.0.0.0]"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nStability, Availability, Standardization\n\n\n\nRisk:\n\nPotential cluster instability due to clusterware version mismatch on cluster nodes.\nIt is possible that if the clusterware versions do not match that some incompatibility\ncould exist which would make diagnosing problems difficult or bugs fixed in the\nlater clusterware version still being present on some nodes but not on others.\n\n\n\nAction / Repair:\n\nUnless in the process of a rolling upgrade of the clusterware it is assumed\nthat the clusterware versions will match across the cluster.  If they do not then it is\nassumed that some mistake has been made and overlooked.  The purpose of\nthis check is to bring this situation to the attention of the customer for action and remedy."}, {"id": "11a7e605-2109-47e6-b0bd-75805e60c899", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1662018.1", "text": "Note: 1662018.1 - Oracle Sun Database Machine Cross Node Consistency Best Practice Checks"}]}]}, {"id": "a00734a5-d521-4151-93fc-6d470faee8cd", "checkCategory": "ASM", "checkID": "DC3C01B138170E36E04313C0E50AC972", "checkType": "CROSS_NODE_CHECK", "checkName": "Verify ASM spfile value across instances", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "ASM instance spfile/init.ora files are consistent"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY ASM SPFILE VALUE ACROSS INSTANCES\n\n\n\n--------------------------------------------------------------------------------------------------------------------------------------------\n[Status:PASS]\n--------------------------------------------------------------------------------------------------------------------------------------------\n*) passes - asm\ninstance name:+ASM1                spfile:+DATAC1/ASM/ASMPARAMETERFILE/registry.253.1123542551         host:scaqal03adm05vm01\ninstance name:+ASM2                spfile:+DATAC1/ASM/ASMPARAMETERFILE/registry.253.1123542551         host:scaqal03adm06vm01\n--------------------------------------------------------------------------------------------------------------------------------------------"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nAll instances for a particular database or ASM cluster should be using the same spfile. Making changes to databases and ASM instances needs to be done in a reliable and consistent way across all instances.\n\n\n\nRisk:\n\nMultiple 'sources of truth' can cause confusion and possibly unintended values being set.\n\n\n\nAction / Repair:\n\nVerify what spfile is used across all instances of one particular ASM or database cluster. If multiple spfiles for one database are found, provide a recommendation to consolidate them into one.\nScope includes all machine types, os types and db versions\nSQL&gt; select name, value from gv$parameter where name = 'spfile';\n\nNAME                           VALUE\n------------------------------ ------------------------------------------------------------\nspfile                         +DATA/racone/spfileracone.ora\n\nThe value for pfile should be empty:\nSQL&gt; select name, value from gv$parameter where name = 'pfile';\n\nno rows selected"}]}, {"id": "605ca864-d9ae-4725-a24f-357bc72595f9", "checkCategory": "RDBMS", "checkID": "CFBC2ED33A5F4573E0431EC0E50ACECE", "checkType": "CROSS_NODE_CHECK", "checkName": "Verify database spfile value across instances", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "Database instance spfile/init.ora files are consistent"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY DATABASE SPFILE VALUE ACROSS INSTANCES\n\n\n\n--------------------------------------------------------------------------------------------------------------------------------------------\n[Status:PASS]\n--------------------------------------------------------------------------------------------------------------------------------------------\n*) passes - database:CDB1\ninstance name:CDB11                spfile:+DATAC1/CDB1/PARAMETERFILE/spfile.274.1123545223             host:scaqal03adm05vm01\ninstance name:CDB12                spfile:+DATAC1/CDB1/PARAMETERFILE/spfile.274.1123545223             host:scaqal03adm06vm01\n--------------------------------------------------------------------------------------------------------------------------------------------"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nAll instances for a particular database or ASM cluster should be using the same spfile. Making changes to databases and ASM instances needs to be done in a reliable and consistent way across all instances.\n\n\n\nRisk:\n\nMultiple 'sources of truth' can cause confusion and possibly unintended values being set.\n\n\n\nAction / Repair:\n\nVerify what spfile is used across all instances of one particular ASM or database cluster. If multiple spfiles for one database are found, provide a recommendation to consolidate them into one.\nScope includes all machine types, os types and db versions\nSQL&gt; select name, value from gv$parameter where name = 'spfile';\n\nNAME                           VALUE\n------------------------------ ------------------------------------------------------------\nspfile                         +DATA/racone/spfileracone.ora\n\nThe value for pfile should be empty:\nSQL&gt; select name, value from gv$parameter where name = 'pfile';\n\nno rows selected"}]}, {"id": "cd064f07-3e69-4517-810d-aa764481b890", "checkCategory": "HOST", "checkID": "F041115E50B322CBE053D198EB0AE2BC", "checkType": "CROSS_NODE_CHECK", "checkName": "Verify CPU configuration across all VMs in the cluster", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "The CPU configuration across all VMs in the cluster is correctly configured"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY CPU CONFIGURATION ACROSS ALL VMS IN THE CLUSTER\n\n\n\n\nSUCCESS:The CPU configuration across all VMs in the cluster is correctly configured:\n\n1) Checks for each node:\n\nSUCCESS:Node scaqal03adm05vm01 has CPU count 92.\nSUCCESS:Node scaqal03adm05vm01 has CPU socket count 2.\nSUCCESS:Node scaqal03adm05vm01 has NUMA node count 2.\n\n2) Checks across all nodes:\nSUCCESS:All nodes have the same and expected number of CPUs.\nSUCCESS:All nodes have the same and expected number of CPU sockets.\nSUCCESS:All nodes have the same and expected number of NUMA nodes."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nCPU configuration values need to be consistent across all nodes in the cluster to make sure performance is reliable and coherent. The total number of CPUs allocated to each node should be an even number. The NUMA nodes allocated for the VM needs to be two to make sure vNUMA features are enabled.\n\nRisk:\n\nInconsistent number of CPU allocations across the cluster nodes would result in unpredictable performance. If CPUs are not even or if there is only one NUMA node configured on the cluster node, performance could be severely impacted.\n\nAction / Repair:\n\nVerify CPU allocation values are consistent across all nodes. Make sure there are even number of CPUs allocated to the node. Validate there are two NUMA nodes. \n\nCorrect the CPU allocation values for cluster nodes if found to be inconsistent.\n\n\n    NOTE: If after corrective actions are completed, you wish to run just this review manually without a full Exachk run, as the \"root\" userid execute the following Exachk command:\n\n    exachk -check F041115E50B722CBE053D198EB0AE2BC,F041115E50B322CBE053D198EB0AE2BC\n\n"}]}, {"id": "4899b803-9ebc-4f97-a9fd-d384411f8590", "checkCategory": "CLUSTER", "checkID": "D4B38AE6B375AB2CE053D298EB0A4609", "checkType": "CROSS_NODE_CHECK", "checkName": "RDBMS software version comparison", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "RDBMS software version matches across cluster."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - RDBMS SOFTWARE VERSION COMPARISON\n\n\n\n----------------------------------------------------------------------------------------------------\n[Status:PASS] Message:RDBMS software versions matches across cluster.\n----------------------------------------------------------------------------------------------------\n*) passes - CDB1\nnode:scaqal03adm05vm01    instance_version:210000\nnode:scaqal03adm06vm01    instance_version:210000\n----------------------------------------------------------------------------------------------------"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nStability, Availability, Standardization\n\n\n\nRisk:\n\nPotential database or application instability due to version mismatch for database homes.\nIt is possible that if the versions of related RDBMS homes on all the cluster nodes do not\nmatch that some incompatibility could exist which would make diagnosing problems difficult\nor bugs fixed in the later RDBMS version still being present on some nodes but not on others.\n\n\n\nAction / Repair:\n\nIt is assumed that the RDBMS versions of related database homes will match across the cluster. \nIf the versions of related RDBMS homes do not match then it is assumed that some mistake has\nbeen made and overlooked.  The purpose of this check is to bring this situation to the attention\nof the customer for action and remedy."}, {"id": "d755c674-d4ff-4bb0-adf3-a4241146cf44", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1662018.1", "text": "Note: 1662018.1 - Oracle Sun Database Machine Cross Node Consistency Best Practice Checks"}]}]}, {"id": "e1d96b90-a847-41fd-acb0-cc826962fedd", "checkCategory": "HOST", "checkID": "D3D5FD75B15A3DECE053D598EB0A2513", "checkType": "CROSS_NODE_CHECK", "checkName": "RDBMS and GRID software owner UID across cluster", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "RDBMS and GRID software owner UID matches across cluster"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - RDBMS AND GRID SOFTWARE OWNER UID ACROSS CLUSTER\n\n\n\n----------------------------------------------------------------------------------------------------\n[Status:PASS] Message:RDBMS and GRID software owner UID matches across cluster\n----------------------------------------------------------------------------------------------------\n*) passes - /u01/app/21.0.0.0/grid - type:crs\nhost:scaqal03adm05vm01    owner:oracle               uid:1001\nhost:scaqal03adm06vm01    owner:oracle               uid:1001\n----------------------------------------------------------------------------------------------------\n*) passes - /u01/app/oracle/product/21.0.0.0/dbhome_1 - type:rdbms\nhost:scaqal03adm05vm01    owner:oracle               uid:1001\nhost:scaqal03adm06vm01    owner:oracle               uid:1001\n----------------------------------------------------------------------------------------------------"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nAvailability, Stability\n\nRisk:\n\nPotential OCR logical corruptions and permission problems accessing OCR keys when multiple O/S users share the same UID which are difficult to diagnose.\n\nAction / Repair:\n\nFor GI/CRS, ASM and RDBMS software owners ensure one unique user ID with a single name is in use across the cluster."}]}, {"id": "57ac6e4a-e40f-4057-8f21-f9db7abc59c1", "checkCategory": "CRS", "checkID": "BA02FDF02FB34B2AE053D298EB0A41BB", "checkType": "CROSS_NODE_CHECK", "checkName": "Verify patches in $ORACLE_HOMEs across database servers", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "All $ORACLE_HOMEs have same patches across database servers"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY PATCHES IN $ORACLE_HOMES ACROSS DATABASE SERVERS\n\n\n\n$ORACLE_HOME /u01/app/oracle/product/21.0.0.0/dbhome_1 has same list of applied patches across nodes\n\n\n$ORACLE_HOME /u01/app/21.0.0.0/grid|root|oinstall has same list of applied patches across nodes"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nFor a given grid infrastructure home or database home, unless performing rolling upgrade the installed patches should match across all database servers in the cluster.\n\nRisk:\n\nInconsistent patches across database servers may be the result of failed patching and may lead to inconsistent Oracle Clusterware and Database behavior. \n\nAction / Repair:\n\nCompare the output of this command across all database servers for each given Grid or Database home:\n$ opatch lsinventory -local | grep '^Patch' | grep -v '^Patch description'"}]}, {"id": "d36ab16a-22fc-4481-8b30-94945f2a6db8", "checkCategory": "HOST", "checkID": "8E55E0B24B89BD14E053D198EB0A3315", "checkType": "CROSS_NODE_CHECK", "checkName": "Verify all database and storage servers time server configuration", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "Time services are properly configured"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY ALL DATABASE AND STORAGE SERVERS TIME SERVER CONFIGURATION\n\n\n\nSUCCESS:time services are properly configured.\n\nscaqal03adm05vm01:SUCCESS:\tserver count: 3\tsynched server in conf: 1\ttimedrift:0\nscaqal03adm06vm01:SUCCESS:\tserver count: 3\tsynched server in conf: 1\ttimedrift:0"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nVerifying all database and storage servers time server configurations are as expected can help avoid issues such as impaired performance or node eviction.\n\nThe impact of verifying all database and storage servers time server configuration is minimal. The impact of making corrections varies depending upon the root cause of the difference. \n\nRisk:\n\nSignificant time drift on database and storage servers may cause unexpected storage server crashes or database server node evictions.\n\nAction / Repair:\n\n    NOTE: This check returns results based on the following criteria:\n\n    SUCCESS: only if the following are all true on each database or storage server:\n    1) There are one or more time servers specified in the configuration file (/etc/chrony.conf or /etc/ntp.conf).\n    2) Each storage or database server is synched with one of the set of available time sources in the configuration file.\n    3) The maximum time drift reported from the synched time source for each storage or database server is less than or equal to 1 second.\n\n    FAILURE:\n    1) There may or may not be one or more time servers specified in the configuration file (/etc/chrony.conf or /etc/ntp.conf).\n    2) Each storage or database server may or may not be synchronized with one of the set of available time sources in the configuration file.\n    3) The maximum time drift reported from the synched time source for each storage or database server is greater than 1 second.\n\n    WARNING:\n    1) Any detected condition other than \"SUCCESS\": or \"FAILURE:\".\n\nTo verify all database and storage servers time server configuration, run Exachk and review the provided report.\n\nThe expected output in the Exachk report should be as follows:\n\nIn the \"Cluster Wide\" section of the report, the overall result should be \"PASS\":\n\nPASS   All database and storage servers time server configuration is as expected  Cluster Wide   View\n\nIn the \"View\" detail section of the report for this check the expected output should be similar to:\n\nStatus on Cluster Wide:\nPASS =&gt; Time services are properly configured\n\nDATA FROM RANDOM05ADM05 - VERIFY ALL DATABASE AND STORAGE SERVERS TIME SERVER CONFIGURATION \n\nSUCCESS: time services are properly configured.\n\nIn the \"View\" detail section of the report for this check a \"FAILURE\" example will be similar to:\n\nFAILURE: time services are not properly configured.  Details:\n\n\nrandomadm05: FAILURE: server count:  1        synched server in conf:  1      timedrift: 2\nrandomceladm07: FAILURE:      server count:  0        synched server in conf:  1      timedrift: 0\nrandomceladm08: FAILURE:      server count:  1        synched server in conf:  0      timedrift: 0\n\n    NOTE: A \"FAILURE\" result prints the gathered data from the cluster to help identify the issue.\n    NOTE: This configuration failed because\n    1) randomadm05 timedrift is too high.\n    2) randomceladm07 has no servers defined in the configuration file.\n    3) randomceladm08 is not synchronized to at least one server defined in the configuration file. \n\nIf the result is not as expected, investigate for root cause and take appropriate corrective action.\n\n    NOTE: If after corrective actions are completed, you wish to run this one check without a full Exachk run execute the following command as the \"root\" userid in the directory in which Exachk was installed:\n\n    ./exachk -check 85C96EAB566F8F13E053D498EB0AE6F1,85C9BA643125E253E053D598EB0A6D07,8E55E0B24B89BD14E053D198EB0A3315"}]}, {"id": "3ea7bd3d-e2de-47b4-ba94-e1d38004c2f3", "checkCategory": "CLUSTER", "checkID": "8955120D63FCAC2DE040E50A1EC006CA", "checkType": "CROSS_NODE_CHECK", "checkName": "Clusterware version comparison", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "Clusterware active version matches across cluster."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - CLUSTERWARE VERSION COMPARISON\n\n\n\nscaqal03adm05vm01.CRS_ACTIVE_VERSION = 21.0.0.0.0\nscaqal03adm06vm01.CRS_ACTIVE_VERSION = 21.0.0.0.0"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nStability, Availability, Standardization\n\n\n\nRisk:\n\nPotential cluster instability due to clusterware version mismatch on cluster nodes.\nIt is possible that if the clusterware versions do not match that some incompatibility\ncould exist which would make diagnosing problems difficult or bugs fixed in the\nlater clusterware version still being present on some nodes but not on others.\n\n\n\nAction / Repair:\n\nUnless in the process of a rolling upgrade of the clusterware it is assumed\nthat the clusterware versions will match across the cluster.  If they do not then it is\nassumed that some mistake has been made and overlooked.  The purpose of\nthis check is to bring this situation to the attention of the customer for action and remedy."}, {"id": "bac174fe-4bd5-4c3a-bbca-9db1d11ab755", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1662018.1", "text": "Note: 1662018.1 - Oracle Sun Database Machine Cross Node Consistency Best Practice Checks"}]}]}, {"id": "7b439c84-7f90-4295-870b-73c4b2410219", "checkCategory": "HOST", "checkID": "5D691B1A8146F67CE053D398EB0A8822", "checkType": "CROSS_NODE_CHECK", "checkName": "Verify the storage servers in use configuration matches across the cluster", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "The storage servers in use configuration matches across the cluster"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY THE STORAGE SERVERS IN USE CONFIGURATION MATCHES ACROSS THE CLUSTER\n\n\n\n\nSUCCESS:The storage servers in use configuration matches:\n-\nDBSRVR:\t\t\tscaqal03adm05vm01\nDBSRVR_CELLIP_MD5SUM:\tf5d6e0ee98547b6d6b6b9d1e6442dfa5\nDBSRVR_KFOD_MD5SUM:\tf5d6e0ee98547b6d6b6b9d1e6442dfa5\nDBSRVR_BASE_MD5SUM:\tf5d6e0ee98547b6d6b6b9d1e6442dfa5"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nVerifying the storage servers in use configuration matches across the cluster can prevent potential issues ranging from impaired performance to a node eviction.\n\nThe impact of verifying the storage servers in use configuration matches across the cluster. The impact of making corrections varies depending upon the root cause of the difference. \n\nRisk:\n\nIf the storage servers in use configuration does not match across the cluster, there is risk of impaired performance, node eviction, and perhaps data loss with multiple hardware failures over time.\n\nAction / Repair:\n\nNOTE: This check will only pass if the following are both true:\n1) For each database server, the md5sum for the cellip.ora file matches the md5sum from the list of storage servers accessed by kfod.\n2) The md5sum from 1) matches across the cluster.\n\nTo verify the storage servers in use configuration matches across the cluster, run Exachk and review the provided report.\n\nThe expected output in the Exachk report should be as follows:\n\nIn the \"Cluster Wide\" section of the report, the overall result should be \"PASS\":\n\nPASS   Cluster Wide Check   The storage servers in use configuration matches across the cluster   Cluster Wide   View\n\nIn the \"View\" detail section of the report for this check the expected output should be similar to:\n\nSUCCESS: The storage servers in use configuration matches:\n-\nDBSRVR:                 busm01client01\nDBSRVR_CELLIP_MD5SUM:   d2144e88f4249a5d267691b85ed2ae49\nDBSRVR_KFOD_MD5SUM:     d2144e88f4249a5d267691b85ed2ae49\nDBSRVR_BASE_MD5SUM:     d2144e88f4249a5d267691b85ed2ae49\n-\nDBSRVR:                 busm01client02\nDBSRVR_CELLIP_MD5SUM:   d2144e88f4249a5d267691b85ed2ae49\nDBSRVR_KFOD_MD5SUM:     d2144e88f4249a5d267691b85ed2ae49\nDBSRVR_BASE_MD5SUM:     d2144e88f4249a5d267691b85ed2ae49\n\nA \"FAILURE\" example:\n\nIn the \"Cluster Wide\" section of the report, the overall result will be \"FAIL\":\n\nFAIL    Cluster Wide Check   The storage servers in use configuration should match across the cluster   Cluster Wide   View\n\nIn the \"View\" detail section of the report for this check the expected output should be similar to:\n\nFAILURE: The storage servers in use configuration does not match:\n-\nDBSRVR:                 randomadm01vm01\nDBSRVR_CELLIP_MD5SUM:   acd6ad6d153ea1ec1ecf9a5aa19cf4a7\nDBSRVR_KFOD_MD5SUM:     d41d8cd98f00b204e9800998ecf8427e\nDBSRVR_BASE_MD5SUM:     acd6ad6d153ea1ec1ecf9a5aa19cf4a7\n-\nDBSRVR:                 randomadm02vm01\nDBSRVR_CELLIP_MD5SUM:   acd6ad6d153ea1ec1ecf9a5aa19cf4a7\nDBSRVR_KFOD_MD5SUM:     d41d8cd98f00b204e9800998ecf8427e\nDBSRVR_BASE_MD5SUM:     acd6ad6d153ea1ec1ecf9a5aa19cf4a7\n\n    NOTE: In the \"FAILURE:\" example, the md5sum for the results reported from kfod on the running system does not match the cellip.ora md5sum. \n\nIf the result is not as expected, investigate for root cause and take appropriate corrective action.\n\n    NOTE: If after corrective actions are completed, you wish to run this one check without a full Exachk run execute the following command as the \"root\" userid in the directory in which Exachk was installed:\n\n    ./exachk -check 5D6AC87BF4669BF2E053D498EB0AFC19,5D691B1A8146F67CE053D398EB0A8822"}, {"id": "110b5004-6e76-4499-8af7-465c149969b7", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=888828.1", "text": "Note: 888828.1 - \tDatabase Machine and Exadata Storage Server 11g Release 2 (11.2) Supported Versions"}]}]}, {"id": "62f61ba3-a8c2-446c-9eea-4c96400a53ab", "checkCategory": "ASM", "checkID": "21E9A0B8216D11FBE0530A98EB0A859E", "checkType": "CROSS_NODE_CHECK", "checkName": "Verify ASM Operations are not blocked by the Clusterware State", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "ASM Operations are not blocked by the Clusterware State"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY ASM OPERATIONS ARE NOT BLOCKED BY THE CLUSTERWARE STATE\n\n\n\nThe clusterware state is:normal"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThe benefit of this check is that it ensures all normal ASM operations work seamlessly regardless of Clusterware state.\n\nRisk:\n\nThe risk of a failure in this check is that certain ASM operations cannot run.  More specifically, without the specific Grid Infrastrcuture version and parameter configuration detailed below, the following ASM operations will be prevented if the Clusterware is not in a \"Normal\" state.\nUser invoked disk operations (ex: add, drop, replace, online, offline, undrop, resize, expel), Create/Drop Diskgroup,  \nRebalance, Voting File Creation/Deletion, Advancing compatibility, SP file parameter add/change/remove, Create/Drop ADVM volume.\n\nNote: Two other possible Clusterware states are \"In Rolling Patch\" and \"In Rolling Upgrade\".  These should only be present when an active software update or patching exercise is in progress.\n\nAction / Repair:\n\nThe following pseudo code code snippet gives an idea of the logic used for this check.  This assumes GI version 19.15 or higher is in place.  Also to enable the most ASM operations, the fix for bug 34038365 should also be in place.\n\nIf (Clusterware state is normal)\n  then PASS\nelse if (Clusterware state=\"In Rolling Patch\") and (_ksxp_allow_ksxr_rolling_migration parameter=TRUE in all ASM instances in the cluster)\n  then PASS\nelse\n  FAIL\n\nTo run the check:\nexachk -check 21E9A0B8216D11FBE0530A98EB0A859E,DEACC5A8C0567285E053D398EB0A5282"}, {"id": "6f98f89e-697e-45dd-a810-95d3eb798bbe", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=2522649.1", "text": "Note: 2522649.1 - The Cluster Upgrade State is [UPGRADE FINAL] After Successful Upgrade of Grid Infrastructure"}]}]}, {"id": "4de04e58-1874-49f4-95c6-ce9fa2eb55b9", "checkCategory": "CRS", "checkID": "18A3409546FFBBCFE0639712F50A46F1", "checkType": "CROSS_NODE_CHECK", "checkName": "Verify clusterware internal patch metadata matches grid home OPatch inventory", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "Cluster Wide", "status": "success", "statusLabel": "PASS", "output": "List of patches match between OPatch inventory and kfod"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY CLUSTERWARE INTERNAL PATCH METADATA MATCHES GRID HOME OPATCH INVENTORY\n\n\n\n----------------------------------------------------------------------------------------------------\n[Status:PASS] Message:\n----------------------------------------------------------------------------------------------------\nPatch validation:\n\n*) passes - CRS Patches matches across all nodes.\n\n*) passes - KFOD Patches matches across all nodes.\n\n*) passes - Patch level matches across all nodes.\n\n----------------------------------------------------------------------------------------------------\n*) hostname             :scaqal03adm05vm01\nPatch level is       :260588894\nThe cluster state is :NORMAL\nPatch comparison     :passes - GRID home OPatch patches list and KFOD patches list match as expected.\n----------------------------------------------------------------------------------------------------\n*) hostname             :scaqal03adm06vm01\nPatch level is       :260588894\nThe cluster state is :NORMAL\nPatch comparison     :passes - GRID home OPatch patches list and KFOD patches list match as expected.\n----------------------------------------------------------------------------------------------------"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nDuring normal patch apply, clusterware internal patch metadata is automatically maintained. This check validates that the process occurred correctly.\n\nRisk:\n\nIf the internal patch metadata at Oracle Cluster Registry (OCR) level is not in sync, and the clusterware is not in 'ROLLING PATCH' state then the newly joining node will not be able to join the cluster, as the Cluster Ready Services daemon (CRSD) process will not be able to start on the newly patched node or the node where the patch metadata is not in sync with the OCR.\n\nWhen OHASD is not able to start:\n    We see the following verbose message on the console - \"CRS-6706: Oracle Clusterware Release patch level ('&lt;version no&gt;') does not match Software patch level ('&lt;version no&gt;'). Oracle Clusterware cannot be started.\"\n\nWhen CRSD is not able to start, below error messages will be observed:\n    CRS alert log will report - \"CRS-2771: Maximum restart attempts reached for resource 'ora.crsd'; will not restart.\"\n    CRSD trace will state - \"Patch Levels don't match. Local Patch Level ['&lt;patch level number&gt;'] != Cache Writer Patch Level ['&lt;patch level number&gt;']\"\n\nAction / Repair:\n\nCheck to make sure if internal metadata patch level at the OCR level matches across all nodes using the command\n    &lt;CRS_HOME&gt;/bin/kfod op=patchlvl\nIf there is a mismatch in the metadata of the OCR patch level, then check the cluster upgrade state using command\n    &lt;CRS_HOME&gt;/bin/crsctl query crs activeversion -f\n\nIf cluster upgrade state is ROLLING PATCH, then the output would look as below:\n    Oracle Clusterware active version on the cluster is [&lt;version no&gt;]. The cluster upgrade state is [ROLLING PATCH]. The cluster active patch level is [&lt;version no&gt;].\n\nIf cluster upgrade state is NORMAL, then the output would look as below:\n    Oracle Clusterware active version on the cluster is [&lt;version no&gt;]. The cluster upgrade state is [NORMAL]. The cluster active patch level is [&lt;version no&gt;].\n\nIf cluster upgrade state is ROLLING PATCH, a mismatch of the patch metadata at the OCR level is expected.\nIf cluster upgrade state is NORMAL, a mismatch of the patch metadata at the OCR level is not expected and thus one will face the issue of CRSD not starting.\n\nTo help with corrective action in case of check failure, please contact Oracle Support.\n\nNote: Once the issue has been resolved, if you wish to validate this check individually, run the following command\n    exachk -check 18A3409546FFBBCFE0639712F50A46F1"}, {"id": "0cac431b-bc44-4115-81bc-93bb20286f19", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= &id=1639285.1", "text": "Note: 1639285.1 - CRS-6706: Oracle Clusterware Release patch level ('nnn') does not match Software patch level ('mmm')"}]}]}]}]}, {"sectionId": "7717a20d-0780-450f-af97-aa49f8ad61da", "sectionName": "Security", "subsection": [{"subSectionName": "Database Server", "checksList": [{"id": "3084ba27-128b-4748-9eb8-f26262549b0a", "checkCategory": "HOST", "checkID": "9EC7304AE678DC2DE040E50A1EC07772", "checkType": "OS_OUT_CHECK", "checkName": "SELinux status", "checkStatus": "INFO", "status": "info", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "info", "statusLabel": "INFO", "output": "AHF-1789: SELinux configuration is not as expected"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR SELINUX STATUS\n\n\n\nINFO:SELinux is disabled.\n\nDetails:\n\nSELinux configuration status:disabled."}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "info", "statusLabel": "INFO", "output": "AHF-1789: SELinux configuration is not as expected"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR SELINUX STATUS\n\n\n\nINFO:SELinux is disabled.\n\nDetails:\n\nSELinux configuration status:disabled."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nIn Oracle Cloud Infrastructure (OCI) Government and National Security regions, SELinux is required to be configured in \"enforcing\" mode. For OCI Commercial regions and Exadata on-premises, SELinux is recommended in \"permissive\" mode. The system administrator must be aware of the SELinux status and take action depending on the system type and / or Cloud region. Additionally, if Access Vector Cache (AVC) denials were triggered by SELinux, corresponding actions must be taken to prevent unexpected system behavior.\n\nNote: More information related to SELinux capabilities and importance for system security can be found in the following documentation: Oracle Linux Administering SELinux (https://docs.oracle.com/en/operating-systems/oracle-linux/8/).\n\n\n\nRisk:\n\nIf SELinux is disabled, unauthorized access events are not recorded and the system administrator cannot use them for maintenance and security operations. On the other hand, if SELinux is enabled and the system policy is not updated and properly maintained, SELinux could block critical access to system processes and trigger unexpected system behavior. Additionally, in Exadata systems where SELinux is required in enforcing mode, not having SELinux properly configured would mean the system failing to comply with legally required functionality.\n\n\n\nAction / Repair:\n\nIn Exadata database nodes and storage servers, depending on the system type and legal requirements, SELinux must be configured in \"permissive\" or \"enforcing\" mode. Additionally, all the system AVC denials generated by SELinux must be reviewed and attended.\n\nIf SELinux is disabled, execute the following command (use appropriate mode, depending on system type and requirements):\n    /opt/oracle.cellos/host_access_control selinux &lt; --permissive | --enforcing &gt;\n\nNote: Before using the \"--enforcing\" option, it is recommended to test the system performance and access event blocking with the \"--permissive\" option.\n\n\nFor all the system executables flagged, execute the following command to understand why the denial was triggered, what the executable is requiring and how it can be fixed:\n    ausearch -i -m avc -x &lt;/path/to/system/executable&gt; | audit2allow [options]\n\nNote: Verify the SELinux system policy is updated not to block access for necessary system functionality.\n\n\nThe AVC denials are persistent audit entries. A 7-day period of denials is collected for analysis, if corresponding fixes have been applied ignore related findings.\n\nUse the following command to collect denials from past dates:\n    ausearch -i -m avc --start [start date] [start time]\n\nUse the following command to collect all AVC denials present in /var/log/audit/audit.log:\n    ausearch -i -m avc\n\n\n\nNote: More information related to SELinux usage in Exadata systems can be found in section 2.1 (Using Security-Enhanced Linux) of the \"Security Guide for Oracle Exadata\".\n\n\nNote: Once the issue has been resolved, if you wish to validate this Exachk check individually, you may run the following command as \"root\" user:\n\n    # exachk -showpass -check 9EC7304AE678DC2DE040E50A1EC07772"}]}, {"id": "198f3fbf-448e-47b7-a0a8-da43163252d3", "checkCategory": "HOST", "checkID": "037DBC37B8C06095E0639712F50A4FF6", "checkType": "OS_OUT_CHECK", "checkName": "Verify DSA authentication is not supported for SSH equivalency", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "DSA authentication is not found for inbound and/or outbound SSH connectivity"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR VERIFY DSA AUTHENTICATION IS NOT SUPPORTED FOR SSH EQUIVALENCY\n\n\n\nSUCCESS:DSA authentication is not found for inbound and/or outbound SSH connectivity."}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "DSA authentication is not found for inbound and/or outbound SSH connectivity"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR VERIFY DSA AUTHENTICATION IS NOT SUPPORTED FOR SSH EQUIVALENCY\n\n\n\nSUCCESS:DSA authentication is not found for inbound and/or outbound SSH connectivity."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nDSA (Digital Signature Algorithm) is considered insecure and should not be used as an authentication mechanism, hence DSA keys must not exist for any operating system user. Additionally, the operating system crypto policy must not contain options and/or configuration allowing DSA key-based authentication for inbound or outbound connectivity. \n\nRisk:\n\nBeginning with Exadata 23.1 (Oracle Linux 8), by default, all inbound and outbound connections attempting DSA authentication are blocked at the operating system level. Under these circumstances, utilities and services requiring key-based authentication will be negatively impacted if they solely rely on DSA support. Using DSA authentication may cause automation tasks failures, increase the attack surface of a system and/or facilitate unauthorized access.\n\nAction / Repair:\n\nIn Exadata database nodes and storage servers, system users must not own a DSA key-pair, nor allow inbound SSH connectivity authenticated via DSA keys. Additionally, the system crypto policy must not contain any DSA cipher that may be used by system processes or services.\n\n    If any system user owns a DSA key-pair, perform the following steps:\n        Remove the public component of the key\n\n        rm -f &lt;/path/key.pub&gt;\n\n        Remove the private component of the key\n\n        rm -f &lt;/path/key.pub&gt;\n\n\n        Create a new RSA key-pair\n        NOTE: Detailed steps on how to identify DSA keys and generate RSA keys (recommended for key-based authentication) may be found in \"How to setup RSA SSH equivalence on Oracle Exadata nodes (Doc ID 2923095.1)\".\n\n    If DSA authentication is allowed for inbound SSH connectivity, perform the following steps on every authorization file flagged:\n        Open the authorization file\n        Remove all entries beginning with \"ssh-dss\"\n        Save the changes and close the authorization file.\n    If DSA support is enabled in the system crypto policy, perform one of the following strategies:\n        Use the Oracle Linux 8 default crypto policy\n            Execute the following command\n\n            update-crypto-policies --set DEFAULT\n\n            Restart the system to apply changes\n\n            reboot\n\n        Enable FIPS mode\n            Execute the following command\n\n            /opt/oracle.cellos/host_access_control fips-mode --enable\n\n            Restart the system to apply changes\n\n            reboot\n\n\nNote: Once the issue has been resolved, if you wish to validate this Exachk check individually, you may run the following command as \"root\" user:\n\n    exachk -showpass -check 037DBC37B8C06095E0639712F50A4FF6"}]}, {"id": "a8a1c3d6-750e-49f8-95fb-8a216540a772", "checkCategory": "RDBMS HOME", "checkID": "0536266F8A1D8579E0639D12F50A79B6", "checkType": "OS", "checkName": "Validate network configuration files in RDBMS homes", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:/u01/app/oracle/product/21.0.0.0/dbhome_1", "status": "success", "statusLabel": "PASS", "output": "Network configuration files in Oracle Database Home are valid."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - /u01/app/oracle/product/21.0.0.0/dbhome_1 DATABASE_HOME - Validate network configuration files in RDBMS homes\n\n\n\nSTATUS             :FILE PATH\n========================================================\nFile does not exist:/u01/app/oracle/product/21.0.0.0/dbhome_1/network/admin/tnsnames.ora\nFile Verified OK:   /u01/app/oracle/product/21.0.0.0/dbhome_1/network/admin/sqlnet.ora"}}]}, {"attr": {"target": "scaqal03adm06vm01:/u01/app/oracle/product/21.0.0.0/dbhome_1", "status": "success", "statusLabel": "PASS", "output": "Network configuration files in Oracle Database Home are valid."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - /u01/app/oracle/product/21.0.0.0/dbhome_1 DATABASE_HOME - Validate network configuration files in RDBMS homes\n\n\n\nSTATUS             :FILE PATH\n========================================================\nFile does not exist:/u01/app/oracle/product/21.0.0.0/dbhome_1/network/admin/tnsnames.ora\nFile Verified OK:   /u01/app/oracle/product/21.0.0.0/dbhome_1/network/admin/sqlnet.ora"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThis check validates tnsnames.ora and sqlnet.ora for syntax issues in Oracle Database Home. Please review any identified issues and address them.\n\nRisk:\n\nIncorrect configuration could cause database connectivity issues.\n"}]}, {"id": "2958dc56-d1e7-4e61-aec8-f7b206fdcc98", "checkCategory": "CRS HOME", "checkID": "D6844924CC71C249E053D198EB0ABF37", "checkType": "OS", "checkName": "Validate network configuration files", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Network configuration files in Oracle Grid Infrastructure Home are valid."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VALIDATE NETWORK CONFIGURATION FILES\n\n\n\nSTATUS             :FILE PATH\n========================================================\nFile Verified OK:   /u01/app/21.0.0.0/grid/network/admin/listener.ora\nFile does not exist:/u01/app/21.0.0.0/grid/network/admin/tnsnames.ora\nFile Verified OK:   /u01/app/21.0.0.0/grid/network/admin/sqlnet.ora"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Network configuration files in Oracle Grid Infrastructure Home are valid."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - VALIDATE NETWORK CONFIGURATION FILES\n\n\n\nSTATUS             :FILE PATH\n========================================================\nFile Verified OK:   /u01/app/21.0.0.0/grid/network/admin/listener.ora\nFile does not exist:/u01/app/21.0.0.0/grid/network/admin/tnsnames.ora\nFile Verified OK:   /u01/app/21.0.0.0/grid/network/admin/sqlnet.ora"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThis check validates tnsnames.ora, sqlnet.ora and listener.ora for syntax issues in GI Home. Please review any identified issues and address them.\n\nRisk:\n\nIncorrect configuration could cause database connectivity issues.\n"}]}]}]}, {"sectionId": "c8613e51-a95b-48f8-b255-8d16bd3a58c8", "sectionName": "MAA Scorecard", "subsection": [{"subSectionName": "MAA Scorecard", "checksList": [{"id": "c016f3e1-9611-42e2-87f2-ca12bea27d29", "checkCategory": "RDBMS", "checkID": "AE071F58E61C18F0E040E50A1EC01EA8", "checkType": "OS", "checkName": "Database init parameter DB_BLOCK_CHECKING on primary", "checkStatus": "FAIL", "status": "danger", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "danger", "statusLabel": "FAIL", "output": "AHF-2715: Database parameter DB_BLOCK_CHECKING on primary is not set to the recommended value."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Database init parameter DB_BLOCK_CHECKING on primary\n\n\n\nDB_BLOCK_CHECKING = FALSE"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "danger", "statusLabel": "FAIL", "output": "AHF-2715: Database parameter DB_BLOCK_CHECKING on primary is not set to the recommended value."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Database init parameter DB_BLOCK_CHECKING on primary\n\n\n\nDB_BLOCK_CHECKING = FALSE"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nInitially db_block_checking is set to off due to potential performance impact. Performance testing is particularly important given that overhead is incurred on every block change. Block checking typically causes 1% to 10% overhead, but for update and insert intensive applications (such as Redo Apply at a standby database) the overhead can be much higher. OLTP compressed tables also require additional checks that can result in higher overhead depending on the frequency of updates to those tables. Workload specific testing is required to assess whether the performance overhead is acceptable.\n\n\n\nRisk:\n\nIf the database initialization parameters are not set as recommended, a variety of issues may be encountered, depending upon which initialization parameter is not set as recommended, and the actual set value.\n\n\n\nAction / Repair:\n\nBased on performance testing results set the primary or standby database to either medium or full depending on the impact. If performance concerns prevent setting DB_BLOCK_CHECKING to either FULL or MEDIUM at a primary database, then it becomes even more important to enable this at the standby database. This protects the standby database from logical corruption that would be undetected at the primary database.\nFor higher data corruption detection and prevention, enable this setting but performance impacts vary per workload.Evaluate performance impact.\n"}, {"id": "f4a9b0c9-1708-4117-b277-1fb455023c4c", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=1302539.1", "text": "Note: 1302539.1 - Best Practices for Corruption Detection, Prevention, and Automatic Repair - in a Data Guard Configuration"}, {"hyperlink": "http://download.oracle.com/docs/cd/E11882_01/server.112/e10803/config_db.htm#HABPT4827", "text": "Protect Against Data Corruption"}]}]}, {"id": "a4f6762a-a139-4c8a-8e07-39667fd27556", "checkCategory": "RDBMS", "checkID": "B09D194B9AEF0F10E0431EC0E50ADE87", "checkType": "SQL", "checkName": "Flashback database on primary", "checkStatus": "FAIL", "status": "danger", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "danger", "statusLabel": "FAIL", "output": "AHF-1918: Flashback on primary is not configured"}, "children": [{"attr": {"consoleOutput": "\n\n'FLASHBACKSTATUS='||UPPER(FLASHBACK_ON)\n---------------------------------------\nFlashback status = NO"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Oracle Flashback Technology enables fast logical failure repair. Oracle recommends that you use automatic undo management with sufficient space to attain your desired undo retention guarantee, enable Oracle Flashback Database, and allocate sufficient space and I/O bandwidth in the fast recovery area.  Application monitoring is required for early detection.  Effective and fast repair comes from leveraging and rehearsing the most common application specific logical failures and using the different flashback features effectively (e.g flashback query, flashback version query, flashback transaction query, flashback transaction, flashback drop, flashback table, and flashback database, and 12.2 flashback pluggable database (PDB)).\n\nKey HA Benefits:\n<ul>\n<li>With application monitoring and rehearsed repair actions with flashback technologies, application downtime can reduce from hours and days to the time to detect the logical inconsistency.</li>\n<li>Fast repair for logical failures caused by malicious or accidental DML or DDL operations.</li>\n<li>Effect fast point-in-time repair at the appropriate level of granularity: transaction, table, pluggable database, or database.</li></ul>\nQuestions that need to be addressed by your application and operations team:\n<ol>\n<li>Can your application or monitoring infrastructure detect logical inconsistencies?</li>\n<li>Is your operations team prepared to use various flashback technologies to repair quickly and efficiently?</li>\n<li>Is security practices enforced to prevent unauthorized privileges that can result logical inconsistencies?</li>\n</ol>"}, {"id": "ccac3927-a064-457f-9043-dab617942eb1", "title": "Links", "links": [{"hyperlink": "http://download.oracle.com/docs/cd/E11882_01/server.112/e10803/config_db.htm#BGBFJGCI", "text": "HABP: Chapter 5.1.4: Enable Flashback Database in 11gR2"}]}]}, {"id": "0ac03af5-2e2d-4f46-b3d9-152c48028f57", "checkCategory": "RDBMS", "checkID": "CD4D51B78F692408E0431EC0E50A3077", "checkType": "SQL", "checkName": "Primary database protection with Data Guard", "checkStatus": "FAIL", "status": "danger", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "danger", "statusLabel": "FAIL", "output": "AHF-2682: Primary database is not protected with Data Guard (standby database) for real-time data protection and availability"}, "children": [{"attr": {"consoleOutput": "\n\nQuery returned no rows."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Active Data Guard is the real-time data protection and availability solution that eliminates single point of failure by maintaining one or more synchronized physical replicas of the production database. If an unplanned outage of any kind impacts the production database, applications and users can quickly failover to a synchronized standby, minimizing downtime and preventing data loss. An Active Data Guard standby can be used to offload read-only applications, ad-hoc queries, and backups from the primary database or be dual-purposed as a test system at the same time it provides disaster protection. An Active Data Guard standby can also be used to minimize downtime for planned maintenance when upgrading to new Oracle Database patch sets and major database releases and for select migrations.  \n \nFor zero data loss protection and fastest recovery time, deploy a local Data Guard standby database with Data Guard Fast-Start Failover and integrated client failover. For protection against outages impacting the entire data center, or a broad geography, deploy a Data Guard standby database at a remote location. Oracle 12c Far Sync Standby can achieve zero data loss protection across Wide Area Network or across regions.\n\nKey HA Benefits:\n<ul>\n<li>Active Data Guard provides optimal data protection by using physical replication and comprehensive Oracle validation to maintain an exact byte-for-byte copy of the primary database that can be open read-only to offload reporting, ad-hoc queries and backups.</li>\n<li>With Oracle 11g release 2 and higher Active Data Guard and real time apply, data block corruptions can be repaired automatically and downtime can be reduced from hours and days of application impact to zero downtime with zero data loss.</li>\n<li>With MAA best practices, Data Guard Fast-Start Failover and integrated client failover, downtime from database, cluster and site failures can be reduced from hours to days to seconds.</li>\n<li>With remote standby database (Disaster Recovery Site), you have protection from complete site failures.</li>\n<li>In all cases, the Active Data Guard instances can be active and used for other activities.</li>\n<li>Data Guard can reduce risks and downtime for planned maintenance activities by using Database rolling upgrade with transient logical standby or DBMS rolling, standby-first patch apply and database migrations.</li>\n<li>For other advanced replication requirements where read-write access to a replica database is required while it is being synchronized with the primary database see Oracle GoldenGate logical replication. Oracle GoldenGate can be used to support heterogeneous database platforms and database releases, an effective read-write full or subset logical replica and to reduce or eliminate downtime for application, database or system changes. Oracle GoldenGate flexible logical replication solution's main trade-off is the additional administration for application developer and database administrators.</li>\n</ul>"}, {"id": "2d28b72f-4015-42b5-bf0b-9c6045e47d4e", "title": "Links", "links": [{"hyperlink": "http://www.oracle.com/us/products/middleware/data-integration/resources/index.html", "text": "Goldengate resources"}, {"hyperlink": "http://docs.oracle.com/cd/E11882_01/server.112/e10803/config_dg.htm", "text": "HABP: Chapter 9: Configuring Oracle Data Guard 11gR2"}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=1265700.1", "text": "Note: 1265700.1 - Oracle Patch Assurance - Data Guard Standby-First Patch Apply"}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=1302539.1", "text": "Note: 1302539.1 - Best Practices for Corruption Detection, Prevention, and Automatic Repair - in a Data Guard Configuration"}, {"hyperlink": "http://www.oracle.com/technetwork/database/features/availability/maa-wp-dr-dbm-130065.pdf", "text": "Oracle Data Guard: Disaster  Recovery for Oracle Exadata Database Machine"}]}]}, {"id": "14a9b696-9262-4f65-91ff-b76bfef7e500", "checkCategory": "RDBMS", "checkID": "E351523AC25874A6E04313C0E50A946C", "checkType": "SQL", "checkName": "Verify the Fast Recovery Area (FRA) has reclaimable space", "checkStatus": "FAIL", "status": "danger", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "danger", "statusLabel": "FAIL", "output": "AHF-2929: FRA space management problem file types are present without an RMAN backup completion within the last 7 days"}, "children": [{"attr": {"consoleOutput": "\n\nFILE_TYPE    NUMBER_OF_FILES\n------------ ---------------\nARCHIVED LOG              80"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nOracle's Fast Recovery Area (FRA) manages archivelog files, flashback logs, and Oracle Recovery Manager (RMAN) backups. Before RMAN's space management can clean up files according to your configured retention and deletion policies, the database needs to be backed up periodically with RMAN. Without this RMAN backup information, the FRA space management function will not have any reclaimable space and thus you can run out of space resulting in a database hang.\n\nThe impact of verifying that RMAN is used to ensure Fast Recovery Area (FRA) can manage the space is minimal.\n\n\n\nRisk:\n\nIf RMAN is not used and FRA is being used, the space management function has no information to determine reclaimable space and the database may hang because it cannot archive a log to the FRA.\n\n\n\nAction / Repair:\n\nTo verify that the FRA space management funcion is not blocked, as the owner userid of the oracle home with the environment properly set for the target database, execute the following command set:\n\nPROBLEM_FILE_TYPES_PRESENT=$(echo -e \"set heading off feedback off\\n select count(*) from V$FLASH_RECOVERY_AREA_USAGE where file_type in ('ARCHIVED LOG', 'FLASHBACK LOG', 'BACKUP PIECE', 'IMAGE COPY') and number_of_files &gt; 0 ;\" | $ORACLE_HOME/bin/sqlplus -s \"/ as sysdba\");\nRMAN_BACKUP_WITHIN_7_DAYS=$(echo -e \"set heading off feedback off\\n select count(*) from V$BACKUP_SET where completion_time &gt; sysdate-7;\" | $ORACLE_HOME/bin/sqlplus -s \"/ as sysdba\");\nif [ $PROBLEM_FILE_TYPES_PRESENT -eq \"0\" ]\nthen echo -e \"\\nThis check is not applicable because file types 'ARCHIVED LOG', 'BACKUP PIECE', 'FLASHBACK LOG' or 'IMAGE COPY' are not present in V$FLASH_RECOVERY_AREA_USAGE\";\nelse if [[ $PROBLEM_FILE_TYPES_PRESENT -ge \"1\" && $RMAN_BACKUP_WITHIN_7_DAYS -ge \"1\" ]]\nthen echo -e \"\\nPASS:  FRA space management problem file types are present with an RMAN backup completion within the last 7 days.\"\nelse echo -e \"\\nFAIL:  FRA space management problem file types are present without an RMAN backup completion within the last 7 days.\"\nfi;\nfi;\n\nThe expected output should be:  PASS:  FRA space management problem file types are present with an RMAN backup completion within the last 7 days.\n\nIf the output is not as expected, configure RMAN and make backups according to Oracle recommended best practices. In order to benefit from the FRA's space management system, you must use RMAN to backup your database on a regular basis."}, {"id": "857c48cf-fa01-400b-b009-1dbf5552eb2c", "title": "Links", "links": [{"hyperlink": "http://docs.oracle.com/cd/E11882_01/backup.112/e10642/rcmquick.htm#BRADV89346", "text": "Getting Started with RMAN"}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=360416.1", "text": "Note: 360416.1 - Oracle10g / 11g - Getting Started with Recovery Manager (RMAN) (Doc ID 360416.1)"}]}]}, {"id": "aabb8f8f-dd79-4ab3-a212-81a353d29da4", "checkCategory": "RDBMS", "checkID": "666BBB359DF17AA6E040E50A1EC02674", "checkType": "SQL", "checkName": "Verify sys and system users default tablespace is system", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "success", "statusLabel": "PASS", "output": "The SYS and SYSTEM user ids have a default tablespace of SYSTEM"}, "children": [{"attr": {"consoleOutput": "\n\nDEFAULT_TABLESPACE\n------------------\nSYSTEM\nSYSTEM"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nIt's recommended to Keep the Default Tablespace for SYS and SYSTEM Schema mapped to the Default SYSTEM. All Standard Dictionary objects as well as all the added option will be located in the same place with no risk to record Dictionary data in other Datafiles.\n\n\n\nRisk:\n\nIf Default tablespace for SYS and SYSTEM is not set to SYSTEM, Data dictionary Object can be created in other locations and cannot be controlled during maintenance activities of the database. Due to this, there's a potential risk to run into severe Data Dictionary Corruption that may implicate time consuming Recovery Steps.\n\nAction / Repair:\n\nIf SYS or SYSTEM schema have a Default Tablespace different than SYSTEM, it's recommended to follow instruction given into Note ID : 1111111.2\n\nSQL&gt; SELECT username, default_tablespace\n     FROM dba_users\n     WHERE username in ('SYS','SYSTEM');\n\nIf  DEFAULT_TABLESPACE is anything other than SYSTEM tablespace, modify the default tablespace to SYSTEM by using the below command."}]}, {"id": "849c9e6d-0e7c-445b-a27f-a6aecb56618a", "checkCategory": "RDBMS", "checkID": "9AC756552BAE5EA4E040E50A1EC0475E", "checkType": "OS", "checkName": "Verify DB_BLOCK_CHECKSUM database parameter", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Database parameter DB_BLOCK_CHECKSUM is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Verify DB_BLOCK_CHECKSUM database parameter\n\n\n\ndb_block_checksum value = FULL"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Database parameter DB_BLOCK_CHECKSUM is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Verify DB_BLOCK_CHECKSUM database parameter\n\n\n\ndb_block_checksum value = FULL"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nExperience and testing has shown that certain database initialization parameters should be set at specific values. These are the best practice values set at deployment time. By setting these database initialization parameters as recommended, known problems may be avoided and performance maximized.\nThe parameters are common to all database instances. The impact of setting these parameters is minimal.\nThe performance related settings provide guidance to maintain highest stability without sacrificing performance. Changing the default performance settings can be done after careful performance evaluation and clear understanding of the performance impact.\n\n\n\nRisk:\n\nIf the database initialization parameters are not set as recommended, a variety of issues may be encountered, depending upon which initialization parameter is not set as recommended, and the actual set value.\n\n\n\nAction / Repair:\n\nDB_BLOCK_CHECKSUM = FULL aids in block corruption detection. Enable for primary and standby databases"}, {"id": "f3badde1-9035-4891-a942-eb70bd44a0c2", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=1302539.1", "text": "Note: 1302539.1 - Best Practices for Corruption Detection, Prevention, and Automatic Repair - in a Data Guard Configuration"}, {"hyperlink": "http://download.oracle.com/docs/cd/E11882_01/server.112/e10803/config_db.htm#HABPT4827", "text": "Protect Against Data Corruption"}]}]}, {"id": "68eb3dd7-8453-4875-af2f-76cc8e34b6c8", "checkCategory": "RDBMS", "checkID": "9FABDE1F9D6D8C4FE053D298EB0A0F82", "checkType": "OS", "checkName": "Verify the Alternate Archive Destination is Configured to Prevent Database Hangs", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "All log archive destination and alternate log archive destination settings are as recommended"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Verify the Alternate Archive Destination is Configured to Prevent Database Hangs\n\n\n\nPASS:LOG_ARCHIVE_DEST_1 attribute ALTERNATE expected value:other than \"NONE\" found value:LOG_ARCHIVE_DEST_2\nPASS:LOG_ARCHIVE_DEST_1 attribute MAX_FAILURE expected value:1 found value:1\nPASS:LOG_ARCHIVE_DEST_1 attribute REOPEN expected value:5 found value:5\nPASS:ALTERNATE local archive destination attribute LOG_ARCHIVE_DEST_STATE_n expected value:ALTERNATE found value:ALTERNATE\nPASS:ALTERNATE local archive destination attribute ALTERNATE expected value:LOG_ARCHIVE_DEST_1 found value:LOG_ARCHIVE_DEST_1\nPASS:ALTERNATE local archive destination attribute DB_UNIQUE_NAME expected value:CDB1 found value:CDB1\nPASS:ALTERNATE local archive destination attribute VALID_TYPE expected value:ALL_LOGFILES found value:ALL_LOGFILES\nPASS:ALTERNATE local archive destination attribute VALID_ROLE expected value:ALL_ROLES found value:ALL_ROLES\nPASS:ALTERNATE local archive destination attribute LOCATION expected value:%DATA% found value:+DATAC1\nPASS:LOG_ARCHIVE_DEST_1 attribute STATUS expected value:VALID found value:VALID\nPASS:LOG_ARCHIVE_DEST_1 attribute DB_UNIQUE_NAME expected value:CDB1 found value:CDB1\nPASS:LOG_ARCHIVE_DEST_1 attribute VALID_TYPE expected value:ALL_LOGFILES found value:ALL_LOGFILES\nPASS:LOG_ARCHIVE_DEST_1 attribute VALID_ROLE expected value:ALL_ROLES found value:ALL_ROLES\nPASS:LOG_ARCHIVE_DEST_1 attribute DESTINATION expected value:USE_DB_RECOVERY_FILE_DEST found value:USE_DB_RECOVERY_FILE_DEST"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "All log archive destination and alternate log archive destination settings are as recommended"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Verify the Alternate Archive Destination is Configured to Prevent Database Hangs\n\n\n\nPASS:LOG_ARCHIVE_DEST_1 attribute ALTERNATE expected value:other than \"NONE\" found value:LOG_ARCHIVE_DEST_2\nPASS:LOG_ARCHIVE_DEST_1 attribute MAX_FAILURE expected value:1 found value:1\nPASS:LOG_ARCHIVE_DEST_1 attribute REOPEN expected value:5 found value:5\nPASS:ALTERNATE local archive destination attribute LOG_ARCHIVE_DEST_STATE_n expected value:ALTERNATE found value:ALTERNATE\nPASS:ALTERNATE local archive destination attribute ALTERNATE expected value:LOG_ARCHIVE_DEST_1 found value:LOG_ARCHIVE_DEST_1\nPASS:ALTERNATE local archive destination attribute DB_UNIQUE_NAME expected value:CDB1 found value:CDB1\nPASS:ALTERNATE local archive destination attribute VALID_TYPE expected value:ALL_LOGFILES found value:ALL_LOGFILES\nPASS:ALTERNATE local archive destination attribute VALID_ROLE expected value:ALL_ROLES found value:ALL_ROLES\nPASS:ALTERNATE local archive destination attribute LOCATION expected value:%DATA% found value:+DATAC1\nPASS:LOG_ARCHIVE_DEST_1 attribute STATUS expected value:VALID found value:VALID\nPASS:LOG_ARCHIVE_DEST_1 attribute DB_UNIQUE_NAME expected value:CDB1 found value:CDB1\nPASS:LOG_ARCHIVE_DEST_1 attribute VALID_TYPE expected value:ALL_LOGFILES found value:ALL_LOGFILES\nPASS:LOG_ARCHIVE_DEST_1 attribute VALID_ROLE expected value:ALL_ROLES found value:ALL_ROLES\nPASS:LOG_ARCHIVE_DEST_1 attribute DESTINATION expected value:USE_DB_RECOVERY_FILE_DEST found value:USE_DB_RECOVERY_FILE_DEST"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nWithout an alternate archive destination configured, if the local archive destination (typically the Fast Recovery Area) becomes unusable, the database will hang when it cannot archive a log. A properly configured alternate archive destination prevents a database hang and provides time for the local archive destination to be made healthy, at which time Oracle will automatically resume archiving to the local archive destination.\n\nThe current recommended redo log archive log destination and alternate configuration is:\nDESTINATION \tATTRIBUTE \tVALUE \tALERT LEVEL\nlog_archive_dest_1 \tALTERNATE \ta separately configured log archive destination,\nlog_archive_dest_n \tFAIL\nlog_archive_dest_1 \tMAX_FAILURE \t1 \tFAIL\nlog_archive_dest_1 \tSTATUS \tVALID \tWARN\nlog_archive_dest_1 \tDB_UNIQUE_NAME \tequal to the DB_UNIQUE_NAME of the database \tWARN\nlog_archive_dest_1 \tREOPEN_SECS \t5 \tWARN\nlog_archive_dest_1 \tVALID_TYPE \tALL_LOGFILES \tWARN\nlog_archive_dest_1 \tVALID_ROLE \tALL_ROLES \tWARN\nlog_archive_dest_1 \tDESTINATION \tUSE_DB_RECOVERY_FILE_DEST \tWARN\nlog_archive_dest_n (ALTERNATE) \tSTATUS \tALTERNATE \tWARN\nlog_archive_dest_n (ALTERNATE) \tALTERNATE \tLOG_ARCHIVE_DEST_1 \tWARN\nlog_archive_dest_n (ALTERNATE) \tDB_UNIQUE_NAME \tequal to the DB_UNIQUE_NAME of the database \tWARN\nlog_archive_dest_n (ALTERNATE) \tVALID_TYPE \tALL_LOGFILES \tWARN\nlog_archive_dest_n (ALTERNATE) \tVALID_ROLE \tALL_ROLES \tWARN\nlog_archive_dest_n (ALTERNATE) \tDESTINATION \t%DATA% diskgroup \tWARN \n\nThe impact of moving critical database files out of ACFS disk groups varies by the type of file involved, and cannot be estimated here.\n\nNOTE: For more information on ACFS use cases and recommended disk group attributes on Exadata, please see below link: Oracle ACFS Support on Oracle Exadata Database Machine (Linux only) (Doc ID 1929629.1) \n\nRisk:\n\nThe database will eventually halt if the online redo logs cannot be archived. \n\nAction / Repair:\n\nTo Verify the log archive destination and alternate log archive destination configuration, run Exachk and examine the MAA Scorecard Section of the provided report.\n\nThe expected output in the Exachk report should be as follows:\n\nIn the \"Findings Passed\" summary section of the report, the overall result should be \"PASS\":\n\nPASS   OS Check    All log archive destination and alternate log archive destination settings are as recommended random01adm01:rac12c   View\n\nIn the \"View\" detail section of the report for each individual database server:\n\nStatus on random01adm01:rac12c:\nPASS =&gt; All log archive destination and alternate log archive destination settings are as recommended\nDATA FROM RANDOMADM01 - RAC12C DATABASE - VERIFY THE ALTERNATE ARCHIVE DESTINATION IS CONFIGURED TO PREVENT DATABASE HANGS\n\nPASS: LOG_ARCHIVE_DEST_1 attribute ALTERNATE expected value: other than \"NONE\" found value: LOG_ARCHIVE_DEST_2\nPASS: LOG_ARCHIVE_DEST_1 attribute MAX_FAILURE expected value: 1 found value: 1\nPASS: LOG_ARCHIVE_DEST_1 attribute REOPEN expected value: 5 found value: 5\nPASS: ALTERNATE local archive destination attribute LOG_ARCHIVE_DEST_STATE_n expected value: ALTERNATE found value: ALTERNATE\nPASS: ALTERNATE local archive destination attribute ALTERNATE expected value: LOG_ARCHIVE_DEST_1 found value: LOG_ARCHIVE_DEST_1\nPASS: ALTERNATE local archive destination attribute DB_UNIQUE_NAME expected value: RAC12C found value: RAC12C\nPASS: ALTERNATE local archive destination attribute VALID_TYPE expected value: ALL_LOGFILES found value: ALL_LOGFILES\nPASS: ALTERNATE local archive destination attribute VALID_ROLE expected value: ALL_ROLES found value: ALL_ROLES\nPASS: ALTERNATE local archive destination attribute LOCATION expected value: %DATA% found value: +DATAC1\nPASS: LOG_ARCHIVE_DEST_1 attribute STATUS expected value: VALID found value: VALID\nPASS: LOG_ARCHIVE_DEST_1 attribute DB_UNIQUE_NAME expected value: RAC12C found value: RAC12C\nPASS: LOG_ARCHIVE_DEST_1 attribute VALID_TYPE expected value: ALL_LOGFILES found value: ALL_LOGFILES\nPASS: LOG_ARCHIVE_DEST_1 attribute VALID_ROLE expected value: ALL_ROLES found value: ALL_ROLES\nPASS: LOG_ARCHIVE_DEST_1 attribute DESTINATION expected value: USE_DB_RECOVERY_FILE_DEST found value: USE_DB_RECOVERY_FILE_DEST\n\nExample of a \"CRITICAL\" result:\nIn the \"View\" detail section of the report:\n\nCRITICAL =&gt; One or more log archive destination and alternate log archive destination settings are not as recommended\nDATA FROM RANDOMADM01 - SING12C DATABASE- VERIFY THE ALTERNATE ARCHIVE DESTINATION IS CONFIGURED TO PREVENT DATABASE HANGS\n\nFAIL: LOG_ARCHIVE_DEST_1 attribute ALTERNATE expected value: other than \"NONE\" found value: NONE\nFAIL: LOG_ARCHIVE_DEST_1 attribute MAX_FAILURE expected value: 1 found value: 0\nWARN: LOG_ARCHIVE_DEST_1 attribute DB_UNIQUE_NAME expected value: SING12C found value: NONE\nPASS: LOG_ARCHIVE_DEST_1 attribute STATUS expected value: VALID found value: VALID\nPASS: LOG_ARCHIVE_DEST_1 attribute VALID_TYPE expected value: ALL_LOGFILES found value: ALL_LOGFILES\nPASS: LOG_ARCHIVE_DEST_1 attribute VALID_ROLE expected value: ALL_ROLES found value: ALL_ROLES\nPASS: LOG_ARCHIVE_DEST_1 attribute DESTINATION expected value: USE_DB_RECOVERY_FILE_DEST found value: USE_DB_RECOVERY_FILE_DEST\n\n    NOTE: For any incorrect settings, change following the appropriate version specific Oracle documentation instructions.\n\n    Example parameter definitions:\n\n    log_archive_dest_1='LOCATION=USE_DB_RECOVERY_FILE_DEST valid_for=(ALL_LOGFILES,ALL_ROLES) MAX_FAILURE=1 REOPEN=5 DB_UNIQUE_NAME=&lt;db_unique_name&gt; ALTERNATE=LOG_ARCHIVE_DEST_10'\n    log_archive_dest_10='location=+DATAC1 valid_for=(ALL_LOGFILES,ALL_ROLES) DB_UNIQUE_NAME=&lt;db_unique_name&gt; ALTERNATE=LOG_ARCHIVE_DEST_1'\n\n    NOTE: If after corrective actions are completed you wish to run just this check without a full Exachk run, execute the following:\n\n    ./exachk -check 9FABDE1F9D6D8C4FE053D298EB0A0F82\n"}]}, {"id": "d6a9e82d-dd8f-46d7-84f9-018ec882f132", "checkCategory": "RDBMS", "checkID": "A3359E9DDCAAE0CDE053D298EB0AE516", "checkType": "SQL", "checkName": "Automatic segment storage management", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "success", "statusLabel": "PASS", "output": "All tablespaces are using Automatic segment storage management"}, "children": [{"attr": {"consoleOutput": "\n\nQuery returned no rows which is expected when the SQL check passes."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Starting with Oracle 9i Auto Segment Space Management (ASSM) can be used by specifying the SEGMENT SPACE MANAGEMENT clause, set to AUTO in the CREATE TABLESPACE statement. Implementing the ASSM feature allows Oracle to use bitmaps to manage the free space within segments. The bitmap describes the status of each data block within a segment, with respect to the amount of space in the block available for inserting rows. The current status of the space available in a data block is reflected in the bitmap allowing for Oracle to manage free space automatically with ASSM. ASSM tablespaces automate freelist management and remove the requirement/ability to specify PCTUSED, FREELISTS, and FREELIST GROUPS storage parameters for individual tables and indexes created in these tablespaces. "}, {"id": "7f4c3ec9-f218-418b-b2cd-6ced5f86e5cc", "title": "Links", "links": [{"hyperlink": "http://docs.oracle.com/cd/E11882_01/server.112/e10803/config_db.htm#HABPT4845", "text": "Use Automatic Segment Space Management"}]}]}, {"id": "2cb96c18-ae38-4fd5-bff6-646af737c1a8", "checkCategory": "RDBMS", "checkID": "A33813C004A33347E053D298EB0AE8D6", "checkType": "SQL", "checkName": "Locally managed tablespaces", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "success", "statusLabel": "PASS", "output": "All tablespaces are locally managed tablespace"}, "children": [{"attr": {"consoleOutput": "\n\nQuery returned no rows which is expected when the SQL check passes."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nIn order to reduce contention to the data dictionary, rollback data, and reduce the amount of generated redo, locally managed tablespaces should be used rather than dictionary managed tablespaces.Please refer to the below referenced notes for more information about benefits of locally managed tablespace and how to migrate a tablespace from dictionary managed to locally managed.\n\n\nAction / Repair:\n\nselect pdb_name,tablespace_name,extent_management from cdb_tablespaces ts,cdb_pdbs p where extent_management !='LOCAL' and ts.con_id=p.con_id  union all select 'CDB$ROOT',tablespace_name,extent_management from dba_tablespaces where extent_management !='LOCAL' order by 1;\n\nIf there are any dictionary managed tablespaces, output will display them."}, {"id": "21979155-339a-478c-ae4b-713bcc1b70bc", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=105120.1", "text": "Note: 105120.1 - \tAdvantages of Using Locally Managed vs Dictionary Managed Tablespaces"}]}]}, {"id": "937c29b5-36a7-490f-afab-66058f281670", "checkCategory": "RDBMS", "checkID": "A97A01C7F17307CFE040E50A1EC06C63", "checkType": "SQL_PARAM", "checkName": "Check for parameter db_lost_write_protect", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Database parameter DB_LOST_WRITE_PROTECT is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Database parameter DB_LOST_WRITE_PROTECT is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nExperience and testing has shown that certain database initialization parameters should be set at specific values. These are the best practice values set at deployment time. By setting these database initialization parameters as recommended, known problems may be avoided and performance maximized.\nThe parameters are common to all database instances. The impact of setting these parameters is minimal.\nThe performance related settings provide guidance to maintain highest stability without sacrificing performance. Changing the default performance settings can be done after careful performance evaluation and clear understanding of the performance impact.\n\n\n\nRisk:\n\nIf the database initialization parameters are not set as recommended, a variety of issues may be encountered, depending upon which initialization parameter is not set as recommended, and the actual set value.\n\n\n\nAction / Repair:\n\nThis is important for data block lost write detection and repair. Enable for\nprimary and standby databases.\n\nSee referenced MOS notes for more info."}, {"id": "40862cbb-747f-48b6-a268-ceee289f5ea6", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1265884.1", "text": "Note: 1265884.1 - Resolving ORA-752 or ORA-600 [3020] During Standby Recovery"}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1302539.1", "text": "Note: 1302539.1 - Best Practices for Corruption Detection, Prevention, and Automatic Repair - in a Data Guard Configuration"}, {"hyperlink": "http://download.oracle.com/docs/cd/E11882_01/server.112/e10803/config_db.htm#HABPT4827", "text": "Protect Against Data Corruption"}]}]}, {"id": "cf9535bf-32c4-4922-8e4a-6d612b8f4541", "checkCategory": "CRS HOME", "checkID": "B0B3017BC94455B9E0431EC0E50AAA2A", "checkType": "OS", "checkName": "Clusterware status", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Clusterware is running"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - CLUSTERWARE STATUS\n\n\n\n--------------------------------------------------------------------------------\nName           Target  State        Server                   State details\n--------------------------------------------------------------------------------\nLocal Resources\n--------------------------------------------------------------------------------\nora.LISTENER.lsnr\nONLINE  ONLINE       scaqal03adm05vm01        STABLE\nONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.chad\nONLINE  ONLINE       scaqal03adm05vm01        STABLE\nONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.net1.network\nONLINE  ONLINE       scaqal03adm05vm01        STABLE\nONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.ons\nONLINE  ONLINE       scaqal03adm05vm01        STABLE\nONLINE  ONLINE       scaqal03adm06vm01        STABLE\n--------------------------------------------------------------------------------\nCluster Resources\n--------------------------------------------------------------------------------\nora.ASMNET1LSNR_ASM.lsnr(ora.asmgroup)\n1        ONLINE  ONLINE       scaqal03adm05vm01        STABLE\n2        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.DATAC1.dg(ora.asmgroup)\n1        ONLINE  ONLINE       scaqal03adm05vm01        STABLE\n2        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.LISTENER_SCAN1.lsnr\n1        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.LISTENER_SCAN2.lsnr\n1        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.LISTENER_SCAN3.lsnr\n1        ONLINE  ONLINE       scaqal03adm05vm01        STABLE\nora.RECOC1.dg(ora.asmgroup)\n1        ONLINE  ONLINE       scaqal03adm05vm01        STABLE\n2        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.asm(ora.asmgroup)\n1        ONLINE  ONLINE       scaqal03adm05vm01        Started,STABLE\n2        ONLINE  ONLINE       scaqal03adm06vm01        Started,STABLE\nora.asmnet1.asmnetwork(ora.asmgroup)\n1        ONLINE  ONLINE       scaqal03adm05vm01        STABLE\n2        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.cdb1.ahfpdb1.pdb\n1        OFFLINE OFFLINE                               STABLE\n2        OFFLINE OFFLINE                               STABLE\nora.cdb1.cdb1_pdb11_svc.svc\n1        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\n2        ONLINE  ONLINE       scaqal03adm05vm01        STABLE\nora.cdb1.db\n1        ONLINE  ONLINE       scaqal03adm05vm01        Open,HOME=/u01/app/o\nracle/product/21.0.0\n.0/dbhome_1,STABLE\n2        ONLINE  ONLINE       scaqal03adm06vm01        Open,HOME=/u01/app/o\nracle/product/21.0.0\n.0/dbhome_1,STABLE\nora.cdb1.pdb11.pdb\n1        ONLINE  ONLINE       scaqal03adm05vm01        STABLE\n2        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.cdp1.cdp\n1        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.cdp2.cdp\n1        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.cdp3.cdp\n1        ONLINE  ONLINE       scaqal03adm05vm01        STABLE\nora.cvu\n1        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.qosmserver\n1        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.scan1.vip\n1        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.scan2.vip\n1        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.scan3.vip\n1        ONLINE  ONLINE       scaqal03adm05vm01        STABLE\nora.scaqal03adm05vm01.vip\n1        ONLINE  ONLINE       scaqal03adm05vm01        STABLE\nora.scaqal03adm06vm01.vip\n1        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\n--------------------------------------------------------------------------------"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Clusterware is running"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - CLUSTERWARE STATUS\n\n\n\n--------------------------------------------------------------------------------\nName           Target  State        Server                   State details\n--------------------------------------------------------------------------------\nLocal Resources\n--------------------------------------------------------------------------------\nora.LISTENER.lsnr\nONLINE  ONLINE       scaqal03adm05vm01        STABLE\nONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.chad\nONLINE  ONLINE       scaqal03adm05vm01        STABLE\nONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.net1.network\nONLINE  ONLINE       scaqal03adm05vm01        STABLE\nONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.ons\nONLINE  ONLINE       scaqal03adm05vm01        STABLE\nONLINE  ONLINE       scaqal03adm06vm01        STABLE\n--------------------------------------------------------------------------------\nCluster Resources\n--------------------------------------------------------------------------------\nora.ASMNET1LSNR_ASM.lsnr(ora.asmgroup)\n1        ONLINE  ONLINE       scaqal03adm05vm01        STABLE\n2        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.DATAC1.dg(ora.asmgroup)\n1        ONLINE  ONLINE       scaqal03adm05vm01        STABLE\n2        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.LISTENER_SCAN1.lsnr\n1        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.LISTENER_SCAN2.lsnr\n1        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.LISTENER_SCAN3.lsnr\n1        ONLINE  ONLINE       scaqal03adm05vm01        STABLE\nora.RECOC1.dg(ora.asmgroup)\n1        ONLINE  ONLINE       scaqal03adm05vm01        STABLE\n2        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.asm(ora.asmgroup)\n1        ONLINE  ONLINE       scaqal03adm05vm01        Started,STABLE\n2        ONLINE  ONLINE       scaqal03adm06vm01        Started,STABLE\nora.asmnet1.asmnetwork(ora.asmgroup)\n1        ONLINE  ONLINE       scaqal03adm05vm01        STABLE\n2        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.cdb1.ahfpdb1.pdb\n1        OFFLINE OFFLINE                               STABLE\n2        OFFLINE OFFLINE                               STABLE\nora.cdb1.cdb1_pdb11_svc.svc\n1        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\n2        ONLINE  ONLINE       scaqal03adm05vm01        STABLE\nora.cdb1.db\n1        ONLINE  ONLINE       scaqal03adm05vm01        Open,HOME=/u01/app/o\nracle/product/21.0.0\n.0/dbhome_1,STABLE\n2        ONLINE  ONLINE       scaqal03adm06vm01        Open,HOME=/u01/app/o\nracle/product/21.0.0\n.0/dbhome_1,STABLE\nora.cdb1.pdb11.pdb\n1        ONLINE  ONLINE       scaqal03adm05vm01        STABLE\n2        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.cdp1.cdp\n1        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.cdp2.cdp\n1        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.cdp3.cdp\n1        ONLINE  ONLINE       scaqal03adm05vm01        STABLE\nora.cvu\n1        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.qosmserver\n1        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.scan1.vip\n1        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.scan2.vip\n1        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\nora.scan3.vip\n1        ONLINE  ONLINE       scaqal03adm05vm01        STABLE\nora.scaqal03adm05vm01.vip\n1        ONLINE  ONLINE       scaqal03adm05vm01        STABLE\nora.scaqal03adm06vm01.vip\n1        ONLINE  ONLINE       scaqal03adm06vm01        STABLE\n--------------------------------------------------------------------------------"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Oracle Clusterware is required for complete client failover integration.  Please consult the following resources for further information."}, {"id": "3b8e1a06-5b99-4d7d-a3c3-695ee51bbbce", "title": "Links", "links": [{"hyperlink": "https://docs.oracle.com/en/database/oracle/oracle-database/19/haovw/continuous-availability-applications.html#GUID-9190424E-2302-4B5D-881D-84F970B39E17", "text": "High Availability Overview and Best Practices: Continuous Availability for Applications"}]}]}, {"id": "0427a8de-8d5f-4960-bff7-153edb53e64b", "checkCategory": "RDBMS", "checkID": "B16B9310FB504695E0431EC0E50A880B", "checkType": "SQL_PARAM", "checkName": "Check for parameter undo_retention", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Database parameter UNDO_RETENTION on PRIMARY is not null"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Database parameter UNDO_RETENTION on PRIMARY is not null"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Oracle Flashback Technology enables fast logical failure repair. Oracle recommends that you use automatic undo management with sufficient space to attain your desired undo retention guarantee, enable Oracle Flashback Database, and allocate sufficient space and I/O bandwidth in the fast recovery area.  Application monitoring is required for early detection.  Effective and fast repair comes from leveraging and rehearsing the most common application specific logical failures and using the different flashback features effectively (e.g flashback query, flashback version query, flashback transaction query, flashback transaction, flashback drop, flashback table, and flashback database, and 12.2 flashback pluggable database (PDB)).\n\nKey HA Benefits:\n<ul>\n<li>With application monitoring and rehearsed repair actions with flashback technologies, application downtime can reduce from hours and days to the time to detect the logical inconsistency.</li>\n<li>Fast repair for logical failures caused by malicious or accidental DML or DDL operations.</li>\n<li>Effect fast point-in-time repair at the appropriate level of granularity: transaction, table, pluggable database, or database.</li></ul>\nQuestions that need to be addressed by your application and operations team:\n<ol>\n<li>Can your application or monitoring infrastructure detect logical inconsistencies?</li>\n<li>Is your operations team prepared to use various flashback technologies to repair quickly and efficiently?</li>\n<li>Is security practices enforced to prevent unauthorized privileges that can result logical inconsistencies?</li>\n</ol>"}]}, {"id": "bb6a21c6-0bf5-4b01-ba86-ac15b2e6c0c3", "checkCategory": "RDBMS", "checkID": "B16C9847624E1B5AE0431EC0E50AE353", "checkType": "SQL_PARAM", "checkName": "Check for parameter fast_start_mttr_target", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "fast_start_mttr_target is greater than or equal to 300"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "fast_start_mttr_target is greater than or equal to 300"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nRelaxing aggressive checkpointing prevents outliers and improves performance.\n\n\n\nRisk:\n\nToo small of a value results in aggresive checkpoint rates, uneven and reduced performance.\n\n\n\nAction / Repair:\n\nCheck that its set and not less than 300.\n\nNOTE: you must disable or remove the FAST_START_IO_TARGET, LOG_CHECKPOINT_INTERVAL, and LOG_CHECKPOINT_TIMEOUT initialization parameters when using FAST_START_MTTR_TARGET. Setting these parameters interferes with the mechanisms used to manage cache recovery time to meet FAST_START_MTTR_TARGET."}]}, {"id": "e50c300c-bfc6-4816-aa94-562bfb01a92f", "checkCategory": "RDBMS", "checkID": "B9BCC54F3A901F18E0431EC0E50AC1A0", "checkType": "SQL_PARAM", "checkName": "Check for parameter recyclebin", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "RECYCLEBIN on PRIMARY is set to the recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "RECYCLEBIN on PRIMARY is set to the recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nExperience and testing has shown that certain database initialization parameters should be set at specific values. These are the best practice  values set at deployment time. By setting these database initialization  parameters as recommended, known problems may be avoided and performance  maximized. \nThe parameters are common to all database instances. The impact of setting  these parameters is minimal.  The performance related settings provide guidance to maintain highest stability without sacrificing performance. Changing the default performance  settings can be done after careful performance evaluation and clear understanding of the performance impact. \n  \n\n\nRisk:\n\nIf the database initialization parameters are not set as recommended, a variety of issues may be encountered, depending upon which initialization  parameter is not set as recommended, and the actual set value. \n  \n\n\nAction / Repair:\n\n\"RECYCLEBIN = ON\" provides higher availability by enabling the Flashback Drop  feature. \"ON\" is the default value and should not be changed. \n"}]}, {"id": "ed675f0b-cfd9-4ca0-af5f-f22c0fe2d4c7", "checkCategory": "RDBMS", "checkID": "C31B975819621D1CE0431EC0E50AC731", "checkType": "OS", "checkName": "Redo Log File Size", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Redo log files are appropriately sized"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Redo Log File Size\n\n\n\nSUCCESS:Redo logs are appropriately sized"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Redo log files are appropriately sized"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Redo Log File Size\n\n\n\nSUCCESS:Redo logs are appropriately sized"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nFor performance reasons redo logs should be sized so that they do not switch more than once every 10 minutes or 7 switches in an hour during peak throughput.\n\nRisk:\n\nSwitching logs too often causes poor recovery performance on the standby as recovery only checkpoints at a log boundary which pauses recovery while the buffer cache is flushed.\n\nAction / Repair:\n\nTo verify redo log size, as the owner userid of a given database, and with the environment properly set to access that database, execute the following command set:\n\nfunction logswitches {\n$ORACLE_HOME/bin/sqlplus -s '/ as sysdba' &lt;&lt;EOF\nset feedback off newpage none termout on\nalter session set nls_date_format='YYYY/MM/DD HH24:MI:SS';\nselect * from (\nselect thread#,sequence#,first_time \"LOG START TIME\",(blocks*block_size/1024/1024)/((next_time-first_time)*86400) \"REDO RATE(MB/s)\", \n(((blocks*block_size)/a.average)*100) pct_full\nfrom v$archived_log, (select avg(bytes) average from v$log) a\nwhere ((next_time-first_time)*86400&lt;300)\nand first_time &gt; (sysdate-90)\nand (((blocks*block_size)/a.average)*100)&gt;80\nand dest_id=1\norder by 4 desc\n)\nwhere rownum&lt;11;\nexit\nEOF\n}\n\nexport SWITCHES=$(logswitches)\n\nif [ $(echo \"$SWITCHES\"| wc -l) -le 1 ]\n then\n  echo -e \"SUCCESS: Redo logs are appropriately sized\"\n else\n  echo\n  echo -e \"WARNING: Redo logs are potentially mis-sized.  Below is a list of archived logs from\"\n  echo -e \"the previous 90 days which were active for less than 5 minutes and the redo rate seen\"\n  echo -e \"for the duration of that log.  These indicate the peak redo rate. Resizing of the log\"\n  echo -e \"files to accomodate this rate may be required.\\n\"\n  echo \"$SWITCHES\"\nfi\n\nThe expected output is:\n\nSUCCESS: Redo logs are appropriately sized\n\nExample of a \"WARNING\" result:\n\nWARNING: Redo logs are potentially mis-sized.  Below is a list of archived logs from\nthe previous 90 days which were active for less than 5 minutes and the redo rate seen\nfor the duration of that log.  These indicate the peak redo rate. Resizing of the log\nfiles to accomodate this rate may be required.\n\n   THREAD#  SEQUENCE# LOG START TIME      REDO RATE(MB/s)   PCT_FULL\n---------- ---------- ------------------- --------------- ----------\n         2      12374 2017/02/24 15:03:04      412.881913 95.7611859\n         2      12382 2017/02/24 15:15:10       408.75571 89.8144871\n         2      12296 2017/02/24 12:06:26       396.99937 92.0774907\n         2      12380 2017/02/24 15:09:31      371.651196 90.7351553\n         2      12385 2017/02/24 15:17:28      370.488538 90.4513031\n         2      12378 2017/02/24 15:06:18      362.405012 95.1136202\n         2      12389 2017/02/24 15:20:51      356.672996 95.7862049\n         2      12377 2017/02/24 15:05:32      354.660687 99.5751441\n         2      12350 2017/02/24 13:27:40      353.577854  97.113058\n         2      12354 2017/02/24 13:30:45      347.344079 97.5209206\n\nIf logs are frequently switching, the redo logs should be increased in size according to the following chart:\n\nPeak redo rate according\nto EM or AWR reports \t     Recommended redo log group size\n&lt;1 MB/sec \t                     1 GB\n&lt;=3 MB/sec \t                     3 GB\n&lt;= 5 MB/sec \t                     4 GB\n&lt;= 25 MB/sec \t             16 GB\n&lt;= 50 MB/sec \t             32 GB\n&gt; 50 MB/sec \t                     64 GB"}]}, {"id": "4720922d-f0c4-4f10-8657-572a09e45d9d", "checkCategory": "RDBMS", "checkID": "C33B66906DA21665E0431EC0E50A0759", "checkType": "OS", "checkName": "Block Corruptions", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "No reported block corruptions in V$DATABASE_BLOCK_CORRUPTIONS"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Block Corruptions\n\n\n\n0 block_corruptions found in v$database_block_corruptions"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "No reported block corruptions in V$DATABASE_BLOCK_CORRUPTIONS"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Block Corruptions\n\n\n\n0 block_corruptions found in v$database_block_corruptions"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "The V$DATABASE_BLOCK_CORRUPTION view displays blocks marked corrupt by Oracle Database components such as RMAN commands, ANALYZE, dbv, SQL queries, and so on. Any process that encounters a corrupt block records the block corruption in this view.  Repair techniques include block media recovery, restoring data files, recovering with incremental backups, and block newing. Block media recovery can repair physical corruptions, but not logical corruptions. It is also recommended to use RMAN \"CHECK LOGICAL\" option to check for data block corruptions periodically. Please consult the Oracle Database Backup and Recovery User's Guide for repair instructions"}]}, {"id": "97d5cb73-af4e-41ea-8a77-6acdba03ac38", "checkCategory": "RDBMS", "checkID": "CCAD91212BD475C4E0431EC0E50A3FB5", "checkType": "SQL_PARAM", "checkName": "Check for parameter undo_management", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Instance is using Automatic Undo Management"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Instance is using Automatic Undo Management"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Oracle provides a fully automated mechanism, referred to as automatic undo management, for managing undo information and space. In this management mode, you create an undo tablespace, and the server automatically manages undo segments and space among the various active sessions.You should set the UNDO_MANAGEMENT initialization parameter to AUTO to enable automatic undo management."}]}, {"id": "72009914-2866-4eb6-8012-925ab4659926", "checkCategory": "RDBMS", "checkID": "CCAD9945F7797A3FE0431EC0E50A856B", "checkType": "SQL", "checkName": "Archivelog Mode", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "success", "statusLabel": "PASS", "output": "Database Archivelog Mode is set to ARCHIVELOG"}, "children": [{"attr": {"consoleOutput": "\n\n'ARCHIVELOGMODE='||UPPER(LOG_MODE)\n----------------------------------\nArchivelog Mode = ARCHIVELOG"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Running the database in ARCHIVELOG mode and using database FORCE LOGGING mode are prerequisites for database recovery operations. The ARCHIVELOG mode enables online database backup and is necessary to recover the database to a point in time later than what has been restored. Features such as Oracle Data Guard and Flashback Database require that the production database run in ARCHIVELOG mode."}, {"id": "2d421f21-fefa-439b-b24c-95935ab10f70", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=69739.1", "text": "Note: 69739.1 - How to Turn Archiving ON and OFF in Oracle RDBMS"}]}]}, {"id": "974d4f59-8ca0-48c1-a81b-e73ee7546f85", "checkCategory": "RDBMS", "checkID": "CCAD995A4067776EE0431EC0E50AD00E", "checkType": "SQL", "checkName": "Default Temporary Tablespace", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "success", "statusLabel": "PASS", "output": "Default temporary tablespace is set"}, "children": [{"attr": {"consoleOutput": "\n\nPROPERTY_NAME           PROPERTY_VALUE\n----------------------- --------------\nDEFAULT_TEMP_TABLESPACE TEMP"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nIts recommended to set default temporary tablespace at database level to achieve optimal performance for queries which requires sorting the data.\n\n\nAction / Repair:\n\nIf default temporary tablespace is not set at database level, it's recommended to follow the instructions given in Note 1498442.1\n\nSQL&gt; SELECT PROPERTY_NAME,PROPERTY_VALUE\n     FROM database_properties\n     PROPERTY_NAME ='DEFAULT_TEMP_TABLESPACE';\n"}, {"id": "aad439c5-2bf1-4448-9d89-f03abbacc0d5", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= DATABASE&id=1498442.1", "text": "Note: 1498442.1 - Overview of Oracle Temporary Tablespaces"}]}]}, {"id": "2207585f-6000-4c1b-8f61-66e42f7d5df7", "checkCategory": "RDBMS", "checkID": "DC223BE507001B0AE04313C0E50A359D", "checkType": "OS", "checkName": "Verify data files are recoverable", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "The data files are all recoverable"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Verify data files are recoverable\n\n\n\nThe RMAN command REPORT UNRECOVERABLE DATABASE returned no rows which is expected if there are no files that have unrecoverable changes."}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "The data files are all recoverable"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Verify data files are recoverable\n\n\n\nThe RMAN command REPORT UNRECOVERABLE DATABASE returned no rows which is expected if there are no files that have unrecoverable changes."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nWhen you perform a DML or DDL operation using the NOLOGGING or UNRECOVERABLE clause, database backups made before the unrecoverable operation are invalidated and new backups are required. You can specify the SQL ALTER DATABASE or SQL ALTER TABLESPACE statement with the FORCE LOGGING clause to override the NOLOGGING setting; however, this statement will not repair a database that is already invalid.\n\nRisk:\n\nChanges under NOLOGGING will not be available after executing database recovery from a backup made before the unrecoverable change.\n\n\n\nAction / Repair:\n\nTo verify that the data files are recoverable, execute the following RMAN command:\n\nRMAN&gt; report unrecoverable database;\n\nIf there are any unrecoverable actions, the output will be similar to:\n\nReport of files that need backup due to unrecoverable operations\nFile   Type of Backup Required   Name\n----   -----------------------   -----------------------------------\n&lt;fno&gt;  &lt;full [or incremental]&gt;   &lt;file name&gt;\n\n\nIf nologging changes have occurred and the data must be recoverable then a backup of those datafiles that have nologging operations within should be done immediately:\n\n    RMAN&gt; backup [incremental] datafile [fno];\n\nPlease consult the \"Backup and Recovery User's Guide\" for specific steps to resolve files that have unrecoverable changes.\n\n\nThe standard best practice is to enable FORCE LOGGING at the database level (ALTER DATABASE FORCE LOGGING;) to ensure that all transactions are recoverable. However, placing the database in force logging mode for ETL operations can lead to unnecessary database overhead. MAA best practices call for isolating data that does not need to be recoverable. Such data would include:\n    - data resulting from temporary loads,\n    - data resulting from transient transformations,\n    - any noncritical data.\n\nTo reduce unnecessary redo generation, do the following:\n1) Specify FORCE LOGGING for all tablespaces that you explicitly wish to protect (ALTER TABLESPACE FORCE LOGGING;).\n2) Specify NO FORCE LOGGING for those tablespaces that do not need protection (ALTER TABLESPACE NO FORCE LOGGING;).\n3) Disable force logging at the database level (ALTER DATABASE NO FORCE LOGGING;) otherwise the database level settings will override the tablespace settings.\n\nOnce the above is complete, redo logging will function as follows:\n\nExplicit no logging operations on objects in the no logging tablespace will not generate the normal redo (a small amount of redo is always generated for no logging operations to signal that a no logging operation was performed).\n\nAll other operations on objects in the no logging tablespace will generate the normal redo.\nOperations performed on objects in the force logging tablespaces always generate normal redo.\n\nNote: Please seek assistance from Oracle Support to mitigate this problem. Upon their guidance, the following commands could help validate and identify corrupted blocks:\n\n      oracle&gt; dbv file=&lt;data_file_returned_by_above_command&gt; userid=sys/******\n      RMAN&gt; validate check logical database;\n      SQL&gt; select COUNT(*) from v$database_block_corruption;"}, {"id": "c191fc1f-f001-415f-a100-c8cf88af0e5a", "title": "Links", "links": [{"hyperlink": "http://docs.oracle.com/cd/E11882_01/backup.112/e10642/rcmbckba.htm#i1020015", "text": "Backing Up Database Files with RMAN"}, {"hyperlink": "http://docs.oracle.com/cd/E11882_01/backup.112/e10642/osadvsce.htm#BRADV90047", "text": "Recovering NOLOGGING Tables and Indexes"}]}]}, {"id": "af5c66a7-0a63-4bfc-8c1c-ea0b9072cd05", "checkCategory": "RDBMS", "checkID": "E34EB3F020B35A64E04313C0E50A1DC7", "checkType": "SQL", "checkName": "Verify rman controlfile autobackup is set to ON", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "success", "statusLabel": "PASS", "output": "RMAN controlfile autobackup is set to ON"}, "children": [{"attr": {"consoleOutput": "\n\n'RMAN_CONFIGURATION='||UPPER(VALUE)\n-----------------------------------\nrman_configuration = ON"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThe control file is a binary file that records the physical structure of the database and contains important meta data required to recover the database. The database cannot startup or stay up unless all control files are valid. When a Recovery Manager catalog is not used, the control file is needed for database recovery because it contains all backup and recovery meta data.\n\nThe impact of verifying and setting \"CONTROLFILE AUTOBACKUP\" to \"ON\" is minimal. \n\n\n\nRisk:\n\nWhen a Recovery Manager catalog is not used, loss of the controlfile results in loss of all backup and recovery meta data, which causes a much more challenging database recovery operation\n\n\n\nAction / Repair:\n\nTo verify that RMAN \"CONTROLFILE AUTOBACKUP\" is set to \"ON\", as the owner userid of the oracle home with the environment properly set for the target database, execute the following command set:\n\nRMAN_AUTOBACKUP_STATUS=\"\";\nRMAN_AUTOBACKUP_STATUS=$(echo -e \"set heading off feedback off\\n select value from V$RMAN_CONFIGURATION where name = 'CONTROLFILE AUTOBACKUP';\" | $ORACLE_HOME/bin/sqlplus -s \"/ as sysdba\");\nif [ -n \"$RMAN_AUTOBACKUP_STATUS\" ] && [ \"$RMAN_AUTOBACKUP_STATUS\" = \"ON\" ]\nthen echo -e \"\\nPASS:  RMAN \"CONTROLFILE AUTOBACKUP\" is set to \"ON\":\" $RMAN_AUTOBACKUP_STATUS;\nelse\necho -e \"\\nFAIL:  RMAN \"CONTROLFILE AUTOBACKUP\" should be set to \"ON\":\" $RMAN_AUTOBACKUP_STATUS;\nfi;\n\nThe expected output should be:\n\nPASS:  RMAN CONTROLFILE AUTOBACKUP is set to \"ON\": ON\n\nIf the output is not as expected, investigate and correct the condition(s).\n\nFor additional information, review information on CONFIGURE syntax in Oracle Database Backup and Recovery Reference 11g Release 2 (11.2).\n\nRMAN&gt; CONFIGURE CONTROLFILE AUTOBACKUP ON;\n\nNOTE: Oracle MAA also recommends periodically backing up the controlfile to trace as additional backup.\n\nSQL&gt; ALTER DATABASE BACKUP CONTROLFILE TO TRACE;"}]}, {"id": "552d4eae-d2de-43c8-8700-2ebe7fd0cca7", "checkCategory": "RDBMS", "checkID": "E3508B6664085B53E04313C0E50AC2CA", "checkType": "OS", "checkName": "Verify control_file_record_keep_time value is in recommended range", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "control_file_record_keep_time is within recommended range [1-9]"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Verify control_file_record_keep_time value is in recommended range\n\n\n\ncontrol_file_record_keep_time = 7"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nWhen a Recovery Manager catalog is not used, the initialization parameter \"control_file_record_keep_time\" controls the period of time for which circular reuse records are maintained within the database control file. RMAN repository records are kept in circular reuse records.  The optimal setting is the maximum number of days in the past that is required to restore and recover a specific database without the use of a RMAN recovery catalog.  Setting this parameter within a recommended range (1 to 9 days) has been shown to address most recovery scenarios by ensuring archive logs and backup records are not prematurely aged out making database recovery much more challenging.    \n\nRisk:\n\nIf the control_file_record_keep_time is set to 0, no RMAN repository records are retained in the controlfile, which causes a much more challenging database recovery operation if RMAN recovery catalog is not available.\n\nIf the control_file_record_keep_time is set too high, problems can arise with space management within the control file, expansion of the control file, and control file contention issues.\n\nThe impact of verifying that the initialization parameter control_file_record_keep_time value is in the recommended range is minimal. Increasing this value will increase the size of the controlfile and possible query time for backup meta data and archive data.\n\nAction / Repair:\n\nTo verify that the FRA space management function is not blocked, as the owner userid of the oracle home with the environment properly set for the target database, execute the following command set:\n\nCF_RECORD_KEEP_TIME=\"\";\nCF_RECORD_KEEP_TIME=$(echo -e \"set heading off feedback off\\n select value from V$PARAMETER where name = 'control_file_record_keep_time';\" | $ORACLE_HOME/bin/sqlplus -s \"/ as sysdba\");\nif [[ $CF_RECORD_KEEP_TIME -ge \"1\" && $CF_RECORD_KEEP_TIME -le \"9\" ]]\nthen echo -e \"\\nPASS:  control_file_record_keep_time is within recommended range [1-9]:\" $CF_RECORD_KEEP_TIME;\nelif [ $CF_RECORD_KEEP_TIME -eq \"0\" ]\nthen echo -e \"\\nFAIL:  control_file_record_keep_time is set to zero:\" $CF_RECORD_KEEP_TIME;\nelse echo -e \"\\nWARNING:  control_file_record_keep_time is not within recommended range [1-9]:\" $CF_RECORD_KEEP_TIME;\nfi;\n\nThe expected output should be:\n\nPASS:  control_file_record_keep_time is within recommended range [1-9]: 7\n\nIf the output is not as expected, investigate and correct the condition(s).\n\nNOTE: The use of an RMAN recovery catalog is recommended as the best way to avoid the loss of RMAN metadata because of overwritten control file records."}, {"id": "2e6e9a88-1c15-4208-8021-77b04cd0c931", "title": "Links", "links": [{"hyperlink": "http://docs.oracle.com/cd/E18283_01/server.112/e17110/initparams034.htm", "text": "Initialization parameter CONTROL_FILE_RECORD_KEEP_TIME"}, {"hyperlink": "http://docs.oracle.com/cd/E11882_01/backup.112/e10642/toc.htm", "text": "Oracle Database Backup and Recovery User's Guide 11g Release 2 (11.2)"}]}]}]}]}, {"sectionId": "a787a912-d2ed-4b71-a8a6-062f960da29d", "sectionName": "Platinum Certification", "subsection": [{"subSectionName": "Platinum Certification", "checksList": [{"id": "406f5230-5d8f-4038-8b41-012d704e43fe", "checkCategory": "RDBMS", "checkID": "D8A5CE7E7E1FDFB0E053D298EB0AB79B", "checkType": "OS", "checkName": "Oracle database version verification for platinum certification", "checkStatus": "FAIL", "status": "danger", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "danger", "statusLabel": "FAIL", "output": "AHF-7928: Oracle database does not meet certified platinum configuration"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Oracle database version verification for platinum certification\n\n\n\n\nHost:              scaqal03adm05vm01\nStatus:            fail\nDatabase version:  21.7.0.0.0\nRequired versions: 11.2.0.4.201001 or 19.24.0.0.0 or 21.15.0.0.0\nSystem description:(EDVM)"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "danger", "statusLabel": "FAIL", "output": "AHF-7928: Oracle database does not meet certified platinum configuration"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Oracle database version verification for platinum certification\n\n\n\n\nHost:              scaqal03adm06vm01\nStatus:            fail\nDatabase version:  21.7.0.0.0\nRequired versions: 11.2.0.4.201001 or 19.24.0.0.0 or 21.15.0.0.0\nSystem description:(EDVM)"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nCustomers with Platinum Certified Configurations can access the enhanced support of Oracle Platinum Services under their existing Oracle Premier Support agreement without paying extra.\nIn addition to receiving the complete support essentials with Oracle Premier Support, qualifying Oracle Platinum Services customers also receive:\n24/7 Oracle remote fault monitoring\nIndustry-leading response and restore times\n  - 5 minute fault notification\n  - 15 minute restoration or escalation to\n    development\n  - 30 minute joint debugging with development\nPatch deployment performed by Oracle four times per year\n\nRisk:\n\nIn the event you do not meet the requirements or fulfil an obligation stated in the Oracle Platinum Support Policies you will no longer be eligible to receive Platinum Services, and Oracle, at its sole discretion, may discontinue providing the Platinum Services.\n\nAction / Repair:\n\nContact your Platinum Services representative or check the Platinum Services FAQ\nNote: This check checks against the \"Latest Certified Versions\" from the Certified Platinum Configurations (https://www.oracle.com/us/support/library/certified-platinum-configs-1652888.pdf) - not against the \"Earliest Compliant Versions\"."}, {"id": "25d0ed03-9cc5-418c-9301-f42e32ce2ae7", "title": "Links", "links": [{"hyperlink": "http://www.oracle.com/us/support/library/certified-platinum-configs-1652888.pdf", "text": "Certified Platinum Configurations"}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= PLATINUM&id=888828.1", "text": "Note: 888828.1 - Exadata Database Machine and Exadata Storage Server Supported Versions"}, {"hyperlink": "http://www.oracle.com/us/support/premier/engineered-systems-solutions/platinum-services/overview/index.html", "text": "Oracle Platinum Services"}, {"hyperlink": "http://www.oracle.com/us/support/library/platinum-services-faq-1653259.pdf", "text": "Oracle Platinum Services Frequently Asked Questions"}]}]}]}]}, {"sectionId": "9b6d8ba5-3f40-4028-a323-7414fece61cc", "sectionName": "Findings needing further review", "subsection": [{"subSectionName": "Findings needing further review", "checksList": [{"id": "8aa38ccc-7c1b-46bc-a5ea-dccc264945cd", "checkCategory": "RDBMS", "checkID": "8E7B8D6FAD3511F8E053D498EB0A161B", "checkType": "OS", "checkName": "Evaluate database parameter processes for versions 12 and higher", "checkStatus": "INFO", "status": "info", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "info", "statusLabel": "INFO", "output": "AHF-5332: Please refer to data and guidance provided for database parameter processes"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Evaluate database parameter processes for versions 12 and higher\n\n\n\nINFO:processes parameter value (2048) meets or exceeds recommended minimum:2048\nPlease refer to guidance provided in Action / Repair concerning appropriate testing."}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "info", "statusLabel": "INFO", "output": "AHF-5332: Please refer to data and guidance provided for database parameter processes"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Evaluate database parameter processes for versions 12 and higher\n\n\n\nINFO:processes parameter value (2048) meets or exceeds recommended minimum:2048\nPlease refer to guidance provided in Action / Repair concerning appropriate testing."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nThe values presented here are based upon internal testing and provide maximum reliability with generally acceptable performance.\n\nThe minimum recommended values  for database servers with five or less active instances are based on socket counts:\n\n2 socket servers - minimum of 1024\n8 socket servers - minimum of 2048\n\n\nRisk:\n\nNot properly testing and setting the processes parameter can lead to problems.\n\nAction / Repair:\n\nCustomers should always perform due diligence testing based upon traditional application / system tuning, coupled with analysis of application uptime requirements, to determine the appropriate setting for their application environment. For larger numbers of deployed databases, during the testing please also refer to Consolidation Parameters Reference Table.\n\nOnce the appropriate testing has been done, customers may change this parameter as needed to meet their requirements and ignore this basic guidance. \n\nPlease refer to the version specific Oracle documentation for guidance on adjusting this parameter."}, {"id": "1e37f4c9-6683-4c71-a9a7-008a78bc09d4", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1465230.1", "text": "Note: 1465230.1 - Resizing Grid Disks in Exadata: Example of Recreating RECO Grid Disks in a Rolling Manner"}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1551288.1", "text": "Note: 1551288.1 - Understanding ASM Capacity and Reservation of Free Space in Exadata"}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=757552.1", "text": "Note: 757552.1 - Oracle Exadata Best Practices"}]}]}, {"id": "279ff3db-9d84-4001-a699-a917a66631b0", "checkCategory": "RDBMS", "checkID": "0829D67E8B1549AFE05312C0E50AD04F", "checkType": "SQL", "checkName": "Ensure db_unique_name is unique across the enterprise [primary]", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB1", "status": "success", "statusLabel": "PASS", "output": "DB_UNIQUE_NAME on primary has not been modified from the default, confirm that database name is unique across your Oracle enterprise"}, "children": [{"attr": {"consoleOutput": "\n\nDATABASE_INFO\n--------------------------------------------------------------------------------------\nDatabase Name       :CDB1\nDatabase Unique Name:CDB1\nDatabase ID         :1097260951"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\ndb_unique_name is used extensively in many Clusterware, RDBMS, and Exadata code layers. db_unique_name is enforced to be unique within clusters but not across clusters. Ensuring db_unique_name is unique across clusters, especially those that are sharing the same Exadata storage, ensures that all code layers that use it work properly.\n\nRisk:\n\nHaving databases with the same db_unique_name across different Real Application Clusters that share the same Exadata storage causes unexpected behavior such as database isolation, crashes, or failures to start.\n\nAction / Repair:\n\nTo see whether db_unique_name is at the default value, as the owner of the oracle home for a given database and with the environment set to access that database, execute the following SQL command:\nBy default db_unique_name would be same as db_name parameter.\n\n  col DB_NAME format a30\n  col DB_UNIQUE_NAME format a30 \n  select sys_context ('USERENV','db_name') DB_NAME, sys_context ('USERENV','db_unique_name') DB_UNIQUE_NAME from dual ;\n\nAlternatively one can also use show parameter as below to verify:\n  show parameter db_name\n  show parameter db_unique_name\n\nNOTE:\nOracle recommends that db_unique_name is unique across a customer's Oracle enterprise. This recommendation assumes that an output prefixed with \"SUCCESS\" means specific care has been taken to ensure a given db_unique_name is unique across the customer's Oracle enterprise. An output prefixed with \"FAILURE\" is assumed to imply that enterprise a given db_unique_name may not have been validated to be unique across the customer's Oracle enterprise.\n\nThe corrective action is to ensure all databases have a unique name across the customer's Oracle enterprise, especially those accessing the same Exadata storage.\n\nIf it is known that all database names are unique across the Oracle enterprise, it is not necessary to take an outage just to change the value of db_unique_name. The change to db_unique_name required in order to make this recommendation pass can be done at the next scheduled maintenance period."}]}, {"id": "95f145a9-a160-4213-ad9a-2bd26947041d", "checkCategory": "RDBMS", "checkID": "41FD47D323EE3084E0530C98EB0A7B06", "checkType": "SQL_PARAM", "checkName": "Check for parameter processes", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Database parameter processes is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Database parameter processes is set to recommended value"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nExperience and testing has shown that certain database initialization parameters should be set at specific values. These are the best practice values set at deployment time. By setting these database initialization parameters as recommended, known problems may be avoided and performance maximized.\nThe parameters are common to all database instances. The impact of setting these parameters is minimal.\nThe performance related settings provide guidance to maintain highest stability without sacrificing performance. Changing the default performance settings can be done after careful performance evaluation and clear understanding of the performance impact.\n\n\n\nRisk:\n\nIf the database initialization parameters are not set as recommended, a variety of issues may be encountered, depending upon which initialization parameter is not set as recommended, and the actual set value.\n\n\n\nAction / Repair:\n\nThe values presented here are based upon internal testing and provide maximum reliability with generally acceptable performance.\n\nCustomers should always perform due diligence testing based upon traditional application / system tuning, coupled with analysis of application uptime requirements, to determine the appropriate setting for their application environment. \n\nOnce the appropriate testing has been done, customers may change this parameter as needed to meet their requirements and ignore this basic guidance."}]}, {"id": "9dd55e59-3aea-412c-9b2f-10e1ddacbd2c", "checkCategory": "HOST", "checkID": "54D3081DC73B64F9E0530B98EB0AC5A1", "checkType": "OS_OUT_CHECK", "checkName": "Verify installed rpm(s) kernel type match the active kernel version", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "All installed rpm(s) kernel type match the active kernel version"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 FOR VERIFY INSTALLED RPM(S) KERNEL TYPE MATCH THE ACTIVE KERNEL VERSION\n\n"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "All installed rpm(s) kernel type match the active kernel version"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 FOR VERIFY INSTALLED RPM(S) KERNEL TYPE MATCH THE ACTIVE KERNEL VERSION\n\n"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nVerifying installed rpm(s) kernel type match the active kernel version helps avoid update failures due to dependency conflicts between older rpm versions and newer versions being installed. The impact of verifying that installed rpm(s) kernel type match the active kernel version is minimal. The impact of correction depends upon why the mismatched rpm(s) was/were installed and cannot be estimated here.\n\n\nRisk:\n\nIf installed rpm(s) kernel type do not match the active kernel, there may be update interruptions caused by dependency conflicts between older rpm versions and newer versions being installed.\n\nAction / Repair:\n\n\"To verify the installed rpm(s) kernel type match the active kernel version, execute the following code as the \"root\" userid on each database server:\n\nunset ERROR_MESSAGE\nUNAME_DATA=$(uname -r)\nSTART=$(echo \"$UNAME_DATA\" | awk 'END{print index($0,\"el\")}')\nEND=$(expr $START + 2)\nKERNEL_TYPE=$(echo \"$UNAME_DATA\" | cut -c$START-$END)\ncase \"$KERNEL_TYPE\" in\n  el7)\n    MISMATCHED_RPMS=$(rpm -aq | egrep \".el5|.el6\")\n    ;;\n  el6)\n    MISMATCHED_RPMS=$(rpm -aq | grep \".el5|.el7\")\n    ;;\n  el5)\n    MISMATCHED_RPMS=$(rpm -aq | grep \".el6|.el7\")\n    ;;\n  *)\n    ERROR_MESSAGE=$(echo \"Unrecognized kernel type:  $KERNEL_TYPE\")\n    ;;\nesac\nif [ -n \"$ERROR_MESSAGE\" ]\nthen\n  echo -e \"\\nFAILURE:  $ERROR_MESSAGE\"\nelse\n  if [ -n \"$MISMATCHED_RPMS\" ]\n  then\n    MISMATCH_COUNT=$(echo \"$MISMATCHED_RPMS\" | wc -l)\n  else\n    MISMATCH_COUNT=0\n  fi\n  if [ -z \"$MISMATCHED_RPMS\" ]\n  then\n    echo -e \"\\nSUCCESS:  There were no mismatched rpms found.\\n\\nKernel type:\\t\\t$KERNEL_TYPE\\nMismatch count:\\t\\t$MISMATCH_COUNT\"\n  else\n    echo -e \"\\nFAILURE:  One or more mismatched rpms were found.\\n\\nKernel type:\\t\\t$KERNEL_TYPE\\nMismatch count:\\t\\t$MISMATCH_COUNT\\nMismatched rpms:\\n$MISMATCHED_RPMS\"\n  fi\nfi\n\nThe expected output should be similar to:\n\nSUCCESS:  There were no mismatched rpms found.\n\nKernel type:            el6\nMismatch count:         0\n\nExamples of \"FAILURE\" results:\n\nFAILURE:  One or more mismatched rpms were found.\n\nKernel type:            el5\nMismatch count:         37   \nMismatched rpms:\ngdb-7.2-83.el6.x86_64\nbasesystem-10.0-4.0.1.el6.noarch\nstrace-4.8-10.el6.x86_64\n&lt;output truncated&gt;\n\nFAILURE:  Unrecognized kernel type:  25.el\n\nIf the output is not \"SUCCESS\", investigate for root cause and take corrective action based on root cause findings.\n\""}]}, {"id": "9c223ed0-8db9-4e17-82a1-3aa68ff6455d", "checkCategory": "RDBMS", "checkID": "6BDA8C6A1A27BABBE053D598EB0A6230", "checkType": "OS", "checkName": "Evaluate Automated Maintenance Tasks configuration", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "All automated maintenance tasks are enabled"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm05vm01 - CDB1 DATABASE - Evaluate Automated Maintenance Tasks configuration\n\n\n\nINFO:all automated maintenance tasks are enabled.\nPlease review configuration appropriateness for this environment."}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "All automated maintenance tasks are enabled"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM scaqal03adm06vm01 - CDB1 DATABASE - Evaluate Automated Maintenance Tasks configuration\n\n\n\nINFO:all automated maintenance tasks are enabled.\nPlease review configuration appropriateness for this environment."}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nSome automated maintenance tasks are enabled by default with default settings at database creation time. It is recommended that these automated tasks be allowed to run, but that they are reviewed and adjusted if necessary to provide the most benefit for a given environment's workload. Benefits are provided by improving the overall efficiency of an environment, and also from not having the automated maintenance tasks themselves negatively impact the environment's specific workload.\n\nRisk:\n\nLeaving automated maintenance tasks at their default values, or disabling them completely may significantly impact a given environment's specific workload performance.\n\nAction / Repair:\n\nTo see basic information on automated maintenance tasks, as the owner of the oracle home for a given database and with the environment set to access that database, execute the following command set:\n\nFORMATTED_OUTPUT=$($ORACLE_HOME/bin/sqlplus -s \"/ as sysdba\" &lt;&lt;EOF\nset newpage none head off lines 80 feedback off timing off serveroutput on\nselect client_name,status from DBA_AUTOTASK_CLIENT;\nexit\nEOF\n)\nLINE_COUNT=$(echo \"$FORMATTED_OUTPUT\" | wc -l)\nENABLED_COUNT=$(echo \"$FORMATTED_OUTPUT\" | egrep -ic enabled)\nif [ $LINE_COUNT -eq $ENABLED_COUNT ]\nthen \n  echo -e \"INFO: all automated maintenance tasks are enabled.\"\n  echo -e \"Please review configuration appropriateness for this environment.\"\nelse \n  echo -e \"WARNING: one or more automated maintenance tasks are not enabled.\"\n  echo -e \"Please enable all and review configuration appropriateness for this environment.\\nDetails:\\n$FORMATTED_OUTPUT\" \nfi;\n\nThe expected output should be similar to:\n\nINFO: all automated maintenance tasks are enabled.\nPlease review configuration appropriateness for this environment.\n\nExample of a \"WARNING\" result:\n\nWARNING: one or more automated maintenance tasks are not enabled.\nPlease enable all and review configuration appropriateness for this environment.\nDetails:\nsql tuning advisor                                               ENABLED\nauto optimizer stats collection                                  ENABLED\nauto space advisor                                               DISABLED\n\n    NOTE:\n    Oracle recommends that Oracle supplied automated maintenance tasks be utilized and tuned for each individual database and it's associated workload.\n    For more information, please see:\n    Database Administrator's Guide, 11g Release 2, Managing Automated Database Maintenance Tasks\n    Database Administrator's Guide, 12c Release 1, Managing Automated Database Maintenance Tasks"}, {"id": "3d340a99-83ed-4a46-bbfa-8fadf47159fa", "title": "Links", "links": [{"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1465230.1", "text": "Note: 1465230.1 - Resizing Grid Disks in Exadata: Example of Recreating RECO Grid Disks in a Rolling Manner"}, {"hyperlink": "https://support.oracle.com/epmos/faces/DocumentDisplay?parent=exachkReport&sourceId= ENG SYSTEMS&id=1551288.1", "text": "Note: 1551288.1 - Understanding ASM Capacity and Reservation of Free Space in Exadata"}]}]}, {"id": "cc3743be-a8a0-49d9-b59f-d3f00fd135cc", "checkCategory": "ASM", "checkID": "9AC68A48CF21EDC9E040E50A1EC040A3", "checkType": "OS", "checkName": "ASM disk group compatible.rdbms attribute", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:+ASM1", "status": "success", "statusLabel": "PASS", "output": "All disk groups have compatible.rdbms attribute set to recommended values"}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - ASM DISK GROUP COMPATIBLE.RDBMS ATTRIBUTE\n\n\n\nLowest supported Oracle database version = 11.2.0.4. We highly recommend attribute compatible.rdbms to be higher or equal to such version.\n\nThe following disk groups have compatible.rdbms attribute set to recommended values:\nASM DATAC1.compatible.rdbms = 11.2.0.4\nASM RECOC1.compatible.rdbms = 11.2.0.4.0"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nExperience and MAA testing has shown that certain diskgroup attributes should be set at specific values. These are the best practice values set at deployment time. By setting these diskgroup attributes as recommended, known problems may be avoided and performance maximized. The attributes are specific to ASM diskgroups. The impact of setting these parameters is minimal. \n\n\nRisk:\n\nIf the diskgroup attributes are not set as recommended, performance and or availability issues can be encountered. \n\n\n\nAction / Repair:\n\nIt is recommended that compatible.rdbms be set to the lowest RDBMS version that will ever be used in this Cluster.\n\nNOTE: Reducing \"compatible.rdbms\" to an lower version from a higher version requires the diskgroup to be rebuilt. Therefore, the value of \"compatible.rdbms\" should be carefully analyzed and set according to customer requirements and business plans.\n\nNOTE: \"compatible.rdbms\" is set to 11.2.0.4 by default in new Exadata deployments to provide maximum version flexibility and to assure all space allocations will use fixed extents.\n\nNOTE: important features for Exadata that are enabled via compatible.rdbms are listed below. For the complete set, see the ASM documentation.\n\n    Appliance mode and fixed partnering with compatible.asm=12.1.0.2\n    Disk resync checkpointing with compatible.rdbms=12.1.0.2\n    Sparse disk group with with compatible.rdbms=12.1.0.2\n    Extended and Flex disk groups with compatible.rdbms=12.2.0.1"}]}, {"id": "c0fdc9ce-010a-44a6-b3de-8487c8bce2b8", "checkCategory": "HOST", "checkID": "B81B7B06B22B3D3DE0431EC0E50A29D5", "checkType": "OS", "checkName": "Verify average ping times to DNS nameserver [Database Server]", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01", "status": "success", "statusLabel": "PASS", "output": "Average ping times to DNS nameserver should not be negatively impacting SSH operations."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM05VM01 - VERIFY AVERAGE PING TIMES TO DNS NAMESERVER [DATABASE SERVER]\n\n\n\nActive DNS Server IP:\t\t 10.31.138.25\nAverage for 10 pings in ms:\t 0.278"}}]}, {"attr": {"target": "scaqal03adm06vm01", "status": "success", "statusLabel": "PASS", "output": "Average ping times to DNS nameserver should not be negatively impacting SSH operations."}, "children": [{"attr": {"consoleOutput": "\n\nDATA FROM SCAQAL03ADM06VM01 - VERIFY AVERAGE PING TIMES TO DNS NAMESERVER [DATABASE SERVER]\n\n\n\nActive DNS Server IP:\t\t 10.31.138.25\nAverage for 10 pings in ms:\t 0.275"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nSecure Shell (SSH) remote login procedures require communication between the remote target device and the DNS nameserver. Minimal average ping times to the DNS nameserver improve SSH login times and help to avoid problems such as timeouts or failed connection attempts.\n\nThe impact of verifying average ping times to the DNS nameserver is minimal. The impact required to minimize average ping times to the DNS nameserver varies by configuration and cannot be estimated here.\n\nRisk:\n\nLong ping times between remote SSH targets and the active DNS server may cause remote login failures, performance issues, or dropped application connections.\n\nAction / Repair:\n\nTo verify average ping times to DNS nameserver, enter the following command set as the \"root\" userid on each database server, storage server, and InfiniBand switch:\n\nHOST_NAME=$(hostname);\nif [ -s /usr/local/bin/version ]\nthen\n  DNS_SERVER=$(grep -o '[0-9]{1,3}.[0-9]{1,3}.[0-9]{1,3}.[0-9]{1,3}' /etc/resolv.conf | head -1);\nelse\n  DNS_SERVER=$(nslookup $HOST_NAME | head -1 | cut -d: -f2 | sed -e 's/^[ \\t]*//');\nfi;\nOS_TYPE=$(uname);\nif [ $OS_TYPE = \"Linux\" ]\nthen\n  PING_COMM=\"ping -c10 $DNS_SERVER\";\nelse\n  PING_COMM=\"ping -s $DNS_SERVER 56 5\";\nfi;\nAVG_PING_TIME=$($PING_COMM | egrep avg | cut -d\"/\" -f5);\nTRNC_AVG_PING_TIME=$(echo $AVG_PING_TIME | cut -d\".\" -f1);  \nif [ \"$TRNC_AVG_PING_TIME\" -le \"3\" ];\nthen\n  echo -e \"SUCCESS: Average ping times to DNS nameserver should not be negatively impacting SSH operations: $AVG_PING_TIME\";\n  echo -e \"Active DNS Server IP:  $DNS_SERVER\\n\";\nelse\n  echo -e \"WARNING: Average ping times to DNS nameserver may be negatively impacting SSH operations:  $AVG_PING_TIME\";\n  echo -e \"Active DNS Server IP:  $DNS_SERVER\\n\";\nfi;\n\nThe output should be similar to the following:\n\nSUCCESS: Average ping times to DNS nameserver should not be negatively impacting operations: 3.255\nActive DNS Server IP:  111.222.333.444\n\nIf the result is a \"WARNING\", first repeat the command set several times at different intervals to determine if the results are consistent. The command set is one spot check for ten pings. The environment could normally have a short delay and an execution just happened to catch a period of poor response, or it could normally have a long delay and an execution just happened to catch a period of good response. If the results are consistent, determine the root cause and take appropriate corrective action.\n\nNOTE: The result of this command set is a reflection of how DNS is implemented in the environment and not evidence in itself of a defect in the Oracle Exadata Database Machine.\n\nNOTE: A \"WARNING\" result does not prove that a delay is causing SSH connectivity problems in the environment. A \"WARNING\" result should always be evaluated in conjunction with a review of SSH connectivity issues in the environment. If there are other SSH connectivity issues present, evaluate if reducing or stabilizing the average ping times to the DNS nameserver may correct the issues.\n\nNOTE: As with many other network performance metrics, the average ping times to DNS nameserver should be \"minimal\". However, it is possible that any given environment may return a result that exceeds the threshold used in this command set, yet it is satisfactory given the overall environment characteristics and lack of other related problems. IF NO OTHER PROBLEMS related to DNS exist other than this command set returning a \"WARNING\", and the numbers reported are acceptable after a \"baseline\" for the given environment has been established by repeated sampling, then the documented procedures for bypassing this check in Exachk may be implemented.\n\nNOTE: Due to the differences in available commands for the InfiniBand switch, the command set assumes the first \"nameserver\" in /etc/resolv.conf is the \"active\" DNS server.\n\nNOTE: The use of the Name Service Cache Daemon (NSCD) may also mitigate the effects of long average ping times to DNS nameserver. For more information see: Verify the Name Service Cache Daemon (NSCD) is Running"}]}, {"id": "d05b77c6-d5e0-4717-8b34-0df15d4e5bb7", "checkCategory": "RDBMS", "checkID": "DC3BD42DE3422247E04312C0E50A0CB7", "checkType": "SQL_PARAM", "checkName": "Check for parameter db_files", "checkStatus": "PASS", "status": "success", "targetsTable": {"columns": [{"headerText": "Target", "sortProperty": "attr.target", "id": "checkName"}, {"headerText": "Status", "sortProperty": "attr.status", "id": "status"}, {"headerText": "Output", "sortProperty": "attr.output", "id": "output"}], "records": [{"attr": {"target": "scaqal03adm05vm01:CDB11", "status": "success", "statusLabel": "PASS", "output": "Database parameter DB_FILES is set to a value greater than or equal to 1024. See detailed notes to verify"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}, {"attr": {"target": "scaqal03adm06vm01:CDB12", "status": "success", "statusLabel": "PASS", "output": "Database parameter DB_FILES is set to a value greater than or equal to 1024. See detailed notes to verify"}, "children": [{"attr": {"consoleOutput": "\nCDB11.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB12.DBFIPS_140 = FALSE|TRUE|FALSE\nCDB11._appqos_cdb_setting = 3|FALSE|FALSE\nCDB12._appqos_cdb_setting = 3|FALSE|FALSE\nCDB11._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB12._assm_segment_repair_bg = FALSE|FALSE|FALSE\nCDB11._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB12._disable_oradebug_commands = NONE|FALSE|FALSE\nCDB11._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB12._ipddb_enable = TRUE|TRUE|SYSTEM_MOD\nCDB11._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB12._parallel_adaptive_max_users = 2|FALSE|FALSE\nCDB11.active_instance_count = |TRUE|FALSE\nCDB12.active_instance_count = |TRUE|FALSE\nCDB11.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB12.adg_account_info_tracking = LOCAL|TRUE|FALSE\nCDB11.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB12.adg_redirect_dml = FALSE|TRUE|FALSE\nCDB11.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB12.allow_deprecated_rpcs = YES|TRUE|FALSE\nCDB11.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB12.allow_global_dblinks = FALSE|TRUE|FALSE\nCDB11.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB12.allow_group_access_to_sga = FALSE|TRUE|FALSE\nCDB11.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB12.allow_rowid_column_type = FALSE|TRUE|FALSE\nCDB11.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB12.approx_for_aggregation = FALSE|TRUE|FALSE\nCDB11.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB12.approx_for_count_distinct = FALSE|TRUE|FALSE\nCDB11.approx_for_percentile = NONE|TRUE|FALSE\nCDB12.approx_for_percentile = NONE|TRUE|FALSE\nCDB11.aq_tm_processes = 1|TRUE|FALSE\nCDB12.aq_tm_processes = 1|TRUE|FALSE\nCDB11.archive_lag_target = 0|TRUE|FALSE\nCDB12.archive_lag_target = 0|TRUE|FALSE\nCDB11.asm_diskstring = |TRUE|FALSE\nCDB12.asm_diskstring = |TRUE|FALSE\nCDB11.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB12.asm_preferred_read_failure_groups = |TRUE|FALSE\nCDB11.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB12.audit_file_dest = /u01/app/oracle/homes/DbHome_1/rdbms/audit|TRUE|FALSE\nCDB11.audit_sys_operations = TRUE|FALSE|FALSE\nCDB12.audit_sys_operations = TRUE|FALSE|FALSE\nCDB11.audit_syslog_level = |TRUE|FALSE\nCDB12.audit_syslog_level = |TRUE|FALSE\nCDB11.audit_trail = DB|FALSE|FALSE\nCDB12.audit_trail = DB|FALSE|FALSE\nCDB11.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB12.auto_start_pdb_services = FALSE|TRUE|FALSE\nCDB11.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB12.autotask_max_active_pdbs = 2|TRUE|FALSE\nCDB11.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB12.awr_pdb_autoflush_enabled = FALSE|TRUE|FALSE\nCDB11.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB12.awr_pdb_max_parallel_slaves = 10|TRUE|FALSE\nCDB11.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB12.awr_snapshot_time_offset = 0|TRUE|FALSE\nCDB11.background_core_dump = partial|TRUE|FALSE\nCDB12.background_core_dump = partial|TRUE|FALSE\nCDB11.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB12.background_dump_dest = /u01/app/oracle/homes/DbHome_1/rdbms/log|TRUE|FALSE\nCDB11.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB12.backup_tape_io_slaves = FALSE|TRUE|FALSE\nCDB11.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB12.bitmap_merge_area_size = 1048576|TRUE|FALSE\nCDB11.blank_trimming = FALSE|TRUE|FALSE\nCDB12.blank_trimming = FALSE|TRUE|FALSE\nCDB11.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB12.blockchain_table_max_no_drop = |TRUE|FALSE\nCDB11.buffer_pool_keep = |TRUE|FALSE\nCDB12.buffer_pool_keep = |TRUE|FALSE\nCDB11.buffer_pool_recycle = |TRUE|FALSE\nCDB12.buffer_pool_recycle = |TRUE|FALSE\nCDB11.cdb_cluster = FALSE|TRUE|FALSE\nCDB12.cdb_cluster = FALSE|TRUE|FALSE\nCDB11.cdb_cluster_name = |TRUE|FALSE\nCDB12.cdb_cluster_name = |TRUE|FALSE\nCDB11.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB12.cell_offload_compaction = ADAPTIVE|TRUE|FALSE\nCDB11.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB12.cell_offload_decryption = TRUE|TRUE|FALSE\nCDB11.cell_offload_parameters = |TRUE|FALSE\nCDB12.cell_offload_parameters = |TRUE|FALSE\nCDB11.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB12.cell_offload_plan_display = AUTO|TRUE|FALSE\nCDB11.cell_offload_processing = TRUE|TRUE|FALSE\nCDB12.cell_offload_processing = TRUE|TRUE|FALSE\nCDB11.cell_offloadgroup_name = |TRUE|FALSE\nCDB12.cell_offloadgroup_name = |TRUE|FALSE\nCDB11.circuits = |TRUE|FALSE\nCDB12.circuits = |TRUE|FALSE\nCDB11.client_result_cache_lag = 3000|TRUE|FALSE\nCDB12.client_result_cache_lag = 3000|TRUE|FALSE\nCDB11.client_result_cache_size = 0|TRUE|FALSE\nCDB12.client_result_cache_size = 0|TRUE|FALSE\nCDB11.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB12.client_statistics_level = TYPICAL|TRUE|FALSE\nCDB11.clonedb = FALSE|TRUE|FALSE\nCDB12.clonedb = FALSE|TRUE|FALSE"}}]}]}, "listViewItems": [{"title": "Recommendation", "content": "Benefit / Impact:\n\nExperience and testing has shown that certain database initialization parameters should be set at specific values. These are the best practice values set at deployment time. By setting these database initialization parameters as recommended, known problems may be avoided and performance maximized.\n\nThe parameters are common to all database instances. The impact of setting these parameters is minimal.\n\nThe performance related settings provide guidance to maintain highest stability without sacrificing performance. Changing the default performance settings can be done after careful performance evaluation and clear understanding of the performance impact.\n\nRisk:\n\nIf the database initialization parameters are not set as recommended, a variety of issues may be encountered, depending upon which initialization parameter is not set as recommended, and the actual set value.\n\n\n\nAction / Repair:\n\nThe minimum recommended value for db_files is 1024.\n\nThe default value (200) is typically too small for most customers.\n\nThe values presented here are based upon internal testing and provide maximum reliability with generally acceptable performance.\n\nCustomers should always perform due diligence testing based upon traditional application / system tuning, coupled with analysis of application uptime requirements, to determine the appropriate setting for their application environment.\n\nOnce the appropriate testing has been done, customers may change this parameter as needed to meet their requirements and ignore this basic guidance.\n\nNOTE: Setting DB_FILES to a much larger value can increase pressure on the SGA (even if not all files permitted by the limit are actually created), possibly leading to a performance impact. The risk of performance impact is greater when both DB_FILES and PROCESSES are set to large values. A possible alternative to setting DB_FILES to a large value is to use \"BIGFILE\" tablespaces in conjunction with a reasonable DB_FILES value."}]}]}]}], "nonCheckSections": [{"sectionId": "a46840bd-e2f6-4185-9eec-ecac2be7f35b", "sectionName": "Elapsed Times", "subsection": [{"subSectionName": "Elapsed Times", "plainTable": {"columns": [{"headerText": "Component Name", "field": "name", "className": "table-world-wrap"}, {"headerText": "Component Type", "field": "type", "className": "table-world-wrap"}, {"headerText": "Elapsed Time", "field": "elapsedTime", "className": "table-world-wrap"}], "records": [{"name": "scaqal03adm05vm01", "type": "Database Server", "elapsedTime": "42 seconds"}, {"name": "scaqal03adm06vm01", "type": "Database Server", "elapsedTime": "41 seconds"}]}}]}], "plots": [{"available": true, "report": "../plots/best_practice_distribution_plot.js", "height": 500}, {"available": true, "report": "../plots/best_practice_distribution_pie_plot.js", "height": 500}], "statusOptions": [{"value": "PASS", "label": "PASS"}, {"value": "WARN", "label": "WARN"}, {"value": "CRITICAL", "label": "CRITICAL"}, {"value": "FAIL", "label": "FAIL"}, {"value": "INFO", "label": "INFO"}]}};
          
          exports.default = bestPracticeIssuesJson;
          
        });

        